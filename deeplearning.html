<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Predicting Behavior with Deep Learning | Behavior Analysis with Machine Learning and R</title>
  <meta name="description" content="Chapter 8 Predicting Behavior with Deep Learning | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Predicting Behavior with Deep Learning | Behavior Analysis with Machine Learning and R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="Chapter 8 Predicting Behavior with Deep Learning | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Predicting Behavior with Deep Learning | Behavior Analysis with Machine Learning and R" />
  
  <meta name="twitter:description" content="Chapter 8 Predicting Behavior with Deep Learning | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Enrique Garcia Ceja" />


<meta name="date" content="2020-12-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="representations.html"/>
<link rel="next" href="multiuser.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/d3-4.9.0/d3.min.js"></script>
<script src="libs/d3-tip-0.7.1/index-min.js"></script>
<link href="libs/d3panels-1.4.9/d3panels.min.css" rel="stylesheet" />
<script src="libs/d3panels-1.4.9/d3panels.min.js"></script>
<script src="libs/qtlcharts_iplotCorr-0.11.6/iplotCorr.js"></script>
<script src="libs/qtlcharts_iplotCorr-0.11.6/iplotCorr_noscat.js"></script>
<script src="libs/iplotCorr-binding-0.11.6/iplotCorr.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178679335-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178679335-1', { 'anonymize_ip': true });
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="#">Behavior Analysis with Machine Learning and R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#supplemental-material"><i class="fa fa-check"></i>Supplemental Material</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#taxonomy"><i class="fa fa-check"></i><b>1.2</b> Types of Machine Learning</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#terminology"><i class="fa fa-check"></i><b>1.3</b> Terminology</a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#tables"><i class="fa fa-check"></i><b>1.3.1</b> Tables</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#variable-types"><i class="fa fa-check"></i><b>1.3.2</b> Variable Types</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#predictive-models"><i class="fa fa-check"></i><b>1.3.3</b> Predictive Models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#pipeline"><i class="fa fa-check"></i><b>1.4</b> Data Analysis Pipeline</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#trainingeval"><i class="fa fa-check"></i><b>1.5</b> Evaluating Predictive Models</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#simple-classification-example"><i class="fa fa-check"></i><b>1.6</b> Simple Classification Example</a><ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#k-fold-cross-validation-example"><i class="fa fa-check"></i><b>1.6.1</b> K-fold Cross-Validation Example</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#simple-regression-example"><i class="fa fa-check"></i><b>1.7</b> Simple Regression Example</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>1.8</b> Underfitting and Overfitting</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#bias-and-variance"><i class="fa fa-check"></i><b>1.9</b> Bias and Variance</a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#SummaryIntro"><i class="fa fa-check"></i><b>1.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>2</b> Predicting Behavior with Classification Models</a><ul>
<li class="chapter" data-level="2.1" data-path="classification.html"><a href="classification.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>2.1</b> <em>k</em>-nearest Neighbors</a><ul>
<li class="chapter" data-level="2.1.1" data-path="classification.html"><a href="classification.html#indoor-location-with-wi-fi-signals"><i class="fa fa-check"></i><b>2.1.1</b> Indoor Location with Wi-Fi Signals</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="classification.html"><a href="classification.html#performance-metrics"><i class="fa fa-check"></i><b>2.2</b> Performance Metrics</a><ul>
<li class="chapter" data-level="2.2.1" data-path="classification.html"><a href="classification.html#confusion-matrix"><i class="fa fa-check"></i><b>2.2.1</b> Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="classification.html"><a href="classification.html#decision-trees"><i class="fa fa-check"></i><b>2.3</b> Decision Trees</a><ul>
<li class="chapter" data-level="2.3.1" data-path="classification.html"><a href="classification.html#activityRecognition"><i class="fa fa-check"></i><b>2.3.1</b> Activity Recognition with Smartphones</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="classification.html"><a href="classification.html#naive-bayes"><i class="fa fa-check"></i><b>2.4</b> Naive Bayes</a><ul>
<li class="chapter" data-level="2.4.1" data-path="classification.html"><a href="classification.html#activity-recognition-with-naive-bayes"><i class="fa fa-check"></i><b>2.4.1</b> Activity Recognition with Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="classification.html"><a href="classification.html#dynamic-time-warping"><i class="fa fa-check"></i><b>2.5</b> Dynamic Time Warping</a><ul>
<li class="chapter" data-level="2.5.1" data-path="classification.html"><a href="classification.html#sechandgestures"><i class="fa fa-check"></i><b>2.5.1</b> Hand Gesture Recognition</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="classification.html"><a href="classification.html#dummy-models"><i class="fa fa-check"></i><b>2.6</b> Dummy Models</a><ul>
<li class="chapter" data-level="2.6.1" data-path="classification.html"><a href="classification.html#most-frequent-class-classifier"><i class="fa fa-check"></i><b>2.6.1</b> Most-frequent-class Classifier</a></li>
<li class="chapter" data-level="2.6.2" data-path="classification.html"><a href="classification.html#uniform-classifier"><i class="fa fa-check"></i><b>2.6.2</b> Uniform Classifier</a></li>
<li class="chapter" data-level="2.6.3" data-path="classification.html"><a href="classification.html#frequency-based-classifier"><i class="fa fa-check"></i><b>2.6.3</b> Frequency-based Classifier</a></li>
<li class="chapter" data-level="2.6.4" data-path="classification.html"><a href="classification.html#other-dummy-classifiers"><i class="fa fa-check"></i><b>2.6.4</b> Other Dummy Classifiers</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="classification.html"><a href="classification.html#summaryClassification"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>3</b> Predicting Behavior with Ensemble Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="ensemble.html"><a href="ensemble.html#bagging"><i class="fa fa-check"></i><b>3.1</b> Bagging</a><ul>
<li class="chapter" data-level="3.1.1" data-path="ensemble.html"><a href="ensemble.html#activity-recognition-with-bagging"><i class="fa fa-check"></i><b>3.1.1</b> Activity recognition with Bagging</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ensemble.html"><a href="ensemble.html#random-forest"><i class="fa fa-check"></i><b>3.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.3" data-path="ensemble.html"><a href="ensemble.html#stacked-generalization"><i class="fa fa-check"></i><b>3.3</b> Stacked Generalization</a></li>
<li class="chapter" data-level="3.4" data-path="ensemble.html"><a href="ensemble.html#multiviewhometasks"><i class="fa fa-check"></i><b>3.4</b> Multi-view Stacking for Home Tasks Recognition</a></li>
<li class="chapter" data-level="3.5" data-path="ensemble.html"><a href="ensemble.html#SummaryEnsemble"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="edavis.html"><a href="edavis.html"><i class="fa fa-check"></i><b>4</b> Exploring and Visualizing Behavioral Data</a><ul>
<li class="chapter" data-level="4.1" data-path="edavis.html"><a href="edavis.html#talking-with-field-experts"><i class="fa fa-check"></i><b>4.1</b> Talking with Field Experts</a></li>
<li class="chapter" data-level="4.2" data-path="edavis.html"><a href="edavis.html#summary-statistics"><i class="fa fa-check"></i><b>4.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="4.3" data-path="edavis.html"><a href="edavis.html#class-distributions"><i class="fa fa-check"></i><b>4.3</b> Class Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="edavis.html"><a href="edavis.html#user-class-sparsity-matrix"><i class="fa fa-check"></i><b>4.4</b> User-Class Sparsity Matrix</a></li>
<li class="chapter" data-level="4.5" data-path="edavis.html"><a href="edavis.html#boxplots"><i class="fa fa-check"></i><b>4.5</b> Boxplots</a></li>
<li class="chapter" data-level="4.6" data-path="edavis.html"><a href="edavis.html#correlation-plots"><i class="fa fa-check"></i><b>4.6</b> Correlation Plots</a><ul>
<li class="chapter" data-level="4.6.1" data-path="edavis.html"><a href="edavis.html#interactive-correlation-plots"><i class="fa fa-check"></i><b>4.6.1</b> Interactive Correlation Plots</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="edavis.html"><a href="edavis.html#timeseries"><i class="fa fa-check"></i><b>4.7</b> Timeseries</a><ul>
<li class="chapter" data-level="4.7.1" data-path="edavis.html"><a href="edavis.html#interactive-timeseries"><i class="fa fa-check"></i><b>4.7.1</b> Interactive Timeseries</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="edavis.html"><a href="edavis.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>4.8</b> Multidimensional Scaling (MDS)</a></li>
<li class="chapter" data-level="4.9" data-path="edavis.html"><a href="edavis.html#heatmaps"><i class="fa fa-check"></i><b>4.9</b> Heatmaps</a></li>
<li class="chapter" data-level="4.10" data-path="edavis.html"><a href="edavis.html#automated-eda"><i class="fa fa-check"></i><b>4.10</b> Automated EDA</a></li>
<li class="chapter" data-level="4.11" data-path="edavis.html"><a href="edavis.html#SummaryExploratory"><i class="fa fa-check"></i><b>4.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>5</b> Preprocessing Behavioral Data</a><ul>
<li class="chapter" data-level="5.1" data-path="preprocessing.html"><a href="preprocessing.html#missing-values"><i class="fa fa-check"></i><b>5.1</b> Missing Values</a><ul>
<li class="chapter" data-level="5.1.1" data-path="preprocessing.html"><a href="preprocessing.html#imputation"><i class="fa fa-check"></i><b>5.1.1</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="preprocessing.html"><a href="preprocessing.html#smoothing"><i class="fa fa-check"></i><b>5.2</b> Smoothing</a></li>
<li class="chapter" data-level="5.3" data-path="preprocessing.html"><a href="preprocessing.html#normalization"><i class="fa fa-check"></i><b>5.3</b> Normalization</a></li>
<li class="chapter" data-level="5.4" data-path="preprocessing.html"><a href="preprocessing.html#imbalanced-classes"><i class="fa fa-check"></i><b>5.4</b> Imbalanced Classes</a><ul>
<li class="chapter" data-level="5.4.1" data-path="preprocessing.html"><a href="preprocessing.html#random-oversampling"><i class="fa fa-check"></i><b>5.4.1</b> Random Oversampling</a></li>
<li class="chapter" data-level="5.4.2" data-path="preprocessing.html"><a href="preprocessing.html#smote"><i class="fa fa-check"></i><b>5.4.2</b> SMOTE</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="preprocessing.html"><a href="preprocessing.html#infoinjection"><i class="fa fa-check"></i><b>5.5</b> Information Injection</a></li>
<li class="chapter" data-level="5.6" data-path="preprocessing.html"><a href="preprocessing.html#one-hot-encoding"><i class="fa fa-check"></i><b>5.6</b> One-hot Encoding</a></li>
<li class="chapter" data-level="5.7" data-path="preprocessing.html"><a href="preprocessing.html#SummaryPreprocessing"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>6</b> Discovering Behaviors with Unsupervised Learning</a><ul>
<li class="chapter" data-level="6.1" data-path="unsupervised.html"><a href="unsupervised.html#k-means-clustering"><i class="fa fa-check"></i><b>6.1</b> K-means clustering</a><ul>
<li class="chapter" data-level="6.1.1" data-path="unsupervised.html"><a href="unsupervised.html#studentresponses"><i class="fa fa-check"></i><b>6.1.1</b> Grouping Student Responses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="unsupervised.html"><a href="unsupervised.html#the-silhouette-index"><i class="fa fa-check"></i><b>6.2</b> The Silhouette Index</a></li>
<li class="chapter" data-level="6.3" data-path="unsupervised.html"><a href="unsupervised.html#associationrules"><i class="fa fa-check"></i><b>6.3</b> Mining Association Rules</a><ul>
<li class="chapter" data-level="6.3.1" data-path="unsupervised.html"><a href="unsupervised.html#finding-rules-for-criminal-behavior"><i class="fa fa-check"></i><b>6.3.1</b> Finding Rules for Criminal Behavior</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="unsupervised.html"><a href="unsupervised.html#SummaryUnsupervised"><i class="fa fa-check"></i><b>6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="representations.html"><a href="representations.html"><i class="fa fa-check"></i><b>7</b> Encoding Behavioral Data</a><ul>
<li class="chapter" data-level="7.1" data-path="representations.html"><a href="representations.html#feature-vectors"><i class="fa fa-check"></i><b>7.1</b> Feature Vectors</a></li>
<li class="chapter" data-level="7.2" data-path="representations.html"><a href="representations.html#sectimeseries"><i class="fa fa-check"></i><b>7.2</b> Timeseries</a></li>
<li class="chapter" data-level="7.3" data-path="representations.html"><a href="representations.html#transactions"><i class="fa fa-check"></i><b>7.3</b> Transactions</a></li>
<li class="chapter" data-level="7.4" data-path="representations.html"><a href="representations.html#images"><i class="fa fa-check"></i><b>7.4</b> Images</a></li>
<li class="chapter" data-level="7.5" data-path="representations.html"><a href="representations.html#recurrence-plots"><i class="fa fa-check"></i><b>7.5</b> Recurrence Plots</a><ul>
<li class="chapter" data-level="7.5.1" data-path="representations.html"><a href="representations.html#computing-recurence-plots"><i class="fa fa-check"></i><b>7.5.1</b> Computing Recurence Plots</a></li>
<li class="chapter" data-level="7.5.2" data-path="representations.html"><a href="representations.html#recurrence-plots-of-hand-gestures"><i class="fa fa-check"></i><b>7.5.2</b> Recurrence Plots of Hand Gestures</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="representations.html"><a href="representations.html#bag-of-words"><i class="fa fa-check"></i><b>7.6</b> Bag-of-Words</a><ul>
<li class="chapter" data-level="7.6.1" data-path="representations.html"><a href="representations.html#bow-for-complex-activities."><i class="fa fa-check"></i><b>7.6.1</b> BoW for Complex Activities.</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="representations.html"><a href="representations.html#graphs"><i class="fa fa-check"></i><b>7.7</b> Graphs</a><ul>
<li class="chapter" data-level="7.7.1" data-path="representations.html"><a href="representations.html#complex-activities-as-graphs"><i class="fa fa-check"></i><b>7.7.1</b> Complex Activities as Graphs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="representations.html"><a href="representations.html#SummaryRepresentations"><i class="fa fa-check"></i><b>7.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="deeplearning.html"><a href="deeplearning.html"><i class="fa fa-check"></i><b>8</b> Predicting Behavior with Deep Learning</a><ul>
<li class="chapter" data-level="8.1" data-path="deeplearning.html"><a href="deeplearning.html#ann"><i class="fa fa-check"></i><b>8.1</b> Introduction to Artificial Neural Networks</a><ul>
<li class="chapter" data-level="8.1.1" data-path="deeplearning.html"><a href="deeplearning.html#sigmoid-and-relu-units"><i class="fa fa-check"></i><b>8.1.1</b> Sigmoid and ReLU Units</a></li>
<li class="chapter" data-level="8.1.2" data-path="deeplearning.html"><a href="deeplearning.html#assembling-units-into-layers"><i class="fa fa-check"></i><b>8.1.2</b> Assembling Units into Layers</a></li>
<li class="chapter" data-level="8.1.3" data-path="deeplearning.html"><a href="deeplearning.html#deep-neural-networks"><i class="fa fa-check"></i><b>8.1.3</b> Deep Neural Networks</a></li>
<li class="chapter" data-level="8.1.4" data-path="deeplearning.html"><a href="deeplearning.html#learning-the-parameters"><i class="fa fa-check"></i><b>8.1.4</b> Learning the Parameters</a></li>
<li class="chapter" data-level="8.1.5" data-path="deeplearning.html"><a href="deeplearning.html#parameter-learning-example-in-r"><i class="fa fa-check"></i><b>8.1.5</b> Parameter Learning Example in R</a></li>
<li class="chapter" data-level="8.1.6" data-path="deeplearning.html"><a href="deeplearning.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>8.1.6</b> Stochastic Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="deeplearning.html"><a href="deeplearning.html#keras-and-tensorflow-with-r"><i class="fa fa-check"></i><b>8.2</b> Keras and TensorFlow with R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="deeplearning.html"><a href="deeplearning.html#keras-example"><i class="fa fa-check"></i><b>8.2.1</b> Keras Example</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="deeplearning.html"><a href="deeplearning.html#classification-with-neural-networks"><i class="fa fa-check"></i><b>8.3</b> Classification with Neural Networks</a><ul>
<li class="chapter" data-level="8.3.1" data-path="deeplearning.html"><a href="deeplearning.html#classification-of-electromyography-signals"><i class="fa fa-check"></i><b>8.3.1</b> Classification of Electromyography Signals</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="deeplearning.html"><a href="deeplearning.html#overfitting"><i class="fa fa-check"></i><b>8.4</b> Overfitting</a><ul>
<li class="chapter" data-level="8.4.1" data-path="deeplearning.html"><a href="deeplearning.html#early-stopping"><i class="fa fa-check"></i><b>8.4.1</b> Early Stopping</a></li>
<li class="chapter" data-level="8.4.2" data-path="deeplearning.html"><a href="deeplearning.html#dropout"><i class="fa fa-check"></i><b>8.4.2</b> Dropout</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="deeplearning.html"><a href="deeplearning.html#fine-tuning-a-neural-network"><i class="fa fa-check"></i><b>8.5</b> Fine-Tuning a Neural Network</a></li>
<li class="chapter" data-level="8.6" data-path="deeplearning.html"><a href="deeplearning.html#cnns"><i class="fa fa-check"></i><b>8.6</b> Convolutional Neural Networks</a><ul>
<li class="chapter" data-level="8.6.1" data-path="deeplearning.html"><a href="deeplearning.html#convolutions"><i class="fa fa-check"></i><b>8.6.1</b> Convolutions</a></li>
<li class="chapter" data-level="8.6.2" data-path="deeplearning.html"><a href="deeplearning.html#pooling-operations"><i class="fa fa-check"></i><b>8.6.2</b> Pooling Operations</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="deeplearning.html"><a href="deeplearning.html#cnns-with-keras"><i class="fa fa-check"></i><b>8.7</b> CNNs with Keras</a><ul>
<li class="chapter" data-level="8.7.1" data-path="deeplearning.html"><a href="deeplearning.html#example-1"><i class="fa fa-check"></i><b>8.7.1</b> Example 1</a></li>
<li class="chapter" data-level="8.7.2" data-path="deeplearning.html"><a href="deeplearning.html#example-2"><i class="fa fa-check"></i><b>8.7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="deeplearning.html"><a href="deeplearning.html#cnnSmile"><i class="fa fa-check"></i><b>8.8</b> Smiles Detection with a CNN</a></li>
<li class="chapter" data-level="8.9" data-path="deeplearning.html"><a href="deeplearning.html#SummaryDeepLearning"><i class="fa fa-check"></i><b>8.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiuser.html"><a href="multiuser.html"><i class="fa fa-check"></i><b>9</b> Multi-User Validation</a><ul>
<li class="chapter" data-level="9.1" data-path="multiuser.html"><a href="multiuser.html#mixed-models"><i class="fa fa-check"></i><b>9.1</b> Mixed Models</a><ul>
<li class="chapter" data-level="9.1.1" data-path="multiuser.html"><a href="multiuser.html#skeleton-action-recognition-with-mixed-models"><i class="fa fa-check"></i><b>9.1.1</b> Skeleton Action Recognition with Mixed Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="multiuser.html"><a href="multiuser.html#user-independent-models"><i class="fa fa-check"></i><b>9.2</b> User-Independent Models</a></li>
<li class="chapter" data-level="9.3" data-path="multiuser.html"><a href="multiuser.html#user-dependent-models"><i class="fa fa-check"></i><b>9.3</b> User-Dependent Models</a></li>
<li class="chapter" data-level="9.4" data-path="multiuser.html"><a href="multiuser.html#user-adaptive-models"><i class="fa fa-check"></i><b>9.4</b> User-Adaptive Models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="multiuser.html"><a href="multiuser.html#transfer-learning"><i class="fa fa-check"></i><b>9.4.1</b> Transfer Learning</a></li>
<li class="chapter" data-level="9.4.2" data-path="multiuser.html"><a href="multiuser.html#a-user-adaptive-model-for-activity-recognition"><i class="fa fa-check"></i><b>9.4.2</b> A User-Adaptive Model for Activity Recognition</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="multiuser.html"><a href="multiuser.html#SummaryMultiUser"><i class="fa fa-check"></i><b>9.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html"><i class="fa fa-check"></i><b>10</b> Detecting Abnormal Behaviors</a><ul>
<li class="chapter" data-level="10.1" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#isolation-forests"><i class="fa fa-check"></i><b>10.1</b> Isolation Forests</a></li>
<li class="chapter" data-level="10.2" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#detecting-abnormal-fish-behaviors"><i class="fa fa-check"></i><b>10.2</b> Detecting Abnormal Fish Behaviors</a><ul>
<li class="chapter" data-level="10.2.1" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#explore-and-visualize-trajectories"><i class="fa fa-check"></i><b>10.2.1</b> Explore and Visualize Trajectories</a></li>
<li class="chapter" data-level="10.2.2" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#preprocessing-and-feature-extraction"><i class="fa fa-check"></i><b>10.2.2</b> Preprocessing and Feature Extraction</a></li>
<li class="chapter" data-level="10.2.3" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#training-the-model"><i class="fa fa-check"></i><b>10.2.3</b> Training the Model</a></li>
<li class="chapter" data-level="10.2.4" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#roc-curve-and-auc"><i class="fa fa-check"></i><b>10.2.4</b> ROC curve and AUC</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#autoencoders"><i class="fa fa-check"></i><b>10.3</b> Autoencoders</a><ul>
<li class="chapter" data-level="10.3.1" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#autoencoders-for-anomaly-detection"><i class="fa fa-check"></i><b>10.3.1</b> Autoencoders for Anomaly Detection</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#SummaryAnomalyDetection"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixInstall.html"><a href="appendixInstall.html"><i class="fa fa-check"></i><b>A</b> Setup Your Environment</a><ul>
<li class="chapter" data-level="A.1" data-path="appendixInstall.html"><a href="appendixInstall.html#installing-the-datasets"><i class="fa fa-check"></i><b>A.1</b> Installing the Datasets</a></li>
<li class="chapter" data-level="A.2" data-path="appendixInstall.html"><a href="appendixInstall.html#installing-the-examples-source-code"><i class="fa fa-check"></i><b>A.2</b> Installing the Examples Source Code</a></li>
<li class="chapter" data-level="A.3" data-path="appendixInstall.html"><a href="appendixInstall.html#running-shiny-apps"><i class="fa fa-check"></i><b>A.3</b> Running Shiny Apps</a></li>
<li class="chapter" data-level="A.4" data-path="appendixInstall.html"><a href="appendixInstall.html#installing-keras-and-tensorflow"><i class="fa fa-check"></i><b>A.4</b> Installing Keras and TensorFlow</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixDatasets.html"><a href="appendixDatasets.html"><i class="fa fa-check"></i><b>B</b> Datasets</a><ul>
<li class="chapter" data-level="B.1" data-path="appendixDatasets.html"><a href="appendixDatasets.html#complex-activities"><i class="fa fa-check"></i><b>B.1</b> COMPLEX ACTIVITIES</a></li>
<li class="chapter" data-level="B.2" data-path="appendixDatasets.html"><a href="appendixDatasets.html#depresjon"><i class="fa fa-check"></i><b>B.2</b> DEPRESJON</a></li>
<li class="chapter" data-level="B.3" data-path="appendixDatasets.html"><a href="appendixDatasets.html#electromyography"><i class="fa fa-check"></i><b>B.3</b> ELECTROMYOGRAPHY</a></li>
<li class="chapter" data-level="B.4" data-path="appendixDatasets.html"><a href="appendixDatasets.html#fish-trajectories"><i class="fa fa-check"></i><b>B.4</b> FISH TRAJECTORIES</a></li>
<li class="chapter" data-level="B.5" data-path="appendixDatasets.html"><a href="appendixDatasets.html#hand-gestures"><i class="fa fa-check"></i><b>B.5</b> HAND GESTURES</a></li>
<li class="chapter" data-level="B.6" data-path="appendixDatasets.html"><a href="appendixDatasets.html#home-tasks"><i class="fa fa-check"></i><b>B.6</b> HOME TASKS</a></li>
<li class="chapter" data-level="B.7" data-path="appendixDatasets.html"><a href="appendixDatasets.html#homicide-reports"><i class="fa fa-check"></i><b>B.7</b> HOMICIDE REPORTS</a></li>
<li class="chapter" data-level="B.8" data-path="appendixDatasets.html"><a href="appendixDatasets.html#indoor-location"><i class="fa fa-check"></i><b>B.8</b> INDOOR LOCATION</a></li>
<li class="chapter" data-level="B.9" data-path="appendixDatasets.html"><a href="appendixDatasets.html#sheep-goats"><i class="fa fa-check"></i><b>B.9</b> SHEEP GOATS</a></li>
<li class="chapter" data-level="B.10" data-path="appendixDatasets.html"><a href="appendixDatasets.html#skeleton-actions"><i class="fa fa-check"></i><b>B.10</b> SKELETON ACTIONS</a></li>
<li class="chapter" data-level="B.11" data-path="appendixDatasets.html"><a href="appendixDatasets.html#smartphone-activities"><i class="fa fa-check"></i><b>B.11</b> SMARTPHONE ACTIVITIES</a></li>
<li class="chapter" data-level="B.12" data-path="appendixDatasets.html"><a href="appendixDatasets.html#smiles"><i class="fa fa-check"></i><b>B.12</b> SMILES</a></li>
<li class="chapter" data-level="B.13" data-path="appendixDatasets.html"><a href="appendixDatasets.html#students-mental-health"><i class="fa fa-check"></i><b>B.13</b> STUDENTS’ MENTAL HEALTH</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="citing-this-book.html"><a href="citing-this-book.html"><i class="fa fa-check"></i>Citing this Book</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Behavior Analysis with Machine Learning and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="deeplearning" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Predicting Behavior with Deep Learning</h1>
<p>Deep learning (DL) consists of a set of model architectures and algorithms with applications in supervised, semi-supervised, unsupervised and reinforcement learning. Deep learning is mainly based on artificial neural networks (ANNs). One of the main characteristics of DL is that the models are composed of several levels. Each level transforms its input into more abstract representations. For example, for an image recognition task, the first level corresponds to raw pixels, the next level transforms pixels into simple shapes like horizontal/vertical lines, diagonals, etc. The next level may abstract more complex shapes like wheels, windows, and so on; and the final level could detect if the image contains a car or a human, or maybe both.</p>
<p>Examples of DL architectures include deep neural networks (DNNs), convolutional neural networks (CNNs), recurrent neural networks (RNNs), and autoencoders, to name a few. One of the reasons of the success of DL is due to its flexibility to deal with different types of data and problems. For example, CNNs can be used for image classification, RNNs can be used for timeseries data, autoencoders can be used to generate new data, and so on. Another advantage of DL is that it is not always required to do feature engineering. That is, extract different features depending on the problem domain. Depending on the problem and the DL architecture, it is possible to feed the raw data (with some preprocessing) to the model. The model will then, automatically extract features at each level with an increasing level of abstraction. DL has achieved state-of-the-art results in many different tasks including speech recognition, image recognition, translation, etc. It has also been successfully applied to different types of behavior prediction.</p>
<p>In this chapter, an introduction to artificial neural networks will be presented. Next, we will see how to train deep models in R using Keras and TensorFlow. We will apply these models to behavior prediction tasks. This chapter also includes a section on convolutional neural networks and their application to behavior prediction.</p>
<div id="ann" class="section level2">
<h2><span class="header-section-number">8.1</span> Introduction to Artificial Neural Networks</h2>
<p>Artificial neural networks (ANNs) are mathematical models <em>inspired</em> by the brain. Here, I would like to emphasize the word <em>inspired</em> because ANNs do not model how a biological brain actually works. In fact, there is little knowledge about how the the brain works. ANNs are composed of <strong>units</strong> (also called <strong>neurons</strong> or <strong>nodes</strong>) and connections between units. Each unit can receive inputs from other units. Those inputs are processed inside the unit and produce an output. Typically, units are arranged into layers (as we will see later) and connections between units have an associated weight. Those weights are learned during training and they are the core elements that make a network behave in a certain way.</p>

<div class="rmdinfo">
For the rest of the chapter, I will mostly use the term <strong>units</strong> to refer to neurons/nodes. From time to time, I will use the term <strong>network</strong> to refer to artificial neural networks.
</div>

<p>Before going into details of how multi-layer ANNs work, let’s start with a very simple neural network consisting of a <strong>single unit</strong>. See Figure <a href="deeplearning.html#fig:nnPerceptron">8.1</a>. Even though this network only has one node, it is already composed of several interesting elements which are the basis of more complex networks. First, it has <span class="math inline">\(n\)</span> input variables <span class="math inline">\(x_1 \ldots x_n\)</span> which are real numbers. Second, the unit has a set of <span class="math inline">\(n\)</span> weights <span class="math inline">\(w_1 \ldots w_n\)</span> associated with each input. These weights can take real numbers as values. Finally, there is an output <span class="math inline">\(y&#39;\)</span> which is binary (it can take two values: <span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span>).</p>
<div class="figure" style="text-align: center"><span id="fig:nnPerceptron"></span>
<img src="images/nn_perceptron.png" alt="A neural network composed of a single unit (perceptron)." width="50%" />
<p class="caption">
Figure 8.1: A neural network composed of a single unit (perceptron).
</p>
</div>

<div class="rmdinfo">
This simple network consisting of one unit with a binary output is called a <strong>perceptron</strong> and was proposed by <span class="citation">Rosenblatt (<a href="#ref-rosenblatt1958" role="doc-biblioref">1958</a>)</span>.
</div>

<p>This single unit also known as <em>perceptron</em> is capable of making binary decisions based on the input and the weights. To get the final decision <span class="math inline">\(y&#39;\)</span> the inputs are multiplied by their corresponding weights and the results are summed. If the sum is greater than a given threshold, then the output is <span class="math inline">\(1\)</span> and <span class="math inline">\(0\)</span> otherwise. Formally:</p>
<p><span class="math display" id="eq:perceptron">\[\begin{equation}
  y&#39; =
 \begin{cases}
  1 &amp; \textit{if } \sum_{i}{w_i x_i &gt; t}, \\
  0 &amp; \textit{if } \sum_{i}{w_i x_i \leq t}
 \end{cases}
  \tag{8.1}
\end{equation}\]</span></p>
<p>We can use a perceptron to make important decisions in life. For example, suppose you need to decide whether or not to go to the movies. Assume this decision is based on two pieces of information:</p>
<ol style="list-style-type: decimal">
<li>You have money to pay the entrance (or not) and,</li>
<li>it is a horror movie (or not).</li>
</ol>
<p>There are two additional assumptions as well:</p>
<ol style="list-style-type: decimal">
<li>The movie theater only projects <span class="math inline">\(1\)</span> film.</li>
<li>You don’t like horror movies.</li>
</ol>
<p>This decision-making process can be modeled with the perceptron of Figure <a href="deeplearning.html#fig:nnMovies">8.2</a>. This perceptron has two binary input variables: <em>money</em> and <em>horror</em>. Each variable has an associated weight. Suppose there is a decision threshold of <span class="math inline">\(t=3\)</span>. Finally, there is a binary output: <span class="math inline">\(1\)</span> means you should go to the movies and <span class="math inline">\(0\)</span> indicates that you should not go.</p>

<div class="rmdinfo">
In this example, the weights (<span class="math inline">\(5\)</span> and <span class="math inline">\(-3\)</span>) and the threshold <span class="math inline">\(t=3\)</span> were already provided. The weights and the threshold are called the <em>parameters</em> of the network. Later, we will see how the parameters can be learned automatically from data.
</div>

<div class="figure" style="text-align: center"><span id="fig:nnMovies"></span>
<img src="images/nn_movies.png" alt="Perceptron to decide whether or not to go to the movies based on two input variables." width="50%" />
<p class="caption">
Figure 8.2: Perceptron to decide whether or not to go to the movies based on two input variables.
</p>
</div>
<p>Suppose that today was payday and the theater is projecting an action movie. Then, we can set the input variables <span class="math inline">\(money=1\)</span> and <span class="math inline">\(horror=0\)</span>. Now we want to decide if we should go to the movie theater or not. To get the final answer we can use Equation <a href="deeplearning.html#eq:perceptron">(8.1)</a>. This formula tells us that we need to multiply each input variable with their corresponding weights and add them:</p>
<p><span class="math display">\[\begin{align*}
(money)(5) + (horror)(-3)
\end{align*}\]</span></p>
<p>Substituting <em>money</em> and <em>horror</em> with their corresponding values:</p>
<p><span class="math display">\[\begin{align*}
(1)(5) + (0)(-3) = 5
\end{align*}\]</span></p>
<p>Since <span class="math inline">\(5 &gt; t\)</span> (remember the threshold <span class="math inline">\(t=3\)</span>), the final output will be <span class="math inline">\(1\)</span>, thus, the advice is to go to the movies. Let’s try the scenario when you have money but they are projecting a horror movie: <span class="math inline">\(money=1\)</span>, <span class="math inline">\(horror=1\)</span>.</p>
<p><span class="math display">\[\begin{align*}
(1)(5) + (1)(-3) = 2
\end{align*}\]</span></p>
<p>In this case, <span class="math inline">\(2 &lt; t\)</span> and the final output is <span class="math inline">\(0\)</span>. Even if you have money, you should not waste it on a movie that you know you most likely will not like. This process of applying operations to the inputs and obtaining the final result is called <strong>forward propagation</strong> because the inputs are ‘pushed’ all the way through the network (a single perceptron in this case). For bigger networks, the outputs of the current layer become the inputs of the next layer, and so on.</p>
<p>For convenience, a simplified version of Equation <a href="deeplearning.html#eq:perceptron">(8.1)</a> can be used. This alternative representation is useful because it provides flexibility to change the internals of the units (neurons) as we will see. The first simplification consists of representing the inputs and weights as vectors:</p>
<p><span class="math display">\[\begin{equation}
  \sum_{i}{w_i x_i} = \boldsymbol{w} \cdot \boldsymbol{x}
\end{equation}\]</span></p>
<p>The summation becomes a dot product between <span class="math inline">\(\boldsymbol{w}\)</span> and <span class="math inline">\(\boldsymbol{x}\)</span>. Next, the threshold <span class="math inline">\(t\)</span> can be moved to the left and renamed to <span class="math inline">\(b\)</span> which stands for <strong>bias</strong>. This is only notation but you can still think of the <em>bias</em> as a threshold.</p>
<p><span class="math display">\[\begin{equation}
  y&#39; = f(\boldsymbol{x}) =
 \begin{cases}
  1 &amp; \textit{if } \boldsymbol{w} \cdot \boldsymbol{x} + b &gt; 0, \\
  0 &amp; \textit{otherwise}
 \end{cases}
\end{equation}\]</span></p>
<p>The output <span class="math inline">\(y&#39;\)</span> is a function of <span class="math inline">\(\boldsymbol{x}\)</span> with <span class="math inline">\(\boldsymbol{w}\)</span> and <span class="math inline">\(b\)</span> as fixed parameters. One thing to note is that first, we are performing the operation <span class="math inline">\(\boldsymbol{w} \cdot \boldsymbol{x} + b\)</span> and then, another operation is applied to the result. In this case, it is a comparison. If the result is greater than <span class="math inline">\(0\)</span> the final output is <span class="math inline">\(1\)</span>. You can think of this second operation as another function. Call it <span class="math inline">\(g(x)\)</span>.</p>
<p><span class="math display" id="eq:nnUnit">\[\begin{equation}
  f(\boldsymbol{x}) = g(\boldsymbol{w} \cdot \boldsymbol{x} + b)
  \tag{8.2}
\end{equation}\]</span></p>
<p>In neural networks terminology, this <span class="math inline">\(g(x)\)</span> is known as the <strong>activation function</strong>. Its result indicates how much active this unit is based on its inputs. If the result is <span class="math inline">\(1\)</span>, it means that this unit is active. If the result is <span class="math inline">\(0\)</span>, it means the unit is inactive.</p>
<p>This new notation allows us to use different activation functions by substituting <span class="math inline">\(g(x)\)</span> with some other function in Equation <a href="deeplearning.html#eq:nnUnit">(8.2)</a>. In the case of the perceptron, the activation function <span class="math inline">\(g(x)\)</span> is the threshold function, which is known as the <em>step function</em>:</p>
<p><span class="math display" id="eq:stepfunc">\[\begin{equation}
  g(x) = step(x) =
 \begin{cases}
  1 &amp; \textit{if } x &gt; 0 \\
  0 &amp; \textit{if } x \leq 0
 \end{cases}
  \tag{8.3}
\end{equation}\]</span></p>
<p>Figure <a href="deeplearning.html#fig:nnStep">8.3</a> shows the plot of the step function.</p>
<div class="figure" style="text-align: center"><span id="fig:nnStep"></span>
<img src="images/nn_step.png" alt="The step function." width="100%" />
<p class="caption">
Figure 8.3: The step function.
</p>
</div>
<p>It is worth noting that perceptrons have two major limitations:</p>
<ol style="list-style-type: decimal">
<li>The output is binary.</li>
<li>Perceptrons are linear functions.</li>
</ol>
<p>The first limitation imposes some restrictions on its applicability. For example, a perceptron cannot be used to predict real-valued outputs which is a fundamental aspect for regression problems. The second limitation makes the perceptron only capable of solving linear problems. Figure <a href="deeplearning.html#fig:nnLinearity">8.4</a> graphically shows this limitation. In the first case, the outputs of the OR logical operator can be classified (separated) using a line. On the other hand, it is not possible to classify the output of the XOR function using a single line.</p>
<div class="figure" style="text-align: center"><span id="fig:nnLinearity"></span>
<img src="images/nn_linearity.png" alt="OR and the XOR logical operators." width="80%" />
<p class="caption">
Figure 8.4: OR and the XOR logical operators.
</p>
</div>
<p>To overcome those limitations, several modifications to the perceptron were introduced. This allows us to build models capable of solving more complex non-linear problems. One such modification is to change the activation function. Another improvement is to add the ability to have several layers of interconnected units. In the next section, two new types of units will be presented. Then, the following section will introduce neural networks also known as multilayer perceptrons which are more complex models built by connecting many units and arranging them into layers.</p>
<div id="sigmoid-and-relu-units" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Sigmoid and ReLU Units</h3>
<p>As previously mentioned, perceptrons have some limitations that restrict their applicability including the fact that they are linear models. In practice, problems are complex and most of them are non-linear. One way to overcome this limitation is to introduce non-linearities and this can be done by using a different type of activation function. Remember that a unit can be modeled as <span class="math inline">\(f(x) = g(wx+b)\)</span> where <span class="math inline">\(g(x)\)</span> is some activation function. For the perceptron, <span class="math inline">\(g(x)\)</span> is the <em>step function</em>. However, another practical limitation not mentioned before is that the step function can change abruptly from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span> and vice versa. Small changes in <span class="math inline">\(x\)</span>,<span class="math inline">\(w\)</span>, or <span class="math inline">\(b\)</span> can completely change the output. This is a problem during learning and inference time. Instead, we would prefer a smooth version of the step function, for example, the <strong>sigmoid function</strong> which is also known as the <strong>logistic function</strong>:</p>
<p><span class="math display" id="eq:sigmoidfunct">\[\begin{equation}
  s(x) = \frac{1}{1 + e^{-x}}
  \tag{8.4}
\end{equation}\]</span></p>
<p>This function has an ‘S’ shape (Figure <a href="deeplearning.html#fig:nnSigmoid">8.5</a>) and as opposed to a step function, this one is smooth. The range of this function is from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:nnSigmoid"></span>
<img src="images/nn_sigmoid.png" alt="Sigmoid function." width="100%" />
<p class="caption">
Figure 8.5: Sigmoid function.
</p>
</div>
<p>If we substitute the activation function in Equation <a href="deeplearning.html#eq:nnUnit">(8.2)</a> with the sigmoid function we get our <strong>sigmoid unit</strong>:</p>
<p><span class="math display" id="eq:sigmoidunit">\[\begin{equation}
  f(x) = \frac{1}{1 + e^{-(w \cdot x + b)}}
  \tag{8.5}
\end{equation}\]</span></p>
<p>Sigmoid units have been one of the most commonly used types of units when building bigger neural networks. Another advantage is that the outputs are real values that can be interpreted as probabilities. For instance, if we want to make binary decisions we can set a threshold. For example, if the output of the sigmoid unit is <span class="math inline">\(&gt; 0.5\)</span> then return a <span class="math inline">\(1\)</span>. Of course, that threshold would depend on the application. If we need more confidence about the result we can set a higher threshold.</p>
<p>In the last years, another type of unit has been successfully applied to train neural networks, the <strong>rectified linear unit</strong> or <strong>ReLU</strong> for short. The activation function of this unit is the rectifier function:</p>
<p><span class="math display" id="eq:rectifierfunct">\[\begin{equation}
  rectifier(x) =
 \begin{cases}
  0 &amp; \textit{if } x &lt; 0, \\
  x &amp; \textit{if } x \geq 0
 \end{cases}
  \tag{8.6}
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:nnRectified"></span>
<img src="images/nn_relu.png" alt="Rectifier function." width="100%" />
<p class="caption">
Figure 8.6: Rectifier function.
</p>
</div>
<p>This one is also called the <em>ramp function</em> and is one of the simplest non-linear functions and probably the most common one used in modern big neural networks. These units present several advantages, being among them, efficiency during training and inference time.</p>

<div class="rmdinfo">
In practice, many other activation functions are used but the most common ones are sigmoid and ReLU units. In the following link, you can find an extensive list of activation functions: <a href="https://en.wikipedia.org/wiki/Activation_function" class="uri">https://en.wikipedia.org/wiki/Activation_function</a>
</div>

<p>So far, we have been talking about <strong>single units</strong>. In the next section, we will see how these single units can be assembled to build bigger artificial neural networks.</p>
</div>
<div id="assembling-units-into-layers" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Assembling Units into Layers</h3>
<p>Perceptrons, sigmoid and ReLU units can be thought of as very simple neural networks. By connecting several units, one can build more complex neural networks. For historical reasons, neural networks are also called <strong>multilayer perceptrons</strong> regardless if the units are perceptrons or not. Typically, units are grouped into layers. Figure <a href="deeplearning.html#fig:nnExampleNN">8.7</a> shows an example neural network with <span class="math inline">\(3\)</span> layers. An <strong>input layer</strong> with <span class="math inline">\(3\)</span> nodes, a <strong>hidden layer</strong> with <span class="math inline">\(2\)</span> units and an <strong>output layer</strong> with <span class="math inline">\(1\)</span> unit.</p>
<div class="figure" style="text-align: center"><span id="fig:nnExampleNN"></span>
<img src="images/nn_example_nn.png" alt="Example neural network." width="50%" />
<p class="caption">
Figure 8.7: Example neural network.
</p>
</div>

<div class="rmdcaution">
In this type of diagram, the nodes represent units (perceptrons, sigmoids, ReLUs, etc.) except for the input layer. In the input layer, nodes represent input variables (input features). In the above example, the <span class="math inline">\(3\)</span> nodes in the input layer simply indicate that the network takes as input <span class="math inline">\(3\)</span> variables. In this layer, no operations are performed.
</div>

<p>This network only has one hidden layer. Hidden layers are called like that because they do not have direct contact with the external world. Finally, there is an output layer with a single unit. We could also have an output layer with more than one unit. Most of the time, we will have <strong>fully connected</strong> neural networks. That is, all units have incoming connections from all nodes in the previous layer (as in the previous example).</p>

<div class="rmdinfo">
For each specific problem, we need to define several building blocks for the network. For example, the number of layers, the number of units in each layer, the type of units (sigmoid, ReLU, etc.), and so on. This is known as the <strong>architecture</strong> of the network. Choosing a good architecture for a given problem is not a trivial task. It is advised to start with an architecture that was used to solve a similar problem and then fine-tune it for your specific problem. There exist some automatic ways to optimize the network architecture but those methods are out of the scope of this book.
</div>

<p>We already saw how a unit can produce a result based on the inputs by using <em>forward propagation</em>. For more complex networks the process is the same! Consider the network shown in Figure <a href="deeplearning.html#fig:nnForward">8.8</a>. It consists of two inputs and one output. It also has one hidden layer with <span class="math inline">\(2\)</span> units.</p>
<div class="figure" style="text-align: center"><span id="fig:nnForward"></span>
<img src="images/nn_forward.png" alt="Example of forward propagation." width="50%" />
<p class="caption">
Figure 8.8: Example of forward propagation.
</p>
</div>
<p>Each node is labeled as <span class="math inline">\(n_{l,n}\)</span> where <span class="math inline">\(l\)</span> is the layer and <span class="math inline">\(n\)</span> is the unit number.
The two input values are <span class="math inline">\(1\)</span> and <span class="math inline">\(0.5\)</span>. They could be temperature measurements, for example. Each edge has an associated weight. For simplicity, let’s assume that the activation function of the units is the identity function <span class="math inline">\(g(x)=x\)</span>. The bold underlined number inside the nodes of the hidden and output layers are the biases. Here we assume that the network is already trained (later we will see how those weights and biases are learned). To get the final result, for each node, its inputs are multiplied by their corresponding weights and added. Then, the bias is added. Next, the activation function is applied. In this case, it is just the identify function (returns the same value). The outputs of the nodes in the hidden layer become the inputs of the next layer and so on.</p>
<p>In this example, first we need to compute the outputs of nodes <span class="math inline">\(n_{2,1}\)</span> and <span class="math inline">\(n_{2,2}\)</span>:</p>
<p>output of <span class="math inline">\(n_{2,1} = (1)(2) + (0.5)(1) + 1 = 3.5\)</span></p>
<p>output of <span class="math inline">\(n_{2,2} = (1)(-3) + (0.5)(5) + 0 = -0.5\)</span></p>
<p>Finally, we can compute the output of the last node using the outputs of the previous nodes:</p>
<p>output of <span class="math inline">\(n_{3,1} = (3.5)(1) + (-0.5)(-1) + 3 = 7\)</span>.</p>
</div>
<div id="deep-neural-networks" class="section level3">
<h3><span class="header-section-number">8.1.3</span> Deep Neural Networks</h3>
<p>By increasing the number of layers and the number of units in each layer, one can build more complex networks. But what is a deep neural network (DNN)? It is not a strict rule but some people say that a network with more than <span class="math inline">\(2\)</span> hidden layers is a deep network. Yes, that’s all it takes to build a DNN! Figure <a href="deeplearning.html#fig:nnDNN">8.9</a> shows an example of a deep neural network.</p>
<div class="figure" style="text-align: center"><span id="fig:nnDNN"></span>
<img src="images/nn_dnn.png" alt="Example of a deep neural network." width="50%" />
<p class="caption">
Figure 8.9: Example of a deep neural network.
</p>
</div>
<p>A DNN has nothing special compared to a traditional neural network except that it has many layers. One of the reasons why they became so popular until recent years is because before it was not possible to efficiently train them. With the advent of specialized hardware like graphics processing units (GPUs), it is now possible to efficiently train big DNNs. The introduction of ReLU units was also a key factor that allowed the training of even bigger networks. The availability of big quantities of data was another key factor that allowed the development of deep learning technologies. Note that deep learning is not limited to DNNs but it also encompasses other types of architectures like convolutional networks and recurrent neural networks, to name a few. Convolutional layers will be covered later in this chapter.</p>
</div>
<div id="learning-the-parameters" class="section level3">
<h3><span class="header-section-number">8.1.4</span> Learning the Parameters</h3>
<p>We have seen how <em>forward propagation</em> can be used at inference time to compute the output of the network based on the input values. In the previous examples, we assumed that the network’s parameters (weights and biases) were already learned. In practice, you most likely will be using libraries and frameworks to build and train neural networks. Later in this chapter, I will show you how to use TensorFlow and Keras within R. Before that, I will show you how networks’ parameters are learned and how we can code and train a very simple network from scratch.</p>
<p>Back to the problem, the objective is to find the parameters’ values based on training data such that the predicted result for any input data point is as close as possible as the true value. Put in other words, we want to find the parameters’ values that reduce the network´s prediction error.</p>
<p>One way to estimate the network’s error is by computing the squared difference between the prediction <span class="math inline">\(y&#39;\)</span> and the real value <span class="math inline">\(y\)</span>: <span class="math inline">\(error = (y&#39; - y)^2\)</span>. This is how the error can be computed for a single training data point. The error function is typically called the <strong>loss function</strong> and denoted by <span class="math inline">\(L(\theta)\)</span> where <span class="math inline">\(\theta\)</span> represents the parameters of the network (weights and biases). In this example the loss function is <span class="math inline">\(L(\theta)=(y&#39;- y)^2\)</span>.</p>
<p>If there is more than one training data point (which is often the case), the loss function is just the average of the individual squared differences which is known as the <strong>mean squared error (MSE)</strong>:</p>
<p><span class="math display" id="eq:lossMSE">\[\begin{equation}
  L(\theta) = \frac{1}{N} \sum_{n=1}^N{(y&#39;_n - y_n)^2}
  \tag{8.7}
\end{equation}\]</span></p>

<div class="rmdinfo">
The mean squared error (MSE) loss function is commonly used for regression problems. For classification problems, the average cross-entropy loss function is usually preferred (covered later in this chapter).
</div>

<p>The problem of finding the best parameters can be formulated as an optimization problem, that is, find the optimal parameters such that the loss function is minimized. This is the learning/training phase of a neural network. Formally, this can be stated as:</p>
<p><span class="math display" id="eq:minLoss">\[\begin{equation}
  \operatorname*{arg min}_{\theta} L(\theta)
  \tag{8.8}
\end{equation}\]</span></p>
<p>This notation means: find and return the weights and biases that make the loss function be as small as possible.</p>
<p>The most common method to train neural networks is called <strong>gradient descent</strong>. The algorithm updates the parameters in an iterative fashion based on the loss. This algorithm is suitable for complex functions with millions of parameters.</p>
<p>Suppose there is a network with only <span class="math inline">\(1\)</span> weight and no bias with MSE as loss function (Equation <a href="deeplearning.html#eq:lossMSE">(8.7)</a>. Figure <a href="deeplearning.html#fig:nnGD">8.10</a> shows a plot of the loss function. This is a quadratic function that only depends on the value of <span class="math inline">\(w\)</span>. The task is to find the <span class="math inline">\(w\)</span> where the function is at its minimum.</p>
<div class="figure" style="text-align: center"><span id="fig:nnGD"></span>
<img src="images/nn_gd.png" alt="Gradient descent in action." width="50%" />
<p class="caption">
Figure 8.10: Gradient descent in action.
</p>
</div>
<p>Gradient descent starts by assigning <span class="math inline">\(w\)</span> a random value. Then, at each step and based on the error, <span class="math inline">\(w\)</span> is updated in the direction that minimizes the loss function. In the previous figure, the <strong>global minimum</strong> is found after <span class="math inline">\(5\)</span> iterations. In practice, loss functions are more complex and have many <strong>local minima</strong> (Figure <a href="deeplearning.html#fig:nnLM">8.11</a>). For complex functions, it is difficult to find a global minimum but gradient descent can find a local minimum that is good enough.</p>
<div class="figure" style="text-align: center"><span id="fig:nnLM"></span>
<img src="images/nn_lm.png" alt="Function with 1 global minimum and several local minima." width="50%" />
<p class="caption">
Figure 8.11: Function with 1 global minimum and several local minima.
</p>
</div>
<p>But in what direction and how much is <span class="math inline">\(w\)</span> moved in each iteration? The direction and magnitude are estimated by computing the derivative of the loss function with respect to the weight <span class="math inline">\(\frac{\partial L}{\partial w}\)</span>. The derivative is also called the gradient and denoted by <span class="math inline">\(\nabla L\)</span>. The iterative gradient descent procedure is listed below:</p>
<div class="line-block"><strong>loop</strong> until convergence or max iterations (<em>epochs</em>)<br />
  <strong>for each</strong> <span class="math inline">\(w_i\)</span> in <span class="math inline">\(W\)</span> <strong>do:</strong><br />
     <span class="math inline">\(w_i = w_i - \alpha \frac{\partial L(W)}{\partial w_i}\)</span><br />
</div>
<p>The outer loop is run until the algorithm converges or until a predefined number of iterations is reached. Each iteration is also called an <strong>epoch</strong>. Each weight is updated with the rule: <span class="math inline">\(w_i = w_i - \alpha \frac{\partial L(W)}{\partial w_i}\)</span>. The derivative part will give us the direction and magnitude. The <span class="math inline">\(\alpha\)</span> is called the <strong>learning rate</strong> and it controls how ‘fast’ we move. The learning rate is a constant defined by the user, thus, it is a <strong>hyperparameter</strong>. A high learning rate can cause the algorithm to miss the local minima and the loss can start to increase. A small learning rate will cause the algorithm to take more time to converge. Figure <a href="deeplearning.html#fig:nnLR">8.12</a> illustrates both scenarios.</p>
<div class="figure" style="text-align: center"><span id="fig:nnLR"></span>
<img src="images/nn_lr.png" alt="a) Big learning rate. b) Small learning rate." width="100%" />
<p class="caption">
Figure 8.12: a) Big learning rate. b) Small learning rate.
</p>
</div>
<p>Selecting an appropriate learning rate will depend on the application but common values are between <span class="math inline">\(0.0001\)</span> and <span class="math inline">\(0.05\)</span>.</p>
<p>Let’s see how gradient descent works with a step by step example. Consider a very simple neural network consisting of an input layer with only one input feature and an output layer with one unit. To make it even simpler, the activation function of the output unit is the identity function <span class="math inline">\(f(x)=x\)</span>. Assume that as training data we have a single data point. Figure <a href="deeplearning.html#fig:nnStepExample">8.13</a> shows the simple network and the training data. The training data point only has one input variable (<span class="math inline">\(x\)</span>) and an output (<span class="math inline">\(y\)</span>). We want to train this network such that it can make predictions on new data points. The training point has an input feature of <span class="math inline">\(x=3\)</span> and the expected output is <span class="math inline">\(y=1.5\)</span>. For this particular training point, it seems that the output is equal to the input divided by <span class="math inline">\(2\)</span>. Thus, based on this single training data point the network should learn how to divide any other input by <span class="math inline">\(2\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:nnStepExample"></span>
<img src="images/nn_step_example.png" alt="a) A simple neural network consisting of one unit. b) The training data with only one row." width="100%" />
<p class="caption">
Figure 8.13: a) A simple neural network consisting of one unit. b) The training data with only one row.
</p>
</div>
<p>Before we start the training we need to define <span class="math inline">\(3\)</span> things:</p>
<ol style="list-style-type: decimal">
<li><p>The loss function. This is a regression problem so we can use the MSE. Since there is a single data point our loss function becomes <span class="math inline">\(L(w)=(y&#39; - y)^2\)</span>. Here, <span class="math inline">\(y\)</span> is the ground truth output value and <span class="math inline">\(y&#39;\)</span> is the predicted value. We know how to make predictions using forward propagation. In this case, it is the product between the input value and the single weight, and the activation function has no effect (it returns the same value as its input). We can rewrite the loss function as <span class="math inline">\(L(w)=(xw - y)^2\)</span>.</p></li>
<li><p>We need to define a learning rate. For now, we can set it to <span class="math inline">\(\alpha = 0.05\)</span>.</p></li>
<li><p>The weights need to be initialized at random. Let’s assume the single weight is ‘randomly’ initialized with <span class="math inline">\(w=2\)</span>.</p></li>
</ol>
<p>Now we use gradient descent to iteratively update the weight. Remember that the updating rule is:</p>
<p><span class="math display">\[\begin{equation}
  w = w - \alpha \frac{\partial L(w)}{\partial w}
\end{equation}\]</span></p>
<p>The partial derivative of the loss function with respect to <span class="math inline">\(w\)</span> is:</p>
<p><span class="math display">\[\begin{equation}
  \frac{\partial L(w)}{\partial w} = 2x(xw - y)
\end{equation}\]</span></p>
<p>If we substitute the derivative in the updating rule we get:</p>
<p><span class="math display">\[\begin{equation}
  w = w - \alpha 2x(xw - y)
\end{equation}\]</span></p>
<p>We already know that <span class="math inline">\(\alpha=0.05\)</span>, the input value is <span class="math inline">\(x=3\)</span>, the output is <span class="math inline">\(y=1.5\)</span> and the initial weight is <span class="math inline">\(w=2\)</span>. So we can start updating <span class="math inline">\(w\)</span>. Figure <a href="deeplearning.html#fig:nnTrainProgress">8.14</a> shows the initial state (iteration 0) and <span class="math inline">\(3\)</span> additional iterations. In the initial state, <span class="math inline">\(w=2\)</span> and with that weight the loss is <span class="math inline">\(20.25\)</span>. In iteration <span class="math inline">\(1\)</span>, the weight is updated and now its value is <span class="math inline">\(0.65\)</span>. With this new weight, the loss is <span class="math inline">\(0.2025\)</span>. That was a substantial reduction in the error! After three iterations we see that the final weight is <span class="math inline">\(w=0.501\)</span> and the loss is very close to zero.</p>
<div class="figure" style="text-align: center"><span id="fig:nnTrainProgress"></span>
<img src="images/nn_train_progress.png" alt="First 3 gradient descent iterations (epochs)." width="100%" />
<p class="caption">
Figure 8.14: First 3 gradient descent iterations (epochs).
</p>
</div>
<p>Now, we can start doing predictions with our very simple neural network! To do so, we use forward propagation on the new input data using the learned weight <span class="math inline">\(w=0.501\)</span>. Figure <a href="deeplearning.html#fig:nnExamplePredictions">8.15</a> shows the predictions on new training data points that were never seen by the network before.</p>
<div class="figure" style="text-align: center"><span id="fig:nnExamplePredictions"></span>
<img src="images/nn_example_predictions.png" alt="Example predictions on new data points." width="60%" />
<p class="caption">
Figure 8.15: Example predictions on new data points.
</p>
</div>
<p>Even though the predictions are not perfect, they are very close to the expected value (division by <span class="math inline">\(2\)</span>) considering that the network is very simple and was only trained with a single data point and for only <span class="math inline">\(3\)</span> epochs!</p>
<p>If the training set has more than one data point, then we need to compute the derivative of each point and accumulate them (the derivative of a sum is equal to the sum of the derivatives). In the previous example, the update rule becomes:</p>
<p><span class="math display">\[\begin{equation}
  w = w - \alpha \sum_{i=1}^N{2x_i(x_i w - y)}
\end{equation}\]</span></p>
<p>This means that before updating a weight, first, we need to compute the derivative for each point and add them. This needs to be done for every parameter in the network. Thus, one <strong>epoch</strong> is a pass through all training points and all parameters.</p>
</div>
<div id="parameter-learning-example-in-r" class="section level3">
<h3><span class="header-section-number">8.1.5</span> Parameter Learning Example in R</h3>

<div class="rmdfolder">
<code>gradient_descent.R</code>
</div>

<p>In the previous section, we went step by step to train a neural network with a single unit and with a single training data point. Here, we will see how we can implement that simple network in R but when we have more training data. The code can be found in the script <code>gradient_descent.R</code>.</p>
<p>This code implements the same network as the previous example. That is, one neuron, one input, no bias, and activation function <span class="math inline">\(f(x) = x\)</span>. We start by creating a sample training set with <span class="math inline">\(3\)</span> points. Again, the output is the input divided by <span class="math inline">\(2\)</span>.</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="deeplearning.html#cb151-1"></a>train_set &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="fl">3.0</span>,<span class="fl">4.0</span>,<span class="fl">1.0</span>), <span class="dt">y =</span> <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="fl">2.0</span>, <span class="fl">0.5</span>))</span>
<span id="cb151-2"><a href="deeplearning.html#cb151-2"></a><span class="co"># Print the train set.</span></span>
<span id="cb151-3"><a href="deeplearning.html#cb151-3"></a><span class="kw">print</span>(train_set)</span>
<span id="cb151-4"><a href="deeplearning.html#cb151-4"></a><span class="co">#&gt;   x   y</span></span>
<span id="cb151-5"><a href="deeplearning.html#cb151-5"></a><span class="co">#&gt; 1 3 1.5</span></span>
<span id="cb151-6"><a href="deeplearning.html#cb151-6"></a><span class="co">#&gt; 2 4 2.0</span></span>
<span id="cb151-7"><a href="deeplearning.html#cb151-7"></a><span class="co">#&gt; 3 1 0.5</span></span></code></pre></div>
<p>Then we need to implement <span class="math inline">\(3\)</span> functions: forward propagation, the loss function, and the derivative of the loss function.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="deeplearning.html#cb152-1"></a><span class="co"># Forward propagation w*x</span></span>
<span id="cb152-2"><a href="deeplearning.html#cb152-2"></a>fp &lt;-<span class="st"> </span><span class="cf">function</span>(w, x){</span>
<span id="cb152-3"><a href="deeplearning.html#cb152-3"></a>    <span class="kw">return</span>(w <span class="op">*</span><span class="st"> </span>x)</span>
<span id="cb152-4"><a href="deeplearning.html#cb152-4"></a>}</span>
<span id="cb152-5"><a href="deeplearning.html#cb152-5"></a></span>
<span id="cb152-6"><a href="deeplearning.html#cb152-6"></a><span class="co"># Loss function (y - y&#39;)^2</span></span>
<span id="cb152-7"><a href="deeplearning.html#cb152-7"></a>loss &lt;-<span class="st"> </span><span class="cf">function</span>(w, x, y){</span>
<span id="cb152-8"><a href="deeplearning.html#cb152-8"></a>  predicted &lt;-<span class="st"> </span><span class="kw">fp</span>(w, x) <span class="co"># This is y&#39;</span></span>
<span id="cb152-9"><a href="deeplearning.html#cb152-9"></a>  <span class="kw">return</span>((y <span class="op">-</span><span class="st"> </span>predicted)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb152-10"><a href="deeplearning.html#cb152-10"></a>}</span>
<span id="cb152-11"><a href="deeplearning.html#cb152-11"></a></span>
<span id="cb152-12"><a href="deeplearning.html#cb152-12"></a><span class="co"># Derivative of the loss function. 2x(xw - y)</span></span>
<span id="cb152-13"><a href="deeplearning.html#cb152-13"></a>derivative &lt;-<span class="st"> </span><span class="cf">function</span>(w, x, y){</span>
<span id="cb152-14"><a href="deeplearning.html#cb152-14"></a>  <span class="kw">return</span>(<span class="fl">2.0</span> <span class="op">*</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>((x <span class="op">*</span><span class="st"> </span>w) <span class="op">-</span><span class="st"> </span>y))</span>
<span id="cb152-15"><a href="deeplearning.html#cb152-15"></a>}</span></code></pre></div>
<p>Now we are all set to implement the <code>gradient.descent()</code> function. The first parameter is the train set, the second parameter is the learning rate <span class="math inline">\(\alpha\)</span> and the last parameter is the number of epochs. The initial weight is initialized to some ‘random’ number (selected manually here for the sake of the example). The function returns the final learned weight.</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="deeplearning.html#cb153-1"></a><span class="co"># Gradient descent.</span></span>
<span id="cb153-2"><a href="deeplearning.html#cb153-2"></a>gradient.descent &lt;-<span class="st"> </span><span class="cf">function</span>(train_set, <span class="dt">lr =</span> <span class="fl">0.01</span>, <span class="dt">epochs =</span> <span class="dv">5</span>){</span>
<span id="cb153-3"><a href="deeplearning.html#cb153-3"></a>  </span>
<span id="cb153-4"><a href="deeplearning.html#cb153-4"></a>  w =<span class="st"> </span><span class="fl">-2.5</span> <span class="co"># Initialize weight at &#39;random&#39;</span></span>
<span id="cb153-5"><a href="deeplearning.html#cb153-5"></a>  </span>
<span id="cb153-6"><a href="deeplearning.html#cb153-6"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>epochs){</span>
<span id="cb153-7"><a href="deeplearning.html#cb153-7"></a>    derivative.sum &lt;-<span class="st"> </span><span class="fl">0.0</span></span>
<span id="cb153-8"><a href="deeplearning.html#cb153-8"></a>    loss.sum &lt;-<span class="st"> </span><span class="fl">0.0</span></span>
<span id="cb153-9"><a href="deeplearning.html#cb153-9"></a>    </span>
<span id="cb153-10"><a href="deeplearning.html#cb153-10"></a>    <span class="co"># Iterate each data point in train_set.</span></span>
<span id="cb153-11"><a href="deeplearning.html#cb153-11"></a>    <span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_set)){</span>
<span id="cb153-12"><a href="deeplearning.html#cb153-12"></a>      point &lt;-<span class="st"> </span>train_set[j, ]</span>
<span id="cb153-13"><a href="deeplearning.html#cb153-13"></a>      </span>
<span id="cb153-14"><a href="deeplearning.html#cb153-14"></a>      derivative.sum &lt;-<span class="st"> </span>derivative.sum <span class="op">+</span><span class="st"> </span><span class="kw">derivative</span>(w, point<span class="op">$</span>x, point<span class="op">$</span>y)</span>
<span id="cb153-15"><a href="deeplearning.html#cb153-15"></a>      </span>
<span id="cb153-16"><a href="deeplearning.html#cb153-16"></a>      loss.sum &lt;-<span class="st"> </span>loss.sum <span class="op">+</span><span class="st"> </span><span class="kw">loss</span>(w, point<span class="op">$</span>x, point<span class="op">$</span>y)</span>
<span id="cb153-17"><a href="deeplearning.html#cb153-17"></a>    }</span>
<span id="cb153-18"><a href="deeplearning.html#cb153-18"></a>    </span>
<span id="cb153-19"><a href="deeplearning.html#cb153-19"></a>    <span class="co"># Update weight.</span></span>
<span id="cb153-20"><a href="deeplearning.html#cb153-20"></a>    w &lt;-<span class="st">  </span>w <span class="op">-</span><span class="st"> </span>lr <span class="op">*</span><span class="st"> </span>derivative.sum</span>
<span id="cb153-21"><a href="deeplearning.html#cb153-21"></a>    </span>
<span id="cb153-22"><a href="deeplearning.html#cb153-22"></a>    <span class="co"># mean squared error (MSE)</span></span>
<span id="cb153-23"><a href="deeplearning.html#cb153-23"></a>    mse &lt;-<span class="st"> </span>loss.sum <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(train_set)</span>
<span id="cb153-24"><a href="deeplearning.html#cb153-24"></a>    </span>
<span id="cb153-25"><a href="deeplearning.html#cb153-25"></a>    <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&quot;epoch: &quot;</span>, i, <span class="st">&quot; loss: &quot;</span>,</span>
<span id="cb153-26"><a href="deeplearning.html#cb153-26"></a>                 <span class="kw">formatC</span>(mse, <span class="dt">digits =</span> <span class="dv">8</span>, <span class="dt">format =</span> <span class="st">&quot;f&quot;</span>),</span>
<span id="cb153-27"><a href="deeplearning.html#cb153-27"></a>                 <span class="st">&quot; w = &quot;</span>, <span class="kw">formatC</span>(w, <span class="dt">digits =</span> <span class="dv">5</span>, <span class="dt">format =</span> <span class="st">&quot;f&quot;</span>)))</span>
<span id="cb153-28"><a href="deeplearning.html#cb153-28"></a>  }</span>
<span id="cb153-29"><a href="deeplearning.html#cb153-29"></a>  </span>
<span id="cb153-30"><a href="deeplearning.html#cb153-30"></a>  <span class="kw">return</span>(w)</span>
<span id="cb153-31"><a href="deeplearning.html#cb153-31"></a>}</span></code></pre></div>
<p>Now, let’s train the network with a learning rate of <span class="math inline">\(0.01\)</span> and for <span class="math inline">\(10\)</span> epochs. This function will print for each epoch, the loss and the current weight.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="deeplearning.html#cb154-1"></a><span class="co">#### Train the 1 unit network with gradient descent ####</span></span>
<span id="cb154-2"><a href="deeplearning.html#cb154-2"></a>lr &lt;-<span class="st"> </span><span class="fl">0.01</span> <span class="co"># set learning rate.</span></span>
<span id="cb154-3"><a href="deeplearning.html#cb154-3"></a></span>
<span id="cb154-4"><a href="deeplearning.html#cb154-4"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb154-5"><a href="deeplearning.html#cb154-5"></a></span>
<span id="cb154-6"><a href="deeplearning.html#cb154-6"></a><span class="co"># Run gradient decent to find the optimal weight.</span></span>
<span id="cb154-7"><a href="deeplearning.html#cb154-7"></a>learned_w =<span class="st"> </span><span class="kw">gradient.descent</span>(train_set, lr, <span class="dt">epochs =</span> <span class="dv">10</span>)</span>
<span id="cb154-8"><a href="deeplearning.html#cb154-8"></a></span>
<span id="cb154-9"><a href="deeplearning.html#cb154-9"></a><span class="co">#&gt; [1] &quot;epoch: 1 loss: 78.00000000 w = -0.94000&quot;</span></span>
<span id="cb154-10"><a href="deeplearning.html#cb154-10"></a><span class="co">#&gt; [1] &quot;epoch: 2 loss: 17.97120000 w = -0.19120&quot;</span></span>
<span id="cb154-11"><a href="deeplearning.html#cb154-11"></a><span class="co">#&gt; [1] &quot;epoch: 3 loss: 4.14056448 w = 0.16822&quot;</span></span>
<span id="cb154-12"><a href="deeplearning.html#cb154-12"></a><span class="co">#&gt; [1] &quot;epoch: 4 loss: 0.95398606 w = 0.34075&quot;</span></span>
<span id="cb154-13"><a href="deeplearning.html#cb154-13"></a><span class="co">#&gt; [1] &quot;epoch: 5 loss: 0.21979839 w = 0.42356&quot;</span></span>
<span id="cb154-14"><a href="deeplearning.html#cb154-14"></a><span class="co">#&gt; [1] &quot;epoch: 6 loss: 0.05064155 w = 0.46331&quot;</span></span>
<span id="cb154-15"><a href="deeplearning.html#cb154-15"></a><span class="co">#&gt; [1] &quot;epoch: 7 loss: 0.01166781 w = 0.48239&quot;</span></span>
<span id="cb154-16"><a href="deeplearning.html#cb154-16"></a><span class="co">#&gt; [1] &quot;epoch: 8 loss: 0.00268826 w = 0.49155&quot;</span></span>
<span id="cb154-17"><a href="deeplearning.html#cb154-17"></a><span class="co">#&gt; [1] &quot;epoch: 9 loss: 0.00061938 w = 0.49594&quot;</span></span>
<span id="cb154-18"><a href="deeplearning.html#cb154-18"></a><span class="co">#&gt; [1] &quot;epoch: 10 loss: 0.00014270 w = 0.49805&quot;</span></span></code></pre></div>
<p>From the output, we can see that the loss decreases as the weight is updated. The final value of the weight at iteration <span class="math inline">\(10\)</span> is <span class="math inline">\(0.49805\)</span>. We can now make predictions on new data.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="deeplearning.html#cb155-1"></a><span class="co"># Make predictions on new data using the learned weight.</span></span>
<span id="cb155-2"><a href="deeplearning.html#cb155-2"></a><span class="kw">fp</span>(learned_w, <span class="dv">7</span>)</span>
<span id="cb155-3"><a href="deeplearning.html#cb155-3"></a><span class="co">#&gt; [1] 3.486366</span></span>
<span id="cb155-4"><a href="deeplearning.html#cb155-4"></a></span>
<span id="cb155-5"><a href="deeplearning.html#cb155-5"></a><span class="kw">fp</span>(learned_w, <span class="dv">-88</span>)</span>
<span id="cb155-6"><a href="deeplearning.html#cb155-6"></a><span class="co">#&gt; [1] -43.8286</span></span></code></pre></div>
<p>Now, you can try to change the training set to make the network learn a different arithmetic operation!</p>
<p>In the previous example, we considered a very simple neural network consisting of a single unit. In this case, the partial derivative with respect to the single weight was calculated directly. For bigger networks with more layers and activations, the final output becomes a composition of functions. That is, the activation values of a layer <span class="math inline">\(l\)</span> depend on its weights which are also affected by the previous layer’s <span class="math inline">\(l-1\)</span> weights and so on. So, the derivatives (gradients) can be computed using the chain rule <span class="math inline">\(f(g(x))&#39; = f&#39;(g(x)) \cdot g&#39;(x)\)</span>. This can be performed efficiently by an algorithm known as <strong>backpropagation</strong>.</p>
<blockquote>
<p>“What backpropagation actually lets us do is compute the partial derivatives <span class="math inline">\(\partial C_x / \partial w\)</span> and <span class="math inline">\(\partial C_x / \partial b\)</span> for a single training example.” (Michael Nielsen, 2019)<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>.</p>
</blockquote>
<p>Here, <span class="math inline">\(C\)</span> refers to the loss function which is also called the cost function. In modern deep learning libraries like TensorFlow, this procedure is efficiently implemented with a computational graph. If you want to learn the details about backpropagation I recommend you to check this post by DEEPLIZARD (<a href="https://deeplizard.com/learn/video/XE3krf3CQls" class="uri">https://deeplizard.com/learn/video/XE3krf3CQls</a>) which consists of <span class="math inline">\(5\)</span> parts including videos.</p>
</div>
<div id="stochastic-gradient-descent" class="section level3">
<h3><span class="header-section-number">8.1.6</span> Stochastic Gradient Descent</h3>
<p>We have seen how gradient descent iterates over all training points before updating each parameter. To recall, an epoch is one pass through all parameters and for each parameter, the derivative with each training point needs to be computed. If the training set consists of thousands or millions of points this method becomes very time-consuming. Furthermore, in practice neural networks do not have one or two parameters but thousands or millions. In those cases, the training can be done more efficiently by using <strong>stochastic gradient descent (SGD)</strong>. This method adds two main modifications to the classic gradient descent:</p>
<ol style="list-style-type: decimal">
<li>At the beginning, the training set is shuffled (this is the stochastic part). This is necessary for the method to work.</li>
<li>The training set is divided into <span class="math inline">\(b\)</span> batches with <span class="math inline">\(m\)</span> data points each. This <span class="math inline">\(m\)</span> is known as the <strong>batch size</strong> and is a hyperparameter that we need to define.</li>
</ol>
<p>Then, at each epoch all batches are iterated and the parameters are updated based on each batch and not the entire training set, for example:</p>
<p><span class="math display">\[\begin{equation}
  w = w - \alpha \sum_{i=1}^m{2x_i(x_i w - y)}
\end{equation}\]</span></p>
<p>Again, an epoch is one pass through all parameters and all batches. Now you may be wondering why this method is more efficient if an epoch still involves the same number of operations but they are split into chunks. Part of this is because since the parameter updates are more frequent, the loss also improves quicker. Another reason is that the operations within each batch can be optimized and performed in parallel, for example, by using a GPU. One thing to note is that each update is based on less information by only using <span class="math inline">\(m\)</span> points instead of the entire data set. This can introduce some noise in the learning but at the same time this can help to get out of local minima. In practice, SGD needs more epochs to converge compared to gradient descent but overall, it will take less time. From now on, this is the method we will use to train our networks.</p>

<div class="rmdinfo">
Typical batch sizes are: <span class="math inline">\(4\)</span>,<span class="math inline">\(8\)</span>,<span class="math inline">\(16\)</span>,<span class="math inline">\(32\)</span>,<span class="math inline">\(64\)</span>,<span class="math inline">\(128\)</span>, etc. There is a divided opinion in this respect. Some say it’s better to choose small batch sizes but others say the bigger the better. For any particular problem, it is difficult to say what batch size is the optimal. Usually, one needs to choose the batch size empirically by trying different ones.
</div>


<div class="rmdcaution">
Be aware that when using GPUs, a big batch size can cause out of memory errors since the GPU may not have enough memory to allocate the batch.
</div>

</div>
</div>
<div id="keras-and-tensorflow-with-r" class="section level2">
<h2><span class="header-section-number">8.2</span> Keras and TensorFlow with R</h2>
<p>TensorFlow<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> is an open-source computational library used mainly for machine learning and more specifically, for deep learning. It has many available tools and extensions to perform a wide variety of tasks such as data pre-processing, model optimization, reinforcement learning, probabilistic reasoning, to name a few. TensorFlow is very flexible and is used for research, development, and in production environments. It provides an API that contains the necessary building blocks to build different types of neural networks including CNNs, Autoencoders, Recurrent Neural Networks, etc. It has two main versions. A CPU version and a GPU version. The latter allows the execution of programs by taking advantage of the computational power of graphic processing units. This makes training models much faster. Despite all this flexibility and power, it can take some time to learn the basics. Sometimes you need a way to build and test machine learning models in a simple way, for example, when trying new ideas or prototyping. Fortunately, there exists an interface to TensorFlow called Keras<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>.</p>
<p>Keras offers an API that abstracts many of the TensorFlow’s details making it easier to build and train machine learning models. Keras is what I will use when building deep learning models in this book. Keras does not only provide an interface to TensorFlow but also to other deep learning engines such as Theano<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>, Microsoft Cognitive Toolkit<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>, etc. Keras was developed by François Chollet and later, it was integrated with TensorFlow.</p>
<p>Most of the time its API should be enough to do common tasks and it provides ways to add extensions in case that is not enough. In this book, we will use only a subset of all the available Keras functions, but that will be enough for our purposes of building models to predict behaviors. If you want to learn more about Keras, I recommend you the book <em>“Deep Learning with R”</em> by <span class="citation">Chollet and Allaire (<a href="#ref-Chollet2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Examples in this book will use Keras with TensorFlow as the backend. In R, we can access Keras through the <code>keras</code> package <span class="citation">(Allaire and Chollet <a href="#ref-keras" role="doc-biblioref">2019</a>)</span>.</p>

<div class="rmdinfo">
Instructions on how to install Keras and TensorFlow can be found in Appendix <a href="appendixInstall.html#appendixInstall">A</a>. At this point, I would recommend you to install them since the next section will make use of Keras.
</div>

<p>In the next section, we will start with a simple model built with Keras and the following examples will introduce more functions. By the end of this chapter, you will be able to build and train efficient deep neural networks including convolutional neural networks.</p>
<div id="keras-example" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Keras Example</h3>

<div class="rmdfolder">
<code>keras_simple_network.R</code>
</div>

<p>If you haven’t already installed Keras and TensorFlow, I would recommend you to do so at this point. Instructions on how to install the required software can be found in Appendix <a href="appendixInstall.html#appendixInstall">A</a>.</p>
<p>In the previous section, I showed you how to implement gradient descent in R (see <code>gradient_descent.R</code>). Now, I will show you how to implement the same simple network but using Keras. To recall, our network has one unit, one input, one output, and no bias. The code can be found in the script <code>keras_simple_network.R</code>. First, the <code>keras</code> library is loaded and a sample training set is created. Then, the function <code>keras_model_sequential()</code> is used to instantiate a new empty model. It is called sequential because it is composed of a sequence of layers. At this point it does not have any layers yet.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="deeplearning.html#cb156-1"></a><span class="kw">library</span>(keras)</span>
<span id="cb156-2"><a href="deeplearning.html#cb156-2"></a></span>
<span id="cb156-3"><a href="deeplearning.html#cb156-3"></a><span class="co"># Generate a train set.</span></span>
<span id="cb156-4"><a href="deeplearning.html#cb156-4"></a><span class="co"># First element is the input x and </span></span>
<span id="cb156-5"><a href="deeplearning.html#cb156-5"></a><span class="co"># the second element is the output y.</span></span>
<span id="cb156-6"><a href="deeplearning.html#cb156-6"></a>train_set &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="fl">3.0</span>,<span class="fl">4.0</span>,<span class="fl">1.0</span>),</span>
<span id="cb156-7"><a href="deeplearning.html#cb156-7"></a>                        <span class="dt">y =</span> <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="fl">2.0</span>, <span class="fl">0.5</span>))</span>
<span id="cb156-8"><a href="deeplearning.html#cb156-8"></a></span>
<span id="cb156-9"><a href="deeplearning.html#cb156-9"></a><span class="co"># Instantiate a sequential model.</span></span>
<span id="cb156-10"><a href="deeplearning.html#cb156-10"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span></code></pre></div>
<p>We can now start adding layers (only one in this example). To do so, the <code>layer_dense()</code> method can be used. The <em>dense</em> name means that this will be a densely (fully) connected layer. This layer will be the output layer with a single unit.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="deeplearning.html#cb157-1"></a>model <span class="op">%&gt;%</span></span>
<span id="cb157-2"><a href="deeplearning.html#cb157-2"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>,</span>
<span id="cb157-3"><a href="deeplearning.html#cb157-3"></a>              <span class="dt">use_bias =</span> <span class="ot">FALSE</span>,</span>
<span id="cb157-4"><a href="deeplearning.html#cb157-4"></a>              <span class="dt">activation =</span> <span class="st">&#39;linear&#39;</span>,</span>
<span id="cb157-5"><a href="deeplearning.html#cb157-5"></a>              <span class="dt">input_shape =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The first argument <code>units = 1</code> specifies the number of units in this layer. By default, a bias is added in each layer. To make it the same as in the previous example we will not use a bias so <code>use_bias</code> is set to <code>FALSE</code>. The <code>activation</code> specifies the activation function. Here it is set to <code>'linear'</code> which means that no activation function is applied <span class="math inline">\(f(x)=x\)</span>. Finally, we need to specify the number of inputs with <code>input_shape</code>. In this case, there is only one feature.</p>
<p>Before training the network we need to compile the model and specify the learning algorithm. In this case, stochastic gradient descent with a learning rate of <span class="math inline">\(\alpha=0.01\)</span>. We also need to specify which loss function we would like to use (we’ll use mean squared error). At every epoch, some performance metrics can be computed. Here, we specify that we want the mean squared error and mean absolute error. These metrics are computed on the train data. After compiling the model the <code>summary()</code> method can be used to print a textual description of it. Figure <a href="deeplearning.html#fig:simpleSummary">8.16</a> shows the output of the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="deeplearning.html#cb158-1"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb158-2"><a href="deeplearning.html#cb158-2"></a>  <span class="dt">optimizer =</span> <span class="kw">optimizer_sgd</span>(<span class="dt">lr =</span> <span class="fl">0.01</span>),</span>
<span id="cb158-3"><a href="deeplearning.html#cb158-3"></a>  <span class="dt">loss =</span> <span class="st">&#39;mse&#39;</span>,</span>
<span id="cb158-4"><a href="deeplearning.html#cb158-4"></a>  <span class="dt">metrics =</span> <span class="kw">list</span>(<span class="st">&#39;mse&#39;</span>,<span class="st">&#39;mae&#39;</span>)</span>
<span id="cb158-5"><a href="deeplearning.html#cb158-5"></a>)</span>
<span id="cb158-6"><a href="deeplearning.html#cb158-6"></a><span class="kw">summary</span>(model)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:simpleSummary"></span>
<img src="images/nn_simple_summary.png" alt="Summary of the simple neural network." width="80%" />
<p class="caption">
Figure 8.16: Summary of the simple neural network.
</p>
</div>
<p>From this output, we can see that the network consists of a single dense layer with <span class="math inline">\(1\)</span> unit.
To start the actual training procedure we need to call the <code>fit()</code> function. Its first argument is the input training data (features) as a matrix. The second argument specifies the corresponding true outputs. We will let the algorithm run for <span class="math inline">\(30\)</span> epochs. The batch size is set to <span class="math inline">\(3\)</span> which is also the total number of examples in our data. In this example the dataset is very small so we can just set the batch size equal to the total number of instances. In practice, datasets can contain thousands of instances but the batch size will be relatively small (e.g., <span class="math inline">\(8\)</span>, <span class="math inline">\(16\)</span>, <span class="math inline">\(32\)</span>, etc.).</p>
<p>Additionally, there is a <code>validation_split</code> parameter that specifies the fraction of the train data to be used for validation. Here, I set it to <span class="math inline">\(0\)</span> (the default) since the dataset is very small. If the validation split is greater than <span class="math inline">\(0\)</span> its performance metrics will also be computed. The <code>verbose</code> parameter sets the amount of information to be printed during training. A <span class="math inline">\(0\)</span> will not print anything. A <span class="math inline">\(2\)</span> will print one line of information per epoch. The last parameter <code>view_metrics</code> specifies if you want the progress of the loss and performance metrics to be plotted. The <code>fit()</code> function returns an object with summary statistics collected during training that we are saving in the variable <code>history</code>.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="deeplearning.html#cb159-1"></a>history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(</span>
<span id="cb159-2"><a href="deeplearning.html#cb159-2"></a>  <span class="kw">as.matrix</span>(train_set<span class="op">$</span>x), <span class="kw">as.matrix</span>(train_set<span class="op">$</span>y),</span>
<span id="cb159-3"><a href="deeplearning.html#cb159-3"></a>  <span class="dt">epochs =</span> <span class="dv">30</span>,</span>
<span id="cb159-4"><a href="deeplearning.html#cb159-4"></a>  <span class="dt">batch_size =</span> <span class="dv">3</span>,</span>
<span id="cb159-5"><a href="deeplearning.html#cb159-5"></a>  <span class="dt">validation_split =</span> <span class="dv">0</span>,</span>
<span id="cb159-6"><a href="deeplearning.html#cb159-6"></a>  <span class="dt">verbose =</span> <span class="dv">2</span>,</span>
<span id="cb159-7"><a href="deeplearning.html#cb159-7"></a>  <span class="dt">view_metrics =</span> <span class="ot">TRUE</span></span>
<span id="cb159-8"><a href="deeplearning.html#cb159-8"></a>)</span></code></pre></div>
<p>Figure <a href="deeplearning.html#fig:nnEpochs">8.17</a> shows the output of the <code>fit()</code> function in RStudio. In the console, the training loss, mean squared error, and mean absolute error are printed during each epoch. In the viewer pane, plots of the same metrics are shown. Here, we can see that the loss is nicely decreasing over time. The loss at epoch <span class="math inline">\(30\)</span> should be something close to <span class="math inline">\(0\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:nnEpochs"></span>
<img src="images/nn_epochs.png" alt="fit() function output." width="100%" />
<p class="caption">
Figure 8.17: fit() function output.
</p>
</div>
<p>The information saved in the <code>history</code> variable can be plotted with <code>plot(history)</code>. This will generate plots for the <em>loss</em>, <em>MSE</em>, and <em>MAE</em>.</p>

<div class="rmdcaution">
These results can be slightly different every time the training is run due to random weight initializations made by the back end.
</div>

<p>Once the model is trained, we can perform inference on new data points with the <code>predict_on_batch()</code> function. Here we are passing three data points.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="deeplearning.html#cb160-1"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict_on_batch</span>(<span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">50</span>, <span class="dv">-220</span>))</span>
<span id="cb160-2"><a href="deeplearning.html#cb160-2"></a><span class="co">#&gt;  [,1]</span></span>
<span id="cb160-3"><a href="deeplearning.html#cb160-3"></a><span class="co">#&gt;  [1,]    3.465378</span></span>
<span id="cb160-4"><a href="deeplearning.html#cb160-4"></a><span class="co">#&gt;  [2,]   24.752701</span></span>
<span id="cb160-5"><a href="deeplearning.html#cb160-5"></a><span class="co">#&gt;  [3,] -108.911880</span></span></code></pre></div>
<p>From the results, it can be seen that we got more or less the expected results. Try setting a higher learning rate, for example, <span class="math inline">\(0.05\)</span>. With this learning rate, the algorithm will converge much faster. In my computer, at epoch <span class="math inline">\(11\)</span> the loss was already <span class="math inline">\(0\)</span>.</p>

<div class="rmdcaution">
One practical thing to note is that if you make any changes in the <code>compile()</code> or <code>fit()</code> functions you will have to run again the code that instantiates and defines the network. This is because the model object saves the current state including the learned weights. If you run the <code>fit()</code> function again on a previously trained model, it will start with the previously learned weights.
</div>

</div>
</div>
<div id="classification-with-neural-networks" class="section level2">
<h2><span class="header-section-number">8.3</span> Classification with Neural Networks</h2>
<p>Neural networks are trained iteratively by modifying their weights aiming to minimize the loss function. When the network predicts real numbers, the MSE loss function is normally used. For classification problems, the network should predict what is the most likely class out of <span class="math inline">\(k\)</span> possible categories. To make a neural network work for classification problems, we need to introduce new elements to its architecture:</p>
<ol style="list-style-type: decimal">
<li>Add more units to the output layer.</li>
<li>Use a <strong>softmax</strong> activation function in the output layer.</li>
<li>Use <strong>average cross-entropy</strong> as the loss function.</li>
</ol>
<p>Let’s start with point number <span class="math inline">\(1\)</span> (add more units to the output layer). This means that if the number of classes is <span class="math inline">\(k\)</span>, then the last layer needs to have <span class="math inline">\(k\)</span> units, one for each class. That’s it!. Figure <a href="deeplearning.html#fig:nnCrossEntropy">8.18</a> shows an example of a neural network with an output layer having <span class="math inline">\(3\)</span> units. Each unit predicts a score for each of the <span class="math inline">\(3\)</span> classes. Let’s call the vector of predicted scores <span class="math inline">\(y&#39;\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:nnCrossEntropy"></span>
<img src="images/nn_cross-entropy.png" alt="Neural network with 3 output scores. Softmax is applied to the scores and the cross-entropy with the true scores is calculated. This gives us an estimate of the similarity between the network's predictions and the true values." width="100%" />
<p class="caption">
Figure 8.18: Neural network with 3 output scores. Softmax is applied to the scores and the cross-entropy with the true scores is calculated. This gives us an estimate of the similarity between the network’s predictions and the true values.
</p>
</div>
<p>Point number <span class="math inline">\(2\)</span> says that a <strong>softmax</strong> activation function should be used in the output layer. When training the network, just as with regression, we need a way to compute the error between the predicted values <span class="math inline">\(y&#39;\)</span> and the true values <span class="math inline">\(y\)</span>. In this case, <span class="math inline">\(y\)</span> is a one-hot encoded vector with a <span class="math inline">\(1\)</span> at the position of the true class and <span class="math inline">\(0s\)</span> elsewhere. If you are not familiar with one-hot encoding, you can check the topic in chapter <a href="preprocessing.html#preprocessing">5</a>. As opposed to other classifiers like decision trees, <span class="math inline">\(k\)</span>-nn, etc., neural networks need the classes to be one-hot encoded.</p>
<p>With regression problems, one way to compare the prediction with the true value is by using the squared difference: <span class="math inline">\((y&#39; - y)^2\)</span>. With classification, <span class="math inline">\(y\)</span> and <span class="math inline">\(y&#39;\)</span> are vectors so we need a way to compare them. The true values <span class="math inline">\(y\)</span> are represented as a vector of probabilities with a <span class="math inline">\(1\)</span> at the position of the true class. The output scores <span class="math inline">\(y&#39;\)</span> do not necessarily sum up to <span class="math inline">\(1\)</span> thus, they are not proper probabilities. Before comparing <span class="math inline">\(y\)</span> and <span class="math inline">\(y&#39;\)</span> we need them both to be probabilities. The <strong>softmax</strong> activation function is used to convert <span class="math inline">\(y&#39;\)</span> into a vector of probabilities. The softmax function is applied individually to each element of a vector:</p>
<p><span class="math display" id="eq:softmax">\[\begin{equation}
  softmax(\boldsymbol{x},i) = \frac{e^{\boldsymbol{x}_i}}{\sum_{j}{e^{\boldsymbol{x}_j}}}
  \tag{8.9}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{x}\)</span> is a vector and <span class="math inline">\(i\)</span> is an index pointing to a particular element in the vector. Thus, to convert <span class="math inline">\(y&#39;\)</span> into a vector of probabilities we need to apply softmax to each of its elements. One thing to note is that this activation function depends on all the values in the vector (the output values of all units). Figure <a href="deeplearning.html#fig:nnCrossEntropy">8.18</a> shows the resulting vector of probabilities after applying softmax to each element of <span class="math inline">\(y&#39;\)</span>. In R this can be implemented like the following:</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="deeplearning.html#cb161-1"></a><span class="co"># Scores from the figure.</span></span>
<span id="cb161-2"><a href="deeplearning.html#cb161-2"></a>scores &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">3.0</span>, <span class="fl">0.03</span>, <span class="fl">1.2</span>)</span>
<span id="cb161-3"><a href="deeplearning.html#cb161-3"></a></span>
<span id="cb161-4"><a href="deeplearning.html#cb161-4"></a><span class="co"># Softmax function.</span></span>
<span id="cb161-5"><a href="deeplearning.html#cb161-5"></a>softmax &lt;-<span class="st"> </span><span class="cf">function</span>(scores){</span>
<span id="cb161-6"><a href="deeplearning.html#cb161-6"></a>  <span class="kw">exp</span>(scores) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">exp</span>(scores))</span>
<span id="cb161-7"><a href="deeplearning.html#cb161-7"></a>}</span>
<span id="cb161-8"><a href="deeplearning.html#cb161-8"></a>probabilities &lt;-<span class="st"> </span><span class="kw">softmax</span>(scores)</span>
<span id="cb161-9"><a href="deeplearning.html#cb161-9"></a><span class="kw">print</span>(probabilities)</span>
<span id="cb161-10"><a href="deeplearning.html#cb161-10"></a><span class="co">#&gt; [1] 0.82196136 0.04216934 0.13586930</span></span>
<span id="cb161-11"><a href="deeplearning.html#cb161-11"></a><span class="kw">print</span>(<span class="kw">sum</span>(probabilities)) <span class="co"># Should sum up to 1.</span></span>
<span id="cb161-12"><a href="deeplearning.html#cb161-12"></a><span class="co">#&gt; [1] 1</span></span></code></pre></div>
<p>We used R vectorization capabilities to compute the final vector of probabilities within the same function without having to iterate through each element. When using Keras, these operations are efficiently computed by the backend (for example, TensorFlow).</p>
<p>Finally, point <span class="math inline">\(3\)</span> states that we need to use <strong>average cross-entropy</strong> as the <strong>loss function</strong>. Now that we have converted <span class="math inline">\(y&#39;\)</span> into probabilities, we can compute its dissimilarity with <span class="math inline">\(y\)</span>. The distance (dissimilarity) between two vectors (<span class="math inline">\(A\)</span>,<span class="math inline">\(B\)</span>) of probabilities can be computed using the <strong>cross-entropy</strong>:</p>
<p><span class="math display" id="eq:crossentropy">\[\begin{equation}
  CE(A,B) = - \sum_{i}{B_i log(A_i)}
  \tag{8.10}
\end{equation}\]</span></p>
<p>Thus, to get the dissimilarity between <span class="math inline">\(y&#39;\)</span> and <span class="math inline">\(y\)</span> first we apply softmax to <span class="math inline">\(y&#39;\)</span> (to transform it into proper probabilities) and then, we can compute the cross entropy between the resulting vector of probabilities and <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[\begin{equation}
  CE(softmax(y&#39;),y).
\end{equation}\]</span></p>
<p>In R this can be implemented with the following:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="deeplearning.html#cb162-1"></a><span class="co"># Cross-entropy</span></span>
<span id="cb162-2"><a href="deeplearning.html#cb162-2"></a>CE &lt;-<span class="st"> </span><span class="cf">function</span>(A,B){</span>
<span id="cb162-3"><a href="deeplearning.html#cb162-3"></a> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(B <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(A))</span>
<span id="cb162-4"><a href="deeplearning.html#cb162-4"></a>}</span>
<span id="cb162-5"><a href="deeplearning.html#cb162-5"></a></span>
<span id="cb162-6"><a href="deeplearning.html#cb162-6"></a>y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb162-7"><a href="deeplearning.html#cb162-7"></a></span>
<span id="cb162-8"><a href="deeplearning.html#cb162-8"></a><span class="kw">print</span>(<span class="kw">CE</span>(<span class="kw">softmax</span>(scores), y))</span>
<span id="cb162-9"><a href="deeplearning.html#cb162-9"></a><span class="co">#&gt; [1] 0.1960619</span></span></code></pre></div>

<div class="rmdcaution">
Be aware that when computing the cross-entropy with equation <a href="deeplearning.html#eq:crossentropy">(8.10)</a> <strong>order matters</strong>. The first element should be the predicted scores <span class="math inline">\(y&#39;\)</span> and the second element should be the true one-hot encoded vector <span class="math inline">\(y\)</span>. We don’t want to apply a log function to a vector with values of <span class="math inline">\(0\)</span>. Most of the time, the predicted scores <span class="math inline">\(y&#39;\)</span> will be different from <span class="math inline">\(0\)</span> that’s why we prefer to apply the log function to them. In the very rare case when the predicted scores have zeros, we can add a very small number. In practice, this is taken care of by the backend (e.g., Tensorflow).
</div>

<p>Now we know how to compute the cross-entropy for each training instance. The total loss function is then, the <strong>average cross-entropy across the training points</strong>. The next section shows how to build a neural network for classification using Keras.</p>
<div id="classification-of-electromyography-signals" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Classification of Electromyography Signals</h3>

<div class="rmdfolder">
<code>keras_electromyography.R</code>
</div>

<p>In this example, we will train a neural network with Keras to classify hand gestures based on muscle electrical activity. The <em>ELECTROYMYOGRAPHY</em> dataset will be used here. The electrical activity was recorded with an electromyography (EMG) sensor worn as an armband. The data were collected and made available by <span class="citation">Yashuk (<a href="#ref-kirill" role="doc-biblioref">2019</a>)</span>. The armband device has <span class="math inline">\(8\)</span> sensors which are placed on the skin surface and measure electrical activity from the right forearm at a sampling rate of <span class="math inline">\(200\)</span> Hz. A video of the device can be found here: <a href="https://youtu.be/1u5-G6DPtkk" class="uri">https://youtu.be/1u5-G6DPtkk</a></p>
<p>The data contains <span class="math inline">\(4\)</span> different gestures: 0-rock, 1-scissors, 2-paper, 3-OK, and has <span class="math inline">\(65\)</span> columns. The last column is the class label from <span class="math inline">\(0\)</span> to <span class="math inline">\(3\)</span>. The first <span class="math inline">\(64\)</span> columns are electrical measurements. <span class="math inline">\(8\)</span> consecutive readings for each of the <span class="math inline">\(8\)</span> sensors. The objective is to use the first <span class="math inline">\(64\)</span> variables to predict the class.</p>
<p>The script <code>keras_electromyography.R</code> has the full code. We start by splitting the <code>dataset</code> into train (<span class="math inline">\(60\%\)</span>), validation (<span class="math inline">\(10\%\)</span>) and test (<span class="math inline">\(30\%\)</span>) sets. We will use the validation set to monitor the performance during each epoch. We also need to normalize the three sets but only learning the normalization parameters from the train set. The <code>normalize()</code> function included in the script will do the job.</p>
<p>One last thing we need to do is to format the data as matrices and one-hot encode the class. The following code defines a function that takes as input a data frame and the expected number of classes. It assumes that the first columns are the features and the last column contains the class. First, it converts the features into a matrix and stores them in <code>x</code>. Then, it converts the class into an array and one-hot encodes it using the <code>to_categorical()</code> function from Keras. The classes are stored in <code>y</code> and the function returns a list with the features and one-hot encoded classes. Then, we can call the function with the train, validation, and test sets.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="deeplearning.html#cb163-1"></a><span class="co"># Define a function to format features and one-hot encode the class.</span></span>
<span id="cb163-2"><a href="deeplearning.html#cb163-2"></a>format.to.array &lt;-<span class="st"> </span><span class="cf">function</span>(data, <span class="dt">numclasses =</span> <span class="dv">4</span>){</span>
<span id="cb163-3"><a href="deeplearning.html#cb163-3"></a>  x &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(data[, <span class="dv">1</span><span class="op">:</span>(<span class="kw">ncol</span>(data)<span class="op">-</span><span class="dv">1</span>)])</span>
<span id="cb163-4"><a href="deeplearning.html#cb163-4"></a>  y &lt;-<span class="st"> </span><span class="kw">as.array</span>(data[, <span class="kw">ncol</span>(data)])</span>
<span id="cb163-5"><a href="deeplearning.html#cb163-5"></a>  y &lt;-<span class="st"> </span><span class="kw">to_categorical</span>(y, <span class="dt">num_classes =</span> numclasses)</span>
<span id="cb163-6"><a href="deeplearning.html#cb163-6"></a>  l &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)</span>
<span id="cb163-7"><a href="deeplearning.html#cb163-7"></a>  <span class="kw">return</span>(l)</span>
<span id="cb163-8"><a href="deeplearning.html#cb163-8"></a>}</span>
<span id="cb163-9"><a href="deeplearning.html#cb163-9"></a></span>
<span id="cb163-10"><a href="deeplearning.html#cb163-10"></a><span class="co"># Format data</span></span>
<span id="cb163-11"><a href="deeplearning.html#cb163-11"></a>trainset &lt;-<span class="st"> </span><span class="kw">format.to.array</span>(trainset, <span class="dt">numclasses =</span> <span class="dv">4</span>)</span>
<span id="cb163-12"><a href="deeplearning.html#cb163-12"></a>valset &lt;-<span class="st"> </span><span class="kw">format.to.array</span>(valset, <span class="dt">numclasses =</span> <span class="dv">4</span>)</span>
<span id="cb163-13"><a href="deeplearning.html#cb163-13"></a>testset &lt;-<span class="st"> </span><span class="kw">format.to.array</span>(testset, <span class="dt">numclasses =</span> <span class="dv">4</span>)</span></code></pre></div>
<p>Let’s print the first one-hot encoded classes from the train set:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="deeplearning.html#cb164-1"></a><span class="kw">head</span>(trainset<span class="op">$</span>y)</span>
<span id="cb164-2"><a href="deeplearning.html#cb164-2"></a></span>
<span id="cb164-3"><a href="deeplearning.html#cb164-3"></a><span class="co">#&gt;        [,1] [,2] [,3] [,4]</span></span>
<span id="cb164-4"><a href="deeplearning.html#cb164-4"></a><span class="co">#&gt; [1,]    0    0    1    0</span></span>
<span id="cb164-5"><a href="deeplearning.html#cb164-5"></a><span class="co">#&gt; [2,]    0    0    1    0</span></span>
<span id="cb164-6"><a href="deeplearning.html#cb164-6"></a><span class="co">#&gt; [3,]    0    0    1    0</span></span>
<span id="cb164-7"><a href="deeplearning.html#cb164-7"></a><span class="co">#&gt; [4,]    0    0    0    1</span></span>
<span id="cb164-8"><a href="deeplearning.html#cb164-8"></a><span class="co">#&gt; [5,]    1    0    0    0</span></span>
<span id="cb164-9"><a href="deeplearning.html#cb164-9"></a><span class="co">#&gt; [6,]    0    0    0    1</span></span></code></pre></div>
<p>The first three instances belong to the class <em>‘paper’</em> because the <span class="math inline">\(1s\)</span> are in the third position. The corresponding integers are 0-rock, 1-scissors, 2-paper, 3-OK. So <em>‘paper’</em> comes in the third position. The fourth instance belongs to the class <em>‘OK’</em>, the fifth to <em>‘rock’</em>, and so on.</p>
<p>Now it’s time to define the neural network architecture! We will do so inside a function:</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="deeplearning.html#cb165-1"></a><span class="co"># Define the network&#39;s architecture.</span></span>
<span id="cb165-2"><a href="deeplearning.html#cb165-2"></a>get.nn &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">ninputs =</span> <span class="dv">64</span>, <span class="dt">nclasses =</span> <span class="dv">4</span>, <span class="dt">lr =</span> <span class="fl">0.01</span>){</span>
<span id="cb165-3"><a href="deeplearning.html#cb165-3"></a>  </span>
<span id="cb165-4"><a href="deeplearning.html#cb165-4"></a>  model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span>
<span id="cb165-5"><a href="deeplearning.html#cb165-5"></a>  </span>
<span id="cb165-6"><a href="deeplearning.html#cb165-6"></a>  model <span class="op">%&gt;%</span></span>
<span id="cb165-7"><a href="deeplearning.html#cb165-7"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>,</span>
<span id="cb165-8"><a href="deeplearning.html#cb165-8"></a>                <span class="dt">input_shape =</span> ninputs) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb165-9"><a href="deeplearning.html#cb165-9"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">16</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb165-10"><a href="deeplearning.html#cb165-10"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> nclasses, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb165-11"><a href="deeplearning.html#cb165-11"></a>  </span>
<span id="cb165-12"><a href="deeplearning.html#cb165-12"></a>  model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb165-13"><a href="deeplearning.html#cb165-13"></a>    <span class="dt">loss =</span> <span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb165-14"><a href="deeplearning.html#cb165-14"></a>    <span class="dt">optimizer =</span> <span class="kw">optimizer_sgd</span>(<span class="dt">lr =</span> lr),</span>
<span id="cb165-15"><a href="deeplearning.html#cb165-15"></a>    <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb165-16"><a href="deeplearning.html#cb165-16"></a>  )</span>
<span id="cb165-17"><a href="deeplearning.html#cb165-17"></a>  </span>
<span id="cb165-18"><a href="deeplearning.html#cb165-18"></a>  <span class="kw">return</span>(model)</span>
<span id="cb165-19"><a href="deeplearning.html#cb165-19"></a>}</span></code></pre></div>
<p>The first argument takes the number of inputs (features), the second argument specifies the number of classes and the last argument is the learning rate <span class="math inline">\(\alpha\)</span>. The first line instantiates an empty keras sequential model. Then we add three layers. The first two are hidden layers and the last one will be the output layer. The input layer is implicitly defined when setting the <code>input_shape</code> parameter in the first layer. The first hidden layer has <span class="math inline">\(32\)</span> units with a ReLU activation function. Since this is the first hidden layer we also need to specify what is the expected input by setting the <code>input_shape</code>. In this case, it is the number of inputs which will be <span class="math inline">\(64\)</span> as it is the number of features. The next hidden layer has <span class="math inline">\(16\)</span> ReLU units. For the output layer, the number of units needs to be equal to the number of classes (<span class="math inline">\(4\)</span> in this case). Since this is a classification problem we also set the activation function to <code>softmax</code>.</p>
<p>Then, the model is compiled and the loss function is set to <code>categorical_crossentropy</code> because this is a classification problem. Stochastic gradient descent is used with a learning rate passed as a parameter. During training, we want to monitor the <em>accuracy</em>. Finally, the function returns the compiled model.</p>
<p>Now we can call our function to create a model. This one will have <span class="math inline">\(64\)</span> inputs, <span class="math inline">\(4\)</span> outputs and we will use a learning rate of <span class="math inline">\(0.01\)</span>. It is always useful to print a summary of the model with the <code>summary()</code> function.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="deeplearning.html#cb166-1"></a>model &lt;-<span class="st"> </span><span class="kw">get.nn</span>(<span class="dv">64</span>, <span class="dv">4</span>, <span class="dt">lr =</span> <span class="fl">0.01</span>)</span>
<span id="cb166-2"><a href="deeplearning.html#cb166-2"></a><span class="kw">summary</span>(model)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:nnEMGSummary"></span>
<img src="images/nn_emg_summary.png" alt="Summary of the network." width="90%" />
<p class="caption">
Figure 8.19: Summary of the network.
</p>
</div>
<p>From the summary, we can see that the network has <span class="math inline">\(3\)</span> layers. The second column shows the output shape which in this case corresponds to the number of units in each layer. The last column shows the number of parameters of each layer. For example, the first layer has <span class="math inline">\(2080\)</span> parameters! Those come from the weights and biases. There are <span class="math inline">\(64\)</span> (inputs) * <span class="math inline">\(32\)</span> (units) = <span class="math inline">\(2048\)</span> weights plus the <span class="math inline">\(32\)</span> biases (one for each unit). The biases are included by default on each layer unless otherwise specified.</p>
<p>The second layer receives <span class="math inline">\(32\)</span> inputs on each of its <span class="math inline">\(16\)</span> units. Thus <span class="math inline">\(32\)</span> * <span class="math inline">\(16\)</span> + <span class="math inline">\(16\)</span> (biases) = <span class="math inline">\(528\)</span>. The last layer has <span class="math inline">\(16\)</span> inputs from the previous layer on each of its <span class="math inline">\(4\)</span> units plus <span class="math inline">\(4\)</span> biases giving a total of <span class="math inline">\(68\)</span> parameters. In total, the network has <span class="math inline">\(2676\)</span> parameters. Here, we can see how fast the number of parameters grows when adding more layers and units. Now, we can use the <code>fit()</code> function to train the model.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="deeplearning.html#cb167-1"></a>history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(</span>
<span id="cb167-2"><a href="deeplearning.html#cb167-2"></a>  trainset<span class="op">$</span>x, trainset<span class="op">$</span>y,</span>
<span id="cb167-3"><a href="deeplearning.html#cb167-3"></a>  <span class="dt">epochs =</span> <span class="dv">300</span>,</span>
<span id="cb167-4"><a href="deeplearning.html#cb167-4"></a>  <span class="dt">batch_size =</span> <span class="dv">8</span>,</span>
<span id="cb167-5"><a href="deeplearning.html#cb167-5"></a>  <span class="dt">validation_data =</span> <span class="kw">list</span>(valset<span class="op">$</span>x, valset<span class="op">$</span>y),</span>
<span id="cb167-6"><a href="deeplearning.html#cb167-6"></a>  <span class="dt">verbose =</span> <span class="dv">1</span>,</span>
<span id="cb167-7"><a href="deeplearning.html#cb167-7"></a>  <span class="dt">view_metrics =</span> <span class="ot">TRUE</span></span>
<span id="cb167-8"><a href="deeplearning.html#cb167-8"></a>)</span></code></pre></div>
<p>The model is trained for <span class="math inline">\(300\)</span> epochs with a batch size of <span class="math inline">\(8\)</span>. We used the <code>validation_data</code> parameter to specify the validation set to compute the performance on unseen data. The training will take some minutes to complete. Bigger models can take hours or even several days. Thus, it is a good idea to save a model once it is trained.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="deeplearning.html#cb168-1"></a><span class="co"># Save model.</span></span>
<span id="cb168-2"><a href="deeplearning.html#cb168-2"></a><span class="kw">save_model_hdf5</span>(model, <span class="st">&quot;electromyography.hdf5&quot;</span>)</span></code></pre></div>
<p>We can load a previously saved model with:</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="deeplearning.html#cb169-1"></a><span class="co"># Load model.</span></span>
<span id="cb169-2"><a href="deeplearning.html#cb169-2"></a>model &lt;-<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&quot;electromyography.hdf5&quot;</span>)</span></code></pre></div>
<p>Figure <a href="deeplearning.html#fig:nnEMGloss">8.20</a> shows the train and validation loss and accuracy as produced by <code>plot(history)</code>. We can see that both the training and validation loss are decreasing over time. The accuracy increases over time.</p>
<div class="figure" style="text-align: center"><span id="fig:nnEMGloss"></span>
<img src="images/nn_emg_loss.png" alt="Loss and accuracy of the electromyography model." width="100%" />
<p class="caption">
Figure 8.20: Loss and accuracy of the electromyography model.
</p>
</div>
<p>Now, we can evaluate the performance of the trained model with the test set using the <code>evaluate()</code> function.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="deeplearning.html#cb170-1"></a><span class="co"># Evaluate model.</span></span>
<span id="cb170-2"><a href="deeplearning.html#cb170-2"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">evaluate</span>(testset<span class="op">$</span>x, testset<span class="op">$</span>y)</span>
<span id="cb170-3"><a href="deeplearning.html#cb170-3"></a></span>
<span id="cb170-4"><a href="deeplearning.html#cb170-4"></a><span class="co">#&gt;      loss  accuracy </span></span>
<span id="cb170-5"><a href="deeplearning.html#cb170-5"></a><span class="co">#&gt; 0.4045424 0.8474576</span></span></code></pre></div>
<p>The accuracy was pretty decent (<span class="math inline">\(\approx 84\%\)</span>). If you want to get the actual class predictions you can use the <code>predict_classes()</code> function.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="deeplearning.html#cb171-1"></a><span class="co"># Predict classes.</span></span>
<span id="cb171-2"><a href="deeplearning.html#cb171-2"></a>classes &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict_classes</span>(testset<span class="op">$</span>x)</span>
<span id="cb171-3"><a href="deeplearning.html#cb171-3"></a><span class="kw">head</span>(classes)</span>
<span id="cb171-4"><a href="deeplearning.html#cb171-4"></a><span class="co">#&gt; [1] 2 2 1 3 0 1</span></span></code></pre></div>
<p>Note that this function returns the classes with numbers starting with <span class="math inline">\(0\)</span> just as in the original dataset.</p>
<p>Sometimes it is also useful to get the actual predicted scores for each class. This can be done with the <code>predict_on_batch()</code> function.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="deeplearning.html#cb172-1"></a><span class="co"># Make predictions on the test set.</span></span>
<span id="cb172-2"><a href="deeplearning.html#cb172-2"></a>predictions &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict_on_batch</span>(testset<span class="op">$</span>x)</span>
<span id="cb172-3"><a href="deeplearning.html#cb172-3"></a><span class="kw">head</span>(predictions)</span>
<span id="cb172-4"><a href="deeplearning.html#cb172-4"></a><span class="co">#&gt;              [,1]         [,2]         [,3]         [,4]</span></span>
<span id="cb172-5"><a href="deeplearning.html#cb172-5"></a><span class="co">#&gt; [1,] 1.957638e-05 8.726048e-02 7.708290e-01 1.418910e-01</span></span>
<span id="cb172-6"><a href="deeplearning.html#cb172-6"></a><span class="co">#&gt; [2,] 3.937355e-05 2.571992e-04 9.965665e-01 3.136863e-03</span></span>
<span id="cb172-7"><a href="deeplearning.html#cb172-7"></a><span class="co">#&gt; [3,] 4.261451e-03 7.343097e-01 7.226156e-02 1.891673e-01</span></span>
<span id="cb172-8"><a href="deeplearning.html#cb172-8"></a><span class="co">#&gt; [4,] 8.669784e-06 2.088269e-04 1.339851e-01 8.657974e-01</span></span>
<span id="cb172-9"><a href="deeplearning.html#cb172-9"></a><span class="co">#&gt; [5,] 9.999956e-01 7.354113e-26 1.299388e-08 4.451362e-06</span></span>
<span id="cb172-10"><a href="deeplearning.html#cb172-10"></a><span class="co">#&gt; [6,] 2.513005e-05 9.914154e-01 7.252949e-03 1.306421e-03</span></span></code></pre></div>
<p>If we want to get the actual classes from the scores we can get the index of the maximum column. Then we subtract <span class="math inline">\(-1\)</span> so classes start at <span class="math inline">\(0\)</span>.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="deeplearning.html#cb173-1"></a>classes &lt;-<span class="st"> </span><span class="kw">max.col</span>(predictions) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb173-2"><a href="deeplearning.html#cb173-2"></a><span class="kw">head</span>(classes)</span>
<span id="cb173-3"><a href="deeplearning.html#cb173-3"></a><span class="co">#&gt; [1] 2 2 1 3 0 1</span></span></code></pre></div>
<p>Since the true classes are also one-hot encoded we need to do the same to get the ground truth.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="deeplearning.html#cb174-1"></a>groundTruth &lt;-<span class="st"> </span><span class="kw">max.col</span>(testset<span class="op">$</span>y) <span class="op">-</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb174-2"><a href="deeplearning.html#cb174-2"></a></span>
<span id="cb174-3"><a href="deeplearning.html#cb174-3"></a><span class="co"># Compute accuracy.</span></span>
<span id="cb174-4"><a href="deeplearning.html#cb174-4"></a><span class="kw">sum</span>(classes <span class="op">==</span><span class="st"> </span>groundTruth) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(classes)</span>
<span id="cb174-5"><a href="deeplearning.html#cb174-5"></a><span class="co">#&gt; [1] 0.8474576</span></span></code></pre></div>
<p>We can convert the integers to class strings by mapping them and then generate a confusion matrix.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="deeplearning.html#cb175-1"></a><span class="co"># Convert classes to strings.</span></span>
<span id="cb175-2"><a href="deeplearning.html#cb175-2"></a><span class="co"># Class mapping by index: rock 0, scissors 1, paper 2, ok 3.</span></span>
<span id="cb175-3"><a href="deeplearning.html#cb175-3"></a>mapping &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;rock&quot;</span>, <span class="st">&quot;scissors&quot;</span>, <span class="st">&quot;paper&quot;</span>, <span class="st">&quot;ok&quot;</span>)</span>
<span id="cb175-4"><a href="deeplearning.html#cb175-4"></a><span class="co"># Need to add 1 because indices in R start at 1.</span></span>
<span id="cb175-5"><a href="deeplearning.html#cb175-5"></a>str.predictions &lt;-<span class="st"> </span>mapping[classes<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb175-6"><a href="deeplearning.html#cb175-6"></a>str.groundTruth &lt;-<span class="st"> </span>mapping[groundTruth<span class="op">+</span><span class="dv">1</span>]</span>
<span id="cb175-7"><a href="deeplearning.html#cb175-7"></a></span>
<span id="cb175-8"><a href="deeplearning.html#cb175-8"></a><span class="kw">library</span>(caret)</span>
<span id="cb175-9"><a href="deeplearning.html#cb175-9"></a>cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="kw">as.factor</span>(str.predictions),</span>
<span id="cb175-10"><a href="deeplearning.html#cb175-10"></a>                      <span class="kw">as.factor</span>(str.groundTruth))</span>
<span id="cb175-11"><a href="deeplearning.html#cb175-11"></a>cm<span class="op">$</span>table</span>
<span id="cb175-12"><a href="deeplearning.html#cb175-12"></a><span class="co">#&gt;           Reference</span></span>
<span id="cb175-13"><a href="deeplearning.html#cb175-13"></a><span class="co">#&gt; Prediction  ok paper rock scissors</span></span>
<span id="cb175-14"><a href="deeplearning.html#cb175-14"></a><span class="co">#&gt;   ok       681   118   24       27</span></span>
<span id="cb175-15"><a href="deeplearning.html#cb175-15"></a><span class="co">#&gt;   paper     54   681   47       12</span></span>
<span id="cb175-16"><a href="deeplearning.html#cb175-16"></a><span class="co">#&gt;   rock      29    18  771        1</span></span>
<span id="cb175-17"><a href="deeplearning.html#cb175-17"></a><span class="co">#&gt;   scissors 134    68    8      867</span></span></code></pre></div>
<p>Try to modify the network by making it deeper (adding more layers) and fine-tune the hyperparameters like the learning rate, batch size, etc. to increase the performance.</p>
</div>
</div>
<div id="overfitting" class="section level2">
<h2><span class="header-section-number">8.4</span> Overfitting</h2>
<p>One important thing to look at when training a network is <strong>overfitting</strong>. That is, when the model memorizes instead of learning (see chapter <a href="intro.html#intro">1</a>). Overfitting means that the model becomes very specialized at mapping inputs to outputs from the <em>train set</em> but fails to do so with new <em>test samples</em>. One of the reasons is that a model can become too complex and with so many parameters that it will perfectly adapt to its training data but will miss more general patterns that allow it to perform well on unseen instances. To control for this, one can plot loss/accuracy curves during training epochs.</p>
<div class="figure" style="text-align: center"><span id="fig:lossAccuracy"></span>
<img src="images/nn_loss_accuracy_curves.png" alt="Loss and accuracy curves." width="100%" />
<p class="caption">
Figure 8.21: Loss and accuracy curves.
</p>
</div>
<p>In Figure <a href="deeplearning.html#fig:lossAccuracy">8.21</a> we can see that after some epochs the <em>validation loss</em> starts to increase even though the <em>train loss</em> is still decreasing. This is because the model is getting better on reducing the error on the train set but its performance starts to decrease when presented with new instances. Conversely, one can observe a similar effect with the accuracy. The model keeps improving its performance on the train set but at some point, the accuracy on the validation set starts to decrease. Usually, one stops the training before overfitting starts to occur. In the following, I will introduce you to two common techniques to combat overfitting in neural networks.</p>
<div id="early-stopping" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Early Stopping</h3>

<div class="rmdfolder">
<code>keras_electromyography_earlystopping.R</code>
</div>

<p>Neural networks are trained for several epochs using gradient descent. But the question is: <em>For how many epochs?</em>. As can be seen in Figure <a href="deeplearning.html#fig:lossAccuracy">8.21</a>, too many epochs can lead to overfitting and too few can cause underfitting. <em>Early stopping</em> is a simple but effective method to reduce the risk of overfitting. The method consists of setting a large number of epochs and stop updating the network’s parameters when a condition is met. For example, one condition can be to stop when there is no performance improvement on the validation set after <span class="math inline">\(n\)</span> epochs or when there is a decrease of some percent in accuracy.</p>
<p>Keras provides some mechanisms to implement early stopping and this is accomplished via <strong>callbacks</strong>. A callback is a function that is run at different stages during training such as at the beginning or end of an epoch or at the beginning or end of a batch, etc. Callbacks are passed as a list to the <code>fit()</code> function. You can define custom callbacks or use some of the built-in ones including <code>callback_early_stopping()</code>. This callback will cause the training to stop when a metric stops improving. The metric can be <em>accuracy</em>, <em>loss</em>, etc. The following callback will stop the training if after <span class="math inline">\(10\)</span> epochs (<code>patience</code>) there is no improvement of at least <span class="math inline">\(1\%\)</span> (<code>min_delta</code>) in accuracy on the validation set.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="deeplearning.html#cb176-1"></a><span class="kw">callback_early_stopping</span>(<span class="dt">monitor =</span> <span class="st">&quot;val_acc&quot;</span>,</span>
<span id="cb176-2"><a href="deeplearning.html#cb176-2"></a>                        <span class="dt">min_delta =</span> <span class="fl">0.01</span>,</span>
<span id="cb176-3"><a href="deeplearning.html#cb176-3"></a>                        <span class="dt">patience =</span> <span class="dv">10</span>,</span>
<span id="cb176-4"><a href="deeplearning.html#cb176-4"></a>                        <span class="dt">verbose =</span> <span class="dv">1</span>,</span>
<span id="cb176-5"><a href="deeplearning.html#cb176-5"></a>                        <span class="dt">mode =</span> <span class="st">&quot;max&quot;</span>)</span></code></pre></div>
<p>The <code>min_delta</code> parameter specifies the minimum change in the monitored metric to qualify as an improvement. The <code>mode</code> specifies if training should be stopped when the metric has stopped decreasing if it is set to <code>"min"</code>. If it is set to <code>"max"</code>, training will stop when the monitored metric has stopped increasing.</p>
<p>It may be the case that the best validation performance was achieved not by the model in the last epoch but at some previous point. By setting the <code>restore_best_weights</code> parameter to <code>TRUE</code> the model weights from the epoch with the best value of the monitored metric will be restored.</p>
<p>The script <code>keras_electromyography_earlystopping.R</code> shows how to use the early stopping callback in Keras with the electromyography dataset. The following code is an extract that shows how to define the callback and pass it to the <code>fit()</code> function.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="deeplearning.html#cb177-1"></a><span class="co"># Define early stopping callback.</span></span>
<span id="cb177-2"><a href="deeplearning.html#cb177-2"></a>my_callback &lt;-<span class="st"> </span><span class="kw">callback_early_stopping</span>(<span class="dt">monitor =</span> <span class="st">&quot;val_acc&quot;</span>,</span>
<span id="cb177-3"><a href="deeplearning.html#cb177-3"></a>                                            <span class="dt">min_delta =</span> <span class="fl">0.01</span>,</span>
<span id="cb177-4"><a href="deeplearning.html#cb177-4"></a>                                            <span class="dt">patience =</span> <span class="dv">50</span>,</span>
<span id="cb177-5"><a href="deeplearning.html#cb177-5"></a>                                            <span class="dt">verbose =</span> <span class="dv">1</span>,</span>
<span id="cb177-6"><a href="deeplearning.html#cb177-6"></a>                                            <span class="dt">mode =</span> <span class="st">&quot;max&quot;</span>,</span>
<span id="cb177-7"><a href="deeplearning.html#cb177-7"></a>                                            <span class="dt">restore_best_weights =</span> <span class="ot">TRUE</span>)</span>
<span id="cb177-8"><a href="deeplearning.html#cb177-8"></a></span>
<span id="cb177-9"><a href="deeplearning.html#cb177-9"></a>history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(</span>
<span id="cb177-10"><a href="deeplearning.html#cb177-10"></a>  trainset<span class="op">$</span>x, trainset<span class="op">$</span>y,</span>
<span id="cb177-11"><a href="deeplearning.html#cb177-11"></a>  <span class="dt">epochs =</span> <span class="dv">500</span>,</span>
<span id="cb177-12"><a href="deeplearning.html#cb177-12"></a>  <span class="dt">batch_size =</span> <span class="dv">8</span>,</span>
<span id="cb177-13"><a href="deeplearning.html#cb177-13"></a>  <span class="dt">validation_data =</span> <span class="kw">list</span>(valset<span class="op">$</span>x, valset<span class="op">$</span>y),</span>
<span id="cb177-14"><a href="deeplearning.html#cb177-14"></a>  <span class="dt">verbose =</span> <span class="dv">1</span>,</span>
<span id="cb177-15"><a href="deeplearning.html#cb177-15"></a>  <span class="dt">view_metrics =</span> <span class="ot">TRUE</span>,</span>
<span id="cb177-16"><a href="deeplearning.html#cb177-16"></a>  <span class="dt">callbacks =</span> <span class="kw">list</span>(my_callback)</span>
<span id="cb177-17"><a href="deeplearning.html#cb177-17"></a>)</span></code></pre></div>
<p>This code will cause the training to stop if after <span class="math inline">\(50\)</span> epochs there is no improvement in accuracy of at least <span class="math inline">\(1\%\)</span> and will restore the model’s weights to the ones during the epoch with the highest accuracy. The following Figure shows how the training stopped at epoch <span class="math inline">\(237\)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:earlyStopping"></span>
<img src="images/nn_earlystopping.png" alt="Early stopping example." width="90%" />
<p class="caption">
Figure 8.22: Early stopping example.
</p>
</div>
<p>If we evaluate the final model on the test set we see that the accuracy is <span class="math inline">\(85.2\%\)</span> a small increase compared to the <span class="math inline">\(84\%\)</span> that we got when training for <span class="math inline">\(300\)</span> epochs without early stopping.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="deeplearning.html#cb178-1"></a><span class="co"># Evaluate model.</span></span>
<span id="cb178-2"><a href="deeplearning.html#cb178-2"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">evaluate</span>(testset<span class="op">$</span>x, testset<span class="op">$</span>y)</span>
<span id="cb178-3"><a href="deeplearning.html#cb178-3"></a></span>
<span id="cb178-4"><a href="deeplearning.html#cb178-4"></a><span class="co">#&gt; $loss</span></span>
<span id="cb178-5"><a href="deeplearning.html#cb178-5"></a><span class="co">#&gt; [1] 0.4202231</span></span>
<span id="cb178-6"><a href="deeplearning.html#cb178-6"></a></span>
<span id="cb178-7"><a href="deeplearning.html#cb178-7"></a><span class="co">#&gt; $acc</span></span>
<span id="cb178-8"><a href="deeplearning.html#cb178-8"></a><span class="co">#&gt; [1] 0.8525424</span></span></code></pre></div>
</div>
<div id="dropout" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Dropout</h3>
<p>Dropout is another technique used to reduce overfitting proposed by <span class="citation">Srivastava et al. (<a href="#ref-srivastava14" role="doc-biblioref">2014</a>)</span>. It consists of ‘dropping’ some of the units from a hidden layer for each sample during training. In theory, it can also be applied to input and output layers but that is not very common. The incoming and outgoing connections of a dropped unit are discarded. Figure <a href="deeplearning.html#fig:imgDropout">8.23</a> shows an example of applying dropout to a network. In b), the middle unit was removed from the network whereas in c), the top and bottom units were removed.</p>
<div class="figure" style="text-align: center"><span id="fig:imgDropout"></span>
<img src="images/nn_dropout.png" alt="Dropout example." width="100%" />
<p class="caption">
Figure 8.23: Dropout example.
</p>
</div>
<p>Each unit has an associated probability <span class="math inline">\(p\)</span> (independent of other units) of being dropped. This probability is another hyperparameter but typically it is set to <span class="math inline">\(0.5\)</span>. Thus, during each iteration and for each sample, half of the units are discarded. The effect of this, is having more simple networks (see Figure <a href="deeplearning.html#fig:imgDropout">8.23</a>) and thus, less prone to overfitting. Intuitively, you can also think of dropout as training an <strong>ensemble of neural networks</strong>, each having a slightly different structure.</p>
<p>From the perspective of one unit that receives inputs from the previous hidden layer with dropout, approximately half of its incoming connections will be gone (if <span class="math inline">\(p=0.5\)</span>). See Figure <a href="deeplearning.html#fig:dropoutUnit">8.24</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:dropoutUnit"></span>
<img src="images/nn_dropout_unit.png" alt="Incoming connections to one unit when the previous layer has dropout." width="20%" />
<p class="caption">
Figure 8.24: Incoming connections to one unit when the previous layer has dropout.
</p>
</div>
<p>Dropout has the effect of making units not to rely on any single incoming connection, thus, this makes the whole network able to compensate for the lack of connections by learning alternative paths. In practice and for many applications, this can result in a more robust model. A side effect of applying dropout is that the expected value of the activation function of a unit will be diminished because half of the previous activations will be <span class="math inline">\(0\)</span>. Recall that the output of a neuron is computed as:</p>
<p><span class="math display">\[\begin{equation}
  f(\boldsymbol{x}) = g(\boldsymbol{w} \cdot \boldsymbol{x} + b)
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{x}\)</span> contains the input values from the previous layer, <span class="math inline">\(\boldsymbol{w}\)</span> the corresponding weights and <span class="math inline">\(g()\)</span> is the activation function. With dropout, approximately half of the values of <span class="math inline">\(\boldsymbol{x}\)</span> will be <span class="math inline">\(0\)</span>. To compensate for that, the input values need to be scaled, in this case, by a factor of <span class="math inline">\(2\)</span>.</p>
<p><span class="math display">\[\begin{equation}
  f(\boldsymbol{x}) = g(\boldsymbol{w} \cdot 2 \boldsymbol{x} + b)
\end{equation}\]</span></p>
<p>In modern implementations, this scaling is done during training so at inference time
there is no need to apply dropout. The predictions are done as usual. In Keras, the <code>layer_dropout()</code> can be used to add dropout to any layer. Its parameter <code>rate</code> is a float between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> that specifies the fraction of units to drop. The following code snippet builds a neural network with <span class="math inline">\(2\)</span> hidden layers. Then, dropout with a rate of <span class="math inline">\(0.5\)</span> is applied to both of them.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="deeplearning.html#cb179-1"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span>
<span id="cb179-2"><a href="deeplearning.html#cb179-2"></a>  </span>
<span id="cb179-3"><a href="deeplearning.html#cb179-3"></a>  model <span class="op">%&gt;%</span></span>
<span id="cb179-4"><a href="deeplearning.html#cb179-4"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">256</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>, <span class="dt">input_shape =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb179-5"><a href="deeplearning.html#cb179-5"></a><span class="st">    </span><span class="kw">layer_dropout</span>(<span class="fl">0.5</span>) <span class="op">%&gt;%</span></span>
<span id="cb179-6"><a href="deeplearning.html#cb179-6"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">128</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb179-7"><a href="deeplearning.html#cb179-7"></a><span class="st">    </span><span class="kw">layer_dropout</span>(<span class="fl">0.5</span>) <span class="op">%&gt;%</span></span>
<span id="cb179-8"><a href="deeplearning.html#cb179-8"></a><span class="st">    </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span></code></pre></div>
<p>It is very common to apply dropout to networks in computer vision because the inputs are images or videos containing a lot of input values (pixels) but the number of samples is often very limited causing overfitting. In section <a href="deeplearning.html#cnns">8.6</a> convolutional neural networks (CNNs) will be introduced which are suitable for computer vision problems. In the corresponding smile detection example (section <a href="deeplearning.html#cnnSmile">8.8</a>), we will use dropout. When building CNNs, dropout is almost always added to the different layers.</p>
</div>
</div>
<div id="fine-tuning-a-neural-network" class="section level2">
<h2><span class="header-section-number">8.5</span> Fine-Tuning a Neural Network</h2>
<p>When deciding for a neural network’s architecture, no formula will tell you how many hidden layers or number of units each layer should have. There is also no formula for determining the batch size, the learning rate, type of activation function, for how many epochs should we train the network, and so on. All those are called the <strong>hyperparameters</strong> of the network. Hyperparameter tuning is a complex optimization problem and there is a lot of research going on that tackles the issue from different angles. My suggestion is to start with a simple architecture that has been used before to solve a similar problem and fine-tune it for your specific task. If you are not aware of any network that has been used for a similar problem, there are still some guidelines (described below) to get you started. Always keep in mind that those are only recommendations, so you do not need to abide by them and you should feel free to try configurations that deviate from those guidelines depending on your problem at hand.</p>
<p>Training neural networks is a time-consuming process, especially in deep networks. Training a network can take from several minutes to weeks. In many cases, performing cross-validation is not feasible. A common practice is to divide the data into train/validation/test sets. The training data is used to train a network with a given architecture and a set of hyperparameters. The validation set is used to evaluate the generalization performance of the network. Then, you can try different architectures and hyperparameters and evaluate the performance again and again with the validation set. Typically, the network’s performance is monitored during training epochs by plotting the loss and accuracy of the train and validation sets. Once you are happy with your model, you test its performance on the test set <strong>only once</strong> and that is the result that is reported.</p>
<p>Here are some starting point guidelines, however, also take into consideration that those hyperparameters can be dependent on each other. So, if you modify a hyperparameter it may impact other(s).</p>
<p><strong>Number of hidden layers.</strong>
Most of the time one or two hidden layers should be enough to solve not too complex problems. The advice here is to start with one hidden layer and if that one is not enough to capture the complexity of the problem, then add another layer and so on.</p>
<p><strong>Number of units.</strong>
If a network has too few units it can underfit, that is, the model will be too simple to capture the underlying data patterns. If the network has too many units this can result in overfitting. Also, it will take more time to learn the parameters. Some guidelines mention that the number of units should be somewhere between the number of input features and the number of units in the output layer<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>. <span class="citation">Huang (<a href="#ref-huang2003" role="doc-biblioref">2003</a>)</span> has even proposed a formula for the two-hidden layer case to calculate the number of units that are enough to learn <span class="math inline">\(N\)</span> samples: <span class="math inline">\(2\sqrt{(m+2)N}\)</span> where <span class="math inline">\(m\)</span> is the number of output units. But like this, there are many other similar formulas.</p>
<p>My suggestion is to first gain some practice and intuition with simple problems and a good way to do this is with the TensorFlow playground (<a href="https://playground.tensorflow.org/" class="uri">https://playground.tensorflow.org/</a>). This is a web-based implementation of a neural network that you can fine-tune to solve a predefined set of classification and regression problems. For example, Figure <a href="deeplearning.html#fig:playground">8.25</a> shows how I tried to solve the XOR problem with a neural network with <span class="math inline">\(1\)</span> hidden layer and <span class="math inline">\(1\)</span> unit with a sigmoid activation function. After more than <span class="math inline">\(1,000\)</span> epochs the loss is still quite high (<span class="math inline">\(0.3\)</span>). Try to add more neurons and/or hidden layers and see if you can solve the XOR problem with fewer epochs.</p>
<div class="figure" style="text-align: center"><span id="fig:playground"></span>
<img src="images/playground.png" alt="TensorFlow playground." width="100%" />
<p class="caption">
Figure 8.25: TensorFlow playground.
</p>
</div>
<p><strong>Batch size.</strong>
Batch sizes range between <span class="math inline">\(4\)</span> and <span class="math inline">\(512\)</span>. Big batch sizes provide a better estimate of the gradient but are more computationally expensive. On the other hand, small batch sizes are faster to compute but will incur in more noise in the gradient estimation requiring more epochs to converge. When using a GPU or other specialized hardware, the computations can be performed in parallel thus, allowing bigger batch sizes to be computed in a reasonable time. Some people argue that the noise introduced with small batch sizes is good to escape from local minima. <span class="citation">Keskar et al. (<a href="#ref-keskar2016" role="doc-biblioref">2016</a>)</span> showed that in practice, big batch sizes can result in degraded models. A good starting point is <span class="math inline">\(32\)</span> which is the default in Keras.</p>
<p><strong>Learning rate.</strong>
This is one of the most important hyperparameters. The learning rate specifies how fast gradient descent ‘moves’ when trying to find an optimal minimum. However, this doesn’t mean that the algorithm will <em>learn</em> faster if the learning rate is set to a high value. If it is too high, the loss can start oscillating. If it is too low, the learning will take a lot of time. One way to fine-tune it is to start with the default one. In Keras, the default learning rate for stochastic gradient descent is <span class="math inline">\(0.01\)</span>. Then, based on the loss plot across epochs, you can decrease/increase it. If learning is taking long, try to increase it. If the loss seems to be oscillating or stock try reducing it. Typical values are <span class="math inline">\(0.1\)</span>, <span class="math inline">\(0.01\)</span>, <span class="math inline">\(0.001\)</span>, <span class="math inline">\(0.0001\)</span>, <span class="math inline">\(0.00001\)</span>. Additionally to stochastic gradient descent, Keras provides implementations of other optimizers<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> like Adam<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> which have adaptive learning rates, but still, one needs to specify an initial one.</p>
<!--
### Other Considerations



**Automatic Fine-Tuning**


**Shuffling**


**Normalization**
-->
</div>
<div id="cnns" class="section level2">
<h2><span class="header-section-number">8.6</span> Convolutional Neural Networks</h2>
<p>Convolutional neural networks or CNNs for short, have become extremely popular due to their capacity to solve computer vision problems. Most of the time they are used for image classification tasks but can also be used for regression and for time series data. If we wanted to perform image classification with a traditional neural network, first we would need to either build a feature vector by:</p>
<ol style="list-style-type: decimal">
<li>extracting features from the image or,</li>
<li>flattening the image pixels into a 1D array.</li>
</ol>
<p>The first solution requires a lot of image processing expertise and domain knowledge. Extracting features from images is not a trivial task and requires a lot of preprocessing to reduce noise, artifacts, segment the objects of interest, remove background, etc. Additionally, considerable effort is spent on feature engineering. The drawback of the second solution is that spatial information is lost, that is, the relationship between neighboring pixels. CNNs solve the two previous problems by automatically extracting features while preserving spatial information. As opposed to traditional networks, CNNs can take as input <span class="math inline">\(n\)</span>-dimensional images and process them efficiently. The main building blocks of a CNN are:</p>
<ol style="list-style-type: decimal">
<li><strong>Convolution layers</strong></li>
<li><strong>Pooling operations</strong></li>
<li><strong>Traditional fully connected layers</strong></li>
</ol>
<p>Figure <a href="deeplearning.html#fig:cnnArchitecture">8.26</a> shows a simple CNN and its basic components. First, the image goes through a convolution layer with <span class="math inline">\(4\)</span> kernels (details about the convolution operation are described below). This layer is in charge of extracting features by applying the kernels on top of the image. The result of this operation is a convolved image, also known as <strong>feature maps</strong>. The number of feature maps is equal to the number of kernels, in this case, <span class="math inline">\(4\)</span>. Then, a <strong>pooling operation</strong> is applied on top of the feature maps. This operation reduces the size of the feature maps by downsampling them (details on this below). The output of the pooling operation is a set of feature maps with reduced size. Here, the outputs are <span class="math inline">\(4\)</span> reduced feature maps since the pooling operation is applied to each feature map independently of the others. Then, the feature maps are flattened into a one-dimensional array. Conceptually, this array represents all the features extracted from the previous steps. These features are then used as inputs to a neural network with its respective input, hidden, and output layers. An ’*’ and underlined text means that parameter learning occurs in that layer. For example, in the convolution layer, the parameters of the kernels need to be learned. On the other hand, the pooling operation does not require parameter learning since it is a fixed operation. Finally, the parameters of the neural network are learned too, including the hidden layers and the output layer.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnArchitecture"></span>
<img src="images/cnn_architecture.png" alt="Simple CNN architecture. An '*' indicates where parameter learning occurs." width="100%" />
<p class="caption">
Figure 8.26: Simple CNN architecture. An ’*’ indicates where parameter learning occurs.
</p>
</div>
<p>One can build more complex CNNs by stacking more convolution layers and pooling operations. By doing so, the level of abstraction increases. For example, the first convolution extracts simple features like horizontal, vertical, diagonal lines, etc. The next convolution could extract more complex features like squares, triangles, and so on. The parameter learning of all layers (including the convolution layers) occurs during the same forward and backpropagation step just as with a normal neural network. Both, the features and the classification task are learned at the same time! During learning, batches of images are forward propagated and the parameters are adjusted accordingly to minimize the error (for example, the average cross-entropy for classification). The same methods for training normal neural networks are used for CNNs, for example, stochastic gradient descent.</p>

<div class="rmdinfo">
Each kernel in a convolution layer can have an associated bias which is also a parameter to be learned. By default, Keras uses a bias for each kernel. Furthermore, an activation function can be applied to the outputs of the convolution layer. This is applied element-wise. ReLU is the most common one.
</div>

<p>At inference time, the convolution layers and pooling operations act as feature extractors by generating feature maps that are ultimately flattened and passed to a normal neural network. It is also common to use the first layers as feature extractors and then replace the neural network with another model (Random Forest, SVM, etc.). In the following sections, details about the convolution and pooling operations are presented.</p>
<div id="convolutions" class="section level3">
<h3><span class="header-section-number">8.6.1</span> Convolutions</h3>
<p>Convolutions are used to automatically extract feature maps from images. A convolution operation consists of a <strong>kernel</strong> also known as a <strong>filter</strong> which is a matrix with real values. Kernels are usually much smaller than the original image. For example, for a grayscale image of height and width of <span class="math inline">\(100\)</span>x<span class="math inline">\(100\)</span> a typical kernel size would be <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span>. The size of the kernel is a hyperparameter. The convolution operation consists of applying the kernel over the image staring at the upper left corner and moving forward row by row until reaching the bottom right corner. The <strong>stride</strong> controls how many elements the kernel is moved at a time and this is also a hyperparameter. A typical value for the stride is <span class="math inline">\(1\)</span>.</p>
<p>The convolution operation computes the sum of the element-wise product between the kernel and the image region it is covering. The output of this operation is used to generate the convolved image (feature map). Figure <a href="deeplearning.html#fig:cnnConv">8.27</a> shows the first two iterations and the final iteration of the convolution operation on an image. In this case, the kernel is a <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> matrix with <span class="math inline">\(1\)</span>s in its first row and <span class="math inline">\(0\)</span>s elsewhere. The original image has a size of <span class="math inline">\(5\)</span>x<span class="math inline">\(5\)</span>x<span class="math inline">\(1\)</span> (height, width, depth) and it seems to have the number <span class="math inline">\(7\)</span> in it.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnConv"></span>
<img src="images/cnn_conv_ites.png" alt="Convolution operation with a kernel of size 3x3 and stride=1. Iterations 1, 2 and 9." width="100%" />
<p class="caption">
Figure 8.27: Convolution operation with a kernel of size 3x3 and stride=1. Iterations 1, 2 and 9.
</p>
</div>
<p>In the first iteration, the kernel is aligned with the upper left corner of the original image. An element-wise multiplication is performed and the results are summed. The operation is shown at the top of the figure. In the first iteration, the result was <span class="math inline">\(3\)</span> and it is set at the corresponding position of the final convolved image (feature map). In the next iteration, the kernel is moved one position to the right and again, the final result is <span class="math inline">\(3\)</span> which is set in the next position of the convolved image. The process continues until the kernel reaches the bottom right corner. At the last iteration (9), the result is <span class="math inline">\(1\)</span>.</p>
<p>Now, the convolved image (feature map) represents the features extracted by this particular kernel. Also, note that the feature map is a <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> matrix which is smaller than the original image. It is also possible to force the feature map to have the same size as the original image by padding it with zeros.</p>
<p>Before learning starts, the kernel values are initialized at random. In this example, the kernel has <span class="math inline">\(1\)</span>s in the first row and it has <span class="math inline">\(3\)</span>x<span class="math inline">\(3=9\)</span> parameters. This is whats makes CNNs so efficient since the same kernel is applied to the entire image. This is known as ‘parameter sharing’. Our kernel has <span class="math inline">\(1\)</span>s at the top and zeros elsewhere so it seems that this kernel learned to detect horizontal lines. If we look at the final convolved image we see that the horizontal lines were emphasized by this kernel. This would be a good candidate kernel to differentiate between <span class="math inline">\(7\)</span>s and <span class="math inline">\(0\)</span>s, for example. Since <span class="math inline">\(0\)</span>s does not have long horizontal lines. But maybe it will have difficulties discriminating between <span class="math inline">\(7\)</span>s and <span class="math inline">\(5\)</span>s since both have horizontal lines at the top.</p>
<p>In this example, only <span class="math inline">\(1\)</span> kernel was used but in practice, you may want to have more kernels, each in charge of identifying the best features for the given problem. For example, another kernel could learn to identify diagonal lines which would be useful to differentiate between <span class="math inline">\(7\)</span>s and <span class="math inline">\(5\)</span>s. The number of kernels per convolution layer is a hyperparameter. In the previous example, we could have defined to have <span class="math inline">\(4\)</span> kernels instead of one. In that case, the output of that layer would have been <span class="math inline">\(4\)</span> feature maps of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> each (Figure <a href="deeplearning.html#fig:cnn4kernels">8.28</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:cnn4kernels"></span>
<img src="images/cnn_4kernels.png" alt="A convolution with 4 kernels. The output is 4 feature maps." width="90%" />
<p class="caption">
Figure 8.28: A convolution with 4 kernels. The output is 4 feature maps.
</p>
</div>
<p>What would be the output of a convolution layer with <span class="math inline">\(4\)</span> kernels of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> if it is applied to an RGB color image of size <span class="math inline">\(5\)</span>x<span class="math inline">\(5\)</span>x<span class="math inline">\(3\)</span>)? In that case, the output will be the same (<span class="math inline">\(4\)</span> feature maps of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span>) as if the image were in grayscale (<span class="math inline">\(5\)</span>x<span class="math inline">\(5\)</span>x<span class="math inline">\(1\)</span>). Remember that the number of output feature maps is equal to the number of kernels regardless of the depth of the image. However, in this case, each kernel will have a depth of <span class="math inline">\(3\)</span>. Each depth is applied independently to the corresponding R, G, and B image channels. Thus, each kernel has <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span>x<span class="math inline">\(3=27\)</span> parameters that need to be learned. After applying each kernel to each image channel (in this example, <span class="math inline">\(3\)</span> channels), <strong>the results of each channel are added</strong> and this is why we end up with one feature map per kernel. The following course website has a nice interactive animation of how convolutions are applied to an image with <span class="math inline">\(3\)</span> channels: <a href="https://cs231n.github.io/convolutional-networks/" class="uri">https://cs231n.github.io/convolutional-networks/</a>. In the next section (<em>CNNs with Keras</em>), a couple of examples that demonstrate how to calculate the number of parameters and the outputs’ shape will be presented as well.</p>
</div>
<div id="pooling-operations" class="section level3">
<h3><span class="header-section-number">8.6.2</span> Pooling Operations</h3>
<p>Pooling operations are typically applied after convolution layers. Their purpose is to reduce the size of the data and to emphasize important regions. These operations perform a fixed computation on the image and do no have learnable parameters. Similar to kernels, we need to define a window size. Then, this window is moved throughout the image and a computation is performed on the pixels covered by the window. The difference with kernels is that this window is just a guide but do not have parameters to be learned. The most common pooling operation is <strong>max pooling</strong> which consists of selecting the highest value.
Figure <a href="deeplearning.html#fig:cnnMaxPooling">8.29</a> shows an example of a max pooling operation on a <span class="math inline">\(4\)</span>x<span class="math inline">\(4\)</span> image. The window size is <span class="math inline">\(2\)</span>x<span class="math inline">\(2\)</span> and the stride is <span class="math inline">\(2\)</span>. The latter means that the window moves <span class="math inline">\(2\)</span> places at a time.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnMaxPooling"></span>
<img src="images/cnn_maxpooling.png" alt="Max pooling with a window of size 2x2 and stride = 2." width="100%" />
<p class="caption">
Figure 8.29: Max pooling with a window of size 2x2 and stride = 2.
</p>
</div>
<p>The result of this operation is an image of size <span class="math inline">\(2\)</span>x<span class="math inline">\(2\)</span> which is half of the original one. Aside from max pooling, average pooling can be applied instead. In that case, it computes the mean value across all values covered by the window.</p>
</div>
</div>
<div id="cnns-with-keras" class="section level2">
<h2><span class="header-section-number">8.7</span> CNNs with Keras</h2>

<div class="rmdfolder">
keras_cnns.R
</div>

<p>Keras provides several functions to define convolution layers and pooling operations. In TensorFlow, image dimensions are specified with the following order: height, width, and depth. In Keras, the <code>layer_conv_2d()</code> function is used to add a convolution layer to a sequential model. This function has several arguments but the <span class="math inline">\(6\)</span> most common ones are: <code>filters</code>,<code>kernel_size</code>,<code>strides</code>,<code>padding</code>,<code>activation</code>, and <code>input_shape</code>.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="deeplearning.html#cb180-1"></a><span class="co"># Convolution layer.</span></span>
<span id="cb180-2"><a href="deeplearning.html#cb180-2"></a><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">4</span>, <span class="co"># Number of kernels.</span></span>
<span id="cb180-3"><a href="deeplearning.html#cb180-3"></a>                <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>), <span class="co"># Kernel size.</span></span>
<span id="cb180-4"><a href="deeplearning.html#cb180-4"></a>                <span class="dt">strides =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="co"># Stride.</span></span>
<span id="cb180-5"><a href="deeplearning.html#cb180-5"></a>                <span class="dt">padding =</span> <span class="st">&quot;same&quot;</span>, <span class="co"># Type of padding.</span></span>
<span id="cb180-6"><a href="deeplearning.html#cb180-6"></a>                <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>, <span class="co"># Activation function.</span></span>
<span id="cb180-7"><a href="deeplearning.html#cb180-7"></a>                <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">5</span>,<span class="dv">1</span>)) <span class="co"># Input image dimensions.</span></span>
<span id="cb180-8"><a href="deeplearning.html#cb180-8"></a>                                        <span class="co"># Only specified in first layer.</span></span></code></pre></div>
<p>The <code>filters</code> param specifies the number of kernels. The <code>kernel_size</code> specifies the kernel size (height, width). The <code>strides</code> is an integer or list of <span class="math inline">\(2\)</span> integers, specifying the strides of the convolution along the width and height (the default is <span class="math inline">\(1\)</span>). The <code>padding</code> can take two possible strings: <code>"same"</code> or <code>"valid"</code>. If <code>padding="same"</code> the input image will be padded with zeros based on the kernel size and strides such that the convolved image has the same size as the original one. If <code>padding="valid"</code> it means no padding is applied. The default is <code>"valid"</code>. The <code>activation</code> parameter takes as input a string with the name of the activation function to use. The <code>input_shape</code> parameter is required when this layer is the first one and specifies the dimensions of the input image.</p>
<p>To add a max pooling operation you can use the <code>layer_max_pooling_2d()</code> function. Its most important parameter is <code>pool_size</code>.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="deeplearning.html#cb181-1"></a><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span></code></pre></div>
<p>The <code>pool_size</code> specifies the window size (height, width). By default, the strides will be equal to <code>pool_size</code> but if desired, this can be changed with the <code>strides</code> parameter. This function also accepts a <code>padding</code> parameter similar to the one for <code>layer_max_pooling_2d()</code>.</p>

<div class="rmdinfo">
In Keras, if the stride is not specified, it defaults to the window size (<code>pool_size</code> parameter).
</div>

<p>To illustrate this convolution and pooling operations I will use two simple examples. The complete code for the two examples can be found in the script <code>keras_cnns.R</code>.</p>
<div id="example-1" class="section level3">
<h3><span class="header-section-number">8.7.1</span> Example 1</h3>
<p>Let’s create our first CNN in Keras. For now, this CNN will not be trained but only its architecture will be defined. The objective is to understand the building blocks of the network. In the next section, we will build and train a CNN that detects smiles from image faces.</p>
<p>Our network will consist of <strong><span class="math inline">\(1\)</span> convolution layer</strong>, <strong><span class="math inline">\(1\)</span> max pooling layer</strong>, <strong><span class="math inline">\(1\)</span> fully connected hidden layer</strong>, and <strong><span class="math inline">\(1\)</span> output layer</strong> as if this were a classification problem. The code to build such a network is shown below and the output of the <code>summary()</code> function in Figure <a href="deeplearning.html#fig:cnnEx1">8.30</a>.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="deeplearning.html#cb182-1"></a><span class="kw">library</span>(keras)</span>
<span id="cb182-2"><a href="deeplearning.html#cb182-2"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span>
<span id="cb182-3"><a href="deeplearning.html#cb182-3"></a></span>
<span id="cb182-4"><a href="deeplearning.html#cb182-4"></a>model <span class="op">%&gt;%</span></span>
<span id="cb182-5"><a href="deeplearning.html#cb182-5"></a><span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">4</span>,</span>
<span id="cb182-6"><a href="deeplearning.html#cb182-6"></a>                <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb182-7"><a href="deeplearning.html#cb182-7"></a>                <span class="dt">padding =</span> <span class="st">&quot;valid&quot;</span>,</span>
<span id="cb182-8"><a href="deeplearning.html#cb182-8"></a>                <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>,</span>
<span id="cb182-9"><a href="deeplearning.html#cb182-9"></a>                <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">10</span>,<span class="dv">1</span>)) <span class="op">%&gt;%</span></span>
<span id="cb182-10"><a href="deeplearning.html#cb182-10"></a><span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb182-11"><a href="deeplearning.html#cb182-11"></a><span class="st">  </span><span class="kw">layer_flatten</span>() <span class="op">%&gt;%</span></span>
<span id="cb182-12"><a href="deeplearning.html#cb182-12"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb182-13"><a href="deeplearning.html#cb182-13"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb182-14"><a href="deeplearning.html#cb182-14"></a></span>
<span id="cb182-15"><a href="deeplearning.html#cb182-15"></a><span class="kw">summary</span>(model)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cnnEx1"></span>
<img src="images/cnn_summaryEx1.png" alt="Output of summary()." width="90%" />
<p class="caption">
Figure 8.30: Output of summary().
</p>
</div>
<p>The first convolution layer has <span class="math inline">\(4\)</span> kernels of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> and a ReLU as the activation function. The padding is set to <code>"valid"</code> so no padding will be done. The input image has a size of <span class="math inline">\(10\)</span>x<span class="math inline">\(10\)</span>x<span class="math inline">\(1\)</span> (height, width, depth). Then, we are applying max pooling with a window size of <span class="math inline">\(2\)</span>x<span class="math inline">\(2\)</span>. Later, the output is flattened and fed into a fully connected layer with <span class="math inline">\(32\)</span> units. Finally, the output layer as <span class="math inline">\(2\)</span> units with a softmax activation function for classification.</p>
<p>From the summary, if you look at the output of the first Conv2D layer it shows (None, 8, 8, 4). The ‘None’ means that the number of input images is not fixed and will depend on the batch size. The next two numbers correspond to the height and width which are both <span class="math inline">\(8\)</span>. This is because the image was not padded and after applying the convolution operation on the original <span class="math inline">\(10\)</span>x<span class="math inline">\(10\)</span> height and width image, its dimensions are reduced to <span class="math inline">\(8\)</span>. The last number (<span class="math inline">\(4\)</span>) is the number of feature maps which is equal to the number of kernels (<code>filters=4</code>). The number of parameters is <span class="math inline">\(40\)</span> (last column). This is because there are <span class="math inline">\(4\)</span> kernels with <span class="math inline">\(3\)</span>x<span class="math inline">\(3=9\)</span> parameters each, and there is one bias per kernel included by default: <span class="math inline">\(4 \times 3 \times 3 \times + 4 = 40\)</span>.</p>
<p>The output of MaxPooling2D is (None, 4, 4, 4). The height and width are <span class="math inline">\(4\)</span> because the pool size was <span class="math inline">\(2\)</span> and the stride was <span class="math inline">\(2\)</span>. This had the effect of reducing to half the height and width of the output of the previous layer. Max pooling preserves the number of feature maps, thus, the last number is <span class="math inline">\(4\)</span> (the number of feature maps from the previous layer). Max pooling does not have any learnable parameters since it applies a fixed operation every time.</p>
<p>Before passing the downsampled feature maps to the next fully connected layer they need to be <strong>flattened</strong> into a <span class="math inline">\(1\)</span>-dimensional array. This is done with the <code>layer_flatten()</code> function and its output has a shape of (None, 64) which corresponds to the <span class="math inline">\(4 \times 4 \times 4 =64\)</span> features of the previous layer. The next fully connected layer has <span class="math inline">\(32\)</span> units each with a connection with every one of the <span class="math inline">\(64\)</span> input features. Each unit has a bias. Thus the number of parameters is <span class="math inline">\(64 \times 32 + 32 = 2080\)</span>.</p>
<p>Finally the output layer has <span class="math inline">\(32 \times 2 + 2=66\)</span> parameters. And the entire network has <span class="math inline">\(2,186\)</span> parameters! Now, you can try to modify, the kernel size, the strides, the padding, and input shape and see how the output dimensions and the number of parameters vary.</p>
</div>
<div id="example-2" class="section level3">
<h3><span class="header-section-number">8.7.2</span> Example 2</h3>
<p>Now let’s try another example but this time the input image will have a depth of <span class="math inline">\(3\)</span> simulating an RGB image.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="deeplearning.html#cb183-1"></a>model2 &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span>
<span id="cb183-2"><a href="deeplearning.html#cb183-2"></a></span>
<span id="cb183-3"><a href="deeplearning.html#cb183-3"></a>model2 <span class="op">%&gt;%</span></span>
<span id="cb183-4"><a href="deeplearning.html#cb183-4"></a><span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">16</span>,</span>
<span id="cb183-5"><a href="deeplearning.html#cb183-5"></a>                <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb183-6"><a href="deeplearning.html#cb183-6"></a>                <span class="dt">padding =</span> <span class="st">&quot;same&quot;</span>,</span>
<span id="cb183-7"><a href="deeplearning.html#cb183-7"></a>                <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>,</span>
<span id="cb183-8"><a href="deeplearning.html#cb183-8"></a>                <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">3</span>)) <span class="op">%&gt;%</span></span>
<span id="cb183-9"><a href="deeplearning.html#cb183-9"></a><span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb183-10"><a href="deeplearning.html#cb183-10"></a><span class="st">  </span><span class="kw">layer_flatten</span>() <span class="op">%&gt;%</span></span>
<span id="cb183-11"><a href="deeplearning.html#cb183-11"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb183-12"><a href="deeplearning.html#cb183-12"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">5</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span>
<span id="cb183-13"><a href="deeplearning.html#cb183-13"></a></span>
<span id="cb183-14"><a href="deeplearning.html#cb183-14"></a><span class="kw">summary</span>(model2)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cnnEx2"></span>
<img src="images/cnn_summaryEx2.png" alt="Output of summary()." width="90%" />
<p class="caption">
Figure 8.31: Output of summary().
</p>
</div>
<p>The output height and width of the first Conv2D layer is <span class="math inline">\(28\)</span> which is the same as the input image size. This is because this time we set <code>padding = "same"</code> and the image dimensions were preserved. The <span class="math inline">\(16\)</span> corresponds to the number of feature maps which was set with <code>filters = 16</code>.</p>
<p>The total parameter count for this layer is <span class="math inline">\(448\)</span>. Each kernel has <span class="math inline">\(3 \times 3 = 9\)</span> parameters. There are <span class="math inline">\(16\)</span> kernels but each kernel has a <span class="math inline">\(depth=3\)</span> because the input image is RGB. <span class="math inline">\(9 \times 16[kernels] \times 3[depth] + 16[biases] = 448\)</span>. Notice that even though each kernel has a depth of <span class="math inline">\(3\)</span> the output number of feature maps of this layer is <span class="math inline">\(16\)</span> and not <span class="math inline">\(16 \times 3 = 48\)</span>. This is because as mentioned before, each kernel produces a single feature map regardless of the depth because the values are summed depth-wise. The rest of the layers are similar to the previous example.</p>
</div>
</div>
<div id="cnnSmile" class="section level2">
<h2><span class="header-section-number">8.8</span> Smiles Detection with a CNN</h2>

<div class="rmdfolder">
keras_smile_detection.R
</div>

<p>In this section, we will build a CNN that detects smiling and non-smiling faces from pictures from the <em>SMILES</em> dataset. This information could be used, for example, to analyze smiling patterns during job interviews, exams, etc. For this task, we will use a cropped <span class="citation">(Sanderson and Lovell <a href="#ref-sanderson2009multi" role="doc-biblioref">2009</a>)</span> version of the Labeled Faces in the Wild (LFW) database <span class="citation">(Huang et al. <a href="#ref-huang2008labeled" role="doc-biblioref">2008</a>)</span>. A subset of the database was labeled by <span class="citation">Arigbabu et al. (<a href="#ref-arigbabu2016smile" role="doc-biblioref">2016</a>)</span>, <span class="citation">Arigbabu (<a href="#ref-olasimbo" role="doc-biblioref">2017</a>)</span>. The labels are provided as two text files, each, containing the list of files that correspond to smiling and non-smiling faces. The dataset can be downloaded from: <a href="http://conradsanderson.id.au/lfwcrop/" class="uri">http://conradsanderson.id.au/lfwcrop/</a> and the labels list from: <a href="https://data.mendeley.com/datasets/yz4v8tb3tp/5" class="uri">https://data.mendeley.com/datasets/yz4v8tb3tp/5</a>. See Appendix <a href="appendixDatasets.html#appendixDatasets">B</a> for instructions on how to setup the dataset.</p>
<p>The smiling set has <span class="math inline">\(600\)</span> pictures and the non-smiling has <span class="math inline">\(603\)</span> pictures. Figure <a href="deeplearning.html#fig:cnnSmileNotSmile">8.32</a> shows an example of one image from each of the sets.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnSmileNotSmile"></span>
<img src="images/cnn_smilenosmile.png" alt="Example images of the smiling dataset." width="60%" />
<p class="caption">
Figure 8.32: Example images of the smiling dataset.
</p>
</div>
<p>The script <code>keras_smile_detection.R</code> has the full code of the analysis. First, we load the list of smiling pictures.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="deeplearning.html#cb184-1"></a>datapath &lt;-<span class="st"> </span><span class="kw">file.path</span>(datasets_path,<span class="st">&quot;smiles&quot;</span>)</span>
<span id="cb184-2"><a href="deeplearning.html#cb184-2"></a>smile.list &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="kw">paste0</span>(datapath,<span class="st">&quot;SMILE_list.txt&quot;</span>))</span>
<span id="cb184-3"><a href="deeplearning.html#cb184-3"></a><span class="kw">head</span>(smile.list)</span>
<span id="cb184-4"><a href="deeplearning.html#cb184-4"></a><span class="co">#&gt; V1</span></span>
<span id="cb184-5"><a href="deeplearning.html#cb184-5"></a><span class="co">#&gt; 1     James_Jones_0001.jpg</span></span>
<span id="cb184-6"><a href="deeplearning.html#cb184-6"></a><span class="co">#&gt; 2     James_Kelly_0009.jpg</span></span>
<span id="cb184-7"><a href="deeplearning.html#cb184-7"></a><span class="co">#&gt; 3 James_McPherson_0001.jpg</span></span>
<span id="cb184-8"><a href="deeplearning.html#cb184-8"></a><span class="co">#&gt; 4      James_Watt_0001.jpg</span></span>
<span id="cb184-9"><a href="deeplearning.html#cb184-9"></a><span class="co">#&gt; 5     Jamie_Carey_0001.jpg</span></span>
<span id="cb184-10"><a href="deeplearning.html#cb184-10"></a><span class="co">#&gt; 6      Jamie_King_0001.jpg</span></span>
<span id="cb184-11"><a href="deeplearning.html#cb184-11"></a></span>
<span id="cb184-12"><a href="deeplearning.html#cb184-12"></a><span class="co"># Substitute jpg with ppm.</span></span>
<span id="cb184-13"><a href="deeplearning.html#cb184-13"></a>smile.list &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;jpg&quot;</span>, <span class="st">&quot;ppm&quot;</span>, smile.list<span class="op">$</span>V1)</span></code></pre></div>
<p>The SMILE_list.txt points to the names of pictures in jpg format but we have them in ppm format so the jpg extension is replaced by ppm with the <code>gsub()</code> function. Since the images are in ppm format, we can use the <code>pixmap</code> library <span class="citation">(Bivand, Leisch, and Maechler <a href="#ref-pixmap" role="doc-biblioref">2011</a>)</span> to read and plot them. The <code>print()</code> function can be used to display the image properties. Here, we can see that these are RGB images of <span class="math inline">\(64\)</span>x<span class="math inline">\(64\)</span> pixels.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="deeplearning.html#cb185-1"></a><span class="kw">library</span>(pixmap)</span>
<span id="cb185-2"><a href="deeplearning.html#cb185-2"></a></span>
<span id="cb185-3"><a href="deeplearning.html#cb185-3"></a><span class="co"># Read an smiling face.</span></span>
<span id="cb185-4"><a href="deeplearning.html#cb185-4"></a>img &lt;-<span class="st"> </span><span class="kw">read.pnm</span>(<span class="kw">paste0</span>(datapath,<span class="st">&quot;faces/&quot;</span>, smile.list[<span class="dv">10</span>]), <span class="dt">cellres =</span> <span class="dv">1</span>)</span>
<span id="cb185-5"><a href="deeplearning.html#cb185-5"></a></span>
<span id="cb185-6"><a href="deeplearning.html#cb185-6"></a><span class="co"># Plot the image.</span></span>
<span id="cb185-7"><a href="deeplearning.html#cb185-7"></a><span class="kw">plot</span>(img)</span>
<span id="cb185-8"><a href="deeplearning.html#cb185-8"></a></span>
<span id="cb185-9"><a href="deeplearning.html#cb185-9"></a><span class="co"># Print its properties.</span></span>
<span id="cb185-10"><a href="deeplearning.html#cb185-10"></a><span class="kw">print</span>(img)</span>
<span id="cb185-11"><a href="deeplearning.html#cb185-11"></a></span>
<span id="cb185-12"><a href="deeplearning.html#cb185-12"></a><span class="co">#&gt; Pixmap image</span></span>
<span id="cb185-13"><a href="deeplearning.html#cb185-13"></a><span class="co">#&gt; Type          : pixmapRGB </span></span>
<span id="cb185-14"><a href="deeplearning.html#cb185-14"></a><span class="co">#&gt; Size          : 64x64 </span></span>
<span id="cb185-15"><a href="deeplearning.html#cb185-15"></a><span class="co">#&gt; Resolution    : 1x1 </span></span>
<span id="cb185-16"><a href="deeplearning.html#cb185-16"></a><span class="co">#&gt; Bounding box  : 0 0 64 64 </span></span></code></pre></div>
<p>Then we are going to load the images into two arrays <code>smiling.images</code> and <code>nonsmiling.images</code> (code omitted here). If we print the array dimensions we see that there are <span class="math inline">\(600\)</span> smiling images of size <span class="math inline">\(64 \times 64 \times 3\)</span>.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="deeplearning.html#cb186-1"></a><span class="co"># Print dimensions.</span></span>
<span id="cb186-2"><a href="deeplearning.html#cb186-2"></a><span class="kw">dim</span>(smiling.images)</span>
<span id="cb186-3"><a href="deeplearning.html#cb186-3"></a><span class="co">#&gt; [1] 600  64  64   3</span></span></code></pre></div>
<p>If we print the minimum and maximum values we see that they are <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> so there is no need for normalization.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="deeplearning.html#cb187-1"></a><span class="kw">max</span>(smiling.images)</span>
<span id="cb187-2"><a href="deeplearning.html#cb187-2"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb187-3"><a href="deeplearning.html#cb187-3"></a><span class="kw">min</span>(smiling.images)</span>
<span id="cb187-4"><a href="deeplearning.html#cb187-4"></a><span class="co">#&gt; [1] 0</span></span></code></pre></div>
<p>The next step is to randomly split the dataset into train and test sets. We will use <span class="math inline">\(85\%\)</span> for the train set and <span class="math inline">\(15\%\)</span> for the test set. We will use the <code>validation_split</code> parameter of the <code>fit()</code> function to choose a small percent (<span class="math inline">\(10\%\)</span>) of the train set to be used as the validation set during training.</p>
<p>After creating the train and test sets, the train set images and labels are stored in <code>trainX</code> and <code>trainY</code> respectively and the test set data is stored in <code>testX</code> and <code>testY</code>. The labels in <code>trainY</code> and <code>testY</code> were one-hot encoded. Now that the data is in place, let’s build the CNN.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="deeplearning.html#cb188-1"></a>model &lt;-<span class="st"> </span><span class="kw">keras_model_sequential</span>()</span>
<span id="cb188-2"><a href="deeplearning.html#cb188-2"></a></span>
<span id="cb188-3"><a href="deeplearning.html#cb188-3"></a>model <span class="op">%&gt;%</span></span>
<span id="cb188-4"><a href="deeplearning.html#cb188-4"></a><span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">8</span>,</span>
<span id="cb188-5"><a href="deeplearning.html#cb188-5"></a>                <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb188-6"><a href="deeplearning.html#cb188-6"></a>                <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>,</span>
<span id="cb188-7"><a href="deeplearning.html#cb188-7"></a>                <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">64</span>,<span class="dv">64</span>,<span class="dv">3</span>)) <span class="op">%&gt;%</span></span>
<span id="cb188-8"><a href="deeplearning.html#cb188-8"></a><span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb188-9"><a href="deeplearning.html#cb188-9"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="fl">0.25</span>) <span class="op">%&gt;%</span></span>
<span id="cb188-10"><a href="deeplearning.html#cb188-10"></a><span class="st">  </span><span class="kw">layer_conv_2d</span>(<span class="dt">filters =</span> <span class="dv">16</span>,</span>
<span id="cb188-11"><a href="deeplearning.html#cb188-11"></a>                <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb188-12"><a href="deeplearning.html#cb188-12"></a>                <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb188-13"><a href="deeplearning.html#cb188-13"></a><span class="st">  </span><span class="kw">layer_max_pooling_2d</span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb188-14"><a href="deeplearning.html#cb188-14"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="fl">0.25</span>) <span class="op">%&gt;%</span></span>
<span id="cb188-15"><a href="deeplearning.html#cb188-15"></a><span class="st">  </span><span class="kw">layer_flatten</span>() <span class="op">%&gt;%</span></span>
<span id="cb188-16"><a href="deeplearning.html#cb188-16"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span></span>
<span id="cb188-17"><a href="deeplearning.html#cb188-17"></a><span class="st">  </span><span class="kw">layer_dropout</span>(<span class="fl">0.5</span>) <span class="op">%&gt;%</span></span>
<span id="cb188-18"><a href="deeplearning.html#cb188-18"></a><span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">2</span>, <span class="dt">activation =</span> <span class="st">&#39;softmax&#39;</span>)</span></code></pre></div>
<p>Our CNN consists of two convolution layers each followed by a max pooling operation and dropout. The feature maps are then flattened and passed to a fully connected layer with <span class="math inline">\(32\)</span> units followed by a dropout. Since this is a binary classification problem (<em>‘smile’</em> v.s. <em>‘non-smile’</em>) the output layer has <span class="math inline">\(2\)</span> units with a softmax activation function. Now the model can be compiled and the <code>fit()</code> function used to begin the training!</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="deeplearning.html#cb189-1"></a><span class="co"># Compile model.</span></span>
<span id="cb189-2"><a href="deeplearning.html#cb189-2"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(</span>
<span id="cb189-3"><a href="deeplearning.html#cb189-3"></a>  <span class="dt">loss =</span> <span class="st">&#39;categorical_crossentropy&#39;</span>,</span>
<span id="cb189-4"><a href="deeplearning.html#cb189-4"></a>  <span class="dt">optimizer =</span> <span class="kw">optimizer_sgd</span>(<span class="dt">lr =</span> <span class="fl">0.01</span>),</span>
<span id="cb189-5"><a href="deeplearning.html#cb189-5"></a>  <span class="dt">metrics =</span> <span class="kw">c</span>(<span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb189-6"><a href="deeplearning.html#cb189-6"></a>)</span>
<span id="cb189-7"><a href="deeplearning.html#cb189-7"></a></span>
<span id="cb189-8"><a href="deeplearning.html#cb189-8"></a><span class="co"># Fit model.</span></span>
<span id="cb189-9"><a href="deeplearning.html#cb189-9"></a>history &lt;-<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">fit</span>(</span>
<span id="cb189-10"><a href="deeplearning.html#cb189-10"></a>  trainX, trainY,</span>
<span id="cb189-11"><a href="deeplearning.html#cb189-11"></a>  <span class="dt">epochs =</span> <span class="dv">50</span>,</span>
<span id="cb189-12"><a href="deeplearning.html#cb189-12"></a>  <span class="dt">batch_size =</span> <span class="dv">8</span>,</span>
<span id="cb189-13"><a href="deeplearning.html#cb189-13"></a>  <span class="dt">validation_split =</span> <span class="fl">0.10</span>,</span>
<span id="cb189-14"><a href="deeplearning.html#cb189-14"></a>  <span class="dt">verbose =</span> <span class="dv">1</span>,</span>
<span id="cb189-15"><a href="deeplearning.html#cb189-15"></a>  <span class="dt">view_metrics =</span> <span class="ot">TRUE</span></span>
<span id="cb189-16"><a href="deeplearning.html#cb189-16"></a>)</span></code></pre></div>
<p>We are using a stochastic gradient descent optimizer with a learning rate of <span class="math inline">\(0.01\)</span> and cross-entropy as the loss function. We can use <span class="math inline">\(10\%\)</span> of the train set as the validation set by setting <code>validation_split = 0.10</code>. Once the training is done, we can plot the <em>loss</em> and <em>accuracy</em> of each epoch.</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="deeplearning.html#cb190-1"></a><span class="kw">plot</span>(history)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cnnSmilesLoss"></span>
<img src="images/cnn_smiles_loss.png" alt="Train/test loss and accuracy." width="90%" />
<p class="caption">
Figure 8.33: Train/test loss and accuracy.
</p>
</div>
<p>After epoch <span class="math inline">\(25\)</span> it looks like the training loss is decreasing faster than the validation loss. After epoch <span class="math inline">\(40\)</span> it seems that the model starts to overfit (the validation loss is increasing a bit). If we look at the accuracy, it seems that it starts to get flat after epoch <span class="math inline">\(30\)</span>. We can evaluate the model on the test set:</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="deeplearning.html#cb191-1"></a><span class="co"># Evaluate model on test set.</span></span>
<span id="cb191-2"><a href="deeplearning.html#cb191-2"></a>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">evaluate</span>(testX, testY)</span>
<span id="cb191-3"><a href="deeplearning.html#cb191-3"></a><span class="co">#&gt; $loss</span></span>
<span id="cb191-4"><a href="deeplearning.html#cb191-4"></a><span class="co">#&gt; [1] 0.1862139</span></span>
<span id="cb191-5"><a href="deeplearning.html#cb191-5"></a></span>
<span id="cb191-6"><a href="deeplearning.html#cb191-6"></a><span class="co">#&gt; $acc</span></span>
<span id="cb191-7"><a href="deeplearning.html#cb191-7"></a><span class="co">#&gt; [1] 0.9222222</span></span></code></pre></div>
<p>An accuracy of <span class="math inline">\(92\%\)</span> is pretty decent if we take into account that we didn’t have to do any image preprocessing or feature extraction! We can print the predictions of the first <span class="math inline">\(16\)</span> test images.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnSmileResults"></span>
<img src="images/cnn_smile_predictions.png" alt="Predictions of the first 16 test set images. Correct predictions are in green and incorrect ones in red." width="90%" />
<p class="caption">
Figure 8.34: Predictions of the first 16 test set images. Correct predictions are in green and incorrect ones in red.
</p>
</div>
<p>From those <span class="math inline">\(16\)</span>, all but one were correctly classified. The correct ones are shown in green and the incorrect one in red. Some faces seem to be smiling (last row, third image) but the mouth is closed, though. It seems that this CNN classifies images as <em>‘smiling’</em> only when the mouth is open which may be the way the train labels were defined.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="SummaryDeepLearning" class="section level2">
<h2><span class="header-section-number">8.9</span> Summary</h2>
<p><strong>Deep learning (DL)</strong> consists of a set of different architectures and algorithms. As of now, it mainly focuses on artificial neural networks (ANNs). This chapter introduced two main types of DL models (ANNs and CNNs) and their application to behavior analysis.</p>
<ul>
<li>Artificial neural networks (ANNs) are mathematical models inspired by the brain. But that does not mean they work the same as the brain.</li>
<li>The <strong>perceptron</strong> is one of the simplest ANNs.</li>
<li>ANNs consist of an input layer, hidden layer(s) and an output layer.</li>
<li>Deep networks has many hidden layers.</li>
<li><strong>Gradient descent</strong> can be used to learn the parameters of a network.</li>
<li>Overfitting is a recurring problem in ANNs. Some methods like <strong>dropout</strong> and <strong>early stopping</strong> can be used to reduce the effect of overfitting.</li>
<li>A convolutional neural network (CNN) is a type of ANN that can process <span class="math inline">\(N\)</span>-dimensional arrays very efficiently. They are used mainly for computer vision tasks.</li>
<li>CNNs consist of <strong>convolution</strong> and <strong>pooling</strong> layers.</li>
</ul>
<p><img src="images/comic_spider.png" width="98%" style="display: block; margin: auto;" />
</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-keras">
<p>Allaire, JJ, and François Chollet. 2019. <em>Keras: R Interface to ’Keras’</em>. <a href="https://CRAN.R-project.org/package=keras">https://CRAN.R-project.org/package=keras</a>.</p>
</div>
<div id="ref-olasimbo">
<p>Arigbabu, Olasimbo. 2017. <em>Dataset for Smile Detection from Face Images</em>. <a href="http://dx.doi.org/10.17632/yz4v8tb3tp.5">http://dx.doi.org/10.17632/yz4v8tb3tp.5</a>.</p>
</div>
<div id="ref-arigbabu2016smile">
<p>Arigbabu, Olasimbo Ayodeji, Saif Mahmood, Sharifah Mumtazah Syed Ahmad, and Abayomi A Arigbabu. 2016. “Smile Detection Using Hybrid Face Representation.” <em>Journal of Ambient Intelligence and Humanized Computing</em> 7 (3): 415–26.</p>
</div>
<div id="ref-pixmap">
<p>Bivand, Roger, Friedrich Leisch, and Martin Maechler. 2011. <em>Pixmap: Bitmap Images (“Pixel Maps”)</em>. <a href="https://CRAN.R-project.org/package=pixmap">https://CRAN.R-project.org/package=pixmap</a>.</p>
</div>
<div id="ref-Chollet2018">
<p>Chollet, François, and J. J. Allaire. 2018. <em>Deep Learning with R</em>. Manning.</p>
</div>
<div id="ref-huang2008labeled">
<p>Huang, Gary B, Marwan Mattar, Tamara Berg, and Eric Learned-Miller. 2008. “Labeled Faces in the Wild: A Database Forstudying Face Recognition in Unconstrained Environments.” In.</p>
</div>
<div id="ref-huang2003">
<p>Huang, Guang-Bin. 2003. “Learning Capability and Storage Capacity of Two-Hidden-Layer Feedforward Networks.” <em>IEEE Transactions on Neural Networks</em> 14 (2): 274–81.</p>
</div>
<div id="ref-keskar2016">
<p>Keskar, Nitish Shirish, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. 2016. “On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima.” <a href="http://arxiv.org/abs/1609.04836">http://arxiv.org/abs/1609.04836</a>.</p>
</div>
<div id="ref-rosenblatt1958">
<p>Rosenblatt, Frank. 1958. “The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.” <em>Psychological Review</em> 65 (6): 386.</p>
</div>
<div id="ref-sanderson2009multi">
<p>Sanderson, Conrad, and Brian C Lovell. 2009. “Multi-Region Probabilistic Histograms for Robust and Scalable Identity Inference.” In <em>International Conference on Biometrics</em>, 199–208. Springer.</p>
</div>
<div id="ref-srivastava14">
<p>Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. “Dropout: A Simple Way to Prevent Neural Networks from Overfitting.” <em>Journal of Machine Learning Research</em> 15 (56): 1929–58. <a href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a>.</p>
</div>
<div id="ref-kirill">
<p>Yashuk, Kirill. 2019. <em>Classify Gestures by Reading Muscle Activity: A Recording of Human Hand Muscle Activity Producing Four Different Hand Gestures</em>. <a href="https://www.kaggle.com/kyr7plus/emg-4">https://www.kaggle.com/kyr7plus/emg-4</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="19">
<li id="fn19"><p><a href="http://neuralnetworksanddeeplearning.com/chap2.html" class="uri">http://neuralnetworksanddeeplearning.com/chap2.html</a><a href="deeplearning.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p><a href="https://www.tensorflow.org" class="uri">https://www.tensorflow.org</a><a href="deeplearning.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p><a href="https://keras.io/" class="uri">https://keras.io/</a><a href="deeplearning.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p><a href="https://en.wikipedia.org/wiki/Theano_(software)" class="uri">https://en.wikipedia.org/wiki/Theano_(software)</a><a href="deeplearning.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p><a href="https://en.wikipedia.org/wiki/Microsoft_Cognitive_Toolkit" class="uri">https://en.wikipedia.org/wiki/Microsoft_Cognitive_Toolkit</a><a href="deeplearning.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p><a href="https://www.heatonresearch.com/2017/06/01/hidden-layers.html" class="uri">https://www.heatonresearch.com/2017/06/01/hidden-layers.html</a><a href="deeplearning.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p><a href="https://keras.io/api/optimizers/" class="uri">https://keras.io/api/optimizers/</a><a href="deeplearning.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p><a href="https://keras.io/api/optimizers/adam/" class="uri">https://keras.io/api/optimizers/adam/</a><a href="deeplearning.html#fnref26" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="representations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiuser.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
