<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8.6 Convolutional Neural Networks | Behavior Analysis with Machine Learning and R</title>
  <meta name="description" content="8.6 Convolutional Neural Networks | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="8.6 Convolutional Neural Networks | Behavior Analysis with Machine Learning and R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="8.6 Convolutional Neural Networks | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8.6 Convolutional Neural Networks | Behavior Analysis with Machine Learning and R" />
  
  <meta name="twitter:description" content="8.6 Convolutional Neural Networks | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Enrique Garcia Ceja" />


<meta name="date" content="2020-09-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="fine-tuning-a-neural-network.html"/>
<link rel="next" href="cnns-with-keras.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/d3-4.9.0/d3.min.js"></script>
<script src="libs/d3-tip-0.7.1/index-min.js"></script>
<link href="libs/d3panels-1.4.9/d3panels.min.css" rel="stylesheet" />
<script src="libs/d3panels-1.4.9/d3panels.min.js"></script>
<script src="libs/qtlcharts_iplotCorr-0.11.6/iplotCorr.js"></script>
<script src="libs/qtlcharts_iplotCorr-0.11.6/iplotCorr_noscat.js"></script>
<script src="libs/iplotCorr-binding-0.11.6/iplotCorr.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178679335-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178679335-1', { 'anonymize_ip': true });
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="#">Behavior Analysis with Machine Learning and R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#supplemental-material"><i class="fa fa-check"></i>Supplemental Material</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.2" data-path="taxonomy.html"><a href="taxonomy.html"><i class="fa fa-check"></i><b>1.2</b> Types of Machine Learning</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> Terminology</a><ul>
<li class="chapter" data-level="1.3.1" data-path="terminology.html"><a href="terminology.html#tables"><i class="fa fa-check"></i><b>1.3.1</b> Tables</a></li>
<li class="chapter" data-level="1.3.2" data-path="terminology.html"><a href="terminology.html#variable-types"><i class="fa fa-check"></i><b>1.3.2</b> Variable Types</a></li>
<li class="chapter" data-level="1.3.3" data-path="terminology.html"><a href="terminology.html#predictive-models"><i class="fa fa-check"></i><b>1.3.3</b> Predictive Models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="pipeline.html"><a href="pipeline.html"><i class="fa fa-check"></i><b>1.4</b> Data Analysis Pipeline</a></li>
<li class="chapter" data-level="1.5" data-path="trainingeval.html"><a href="trainingeval.html"><i class="fa fa-check"></i><b>1.5</b> Evaluating Predictive Models</a></li>
<li class="chapter" data-level="1.6" data-path="simple-classification-example.html"><a href="simple-classification-example.html"><i class="fa fa-check"></i><b>1.6</b> Simple Classification Example</a><ul>
<li class="chapter" data-level="1.6.1" data-path="simple-classification-example.html"><a href="simple-classification-example.html#k-fold-cross-validation-example"><i class="fa fa-check"></i><b>1.6.1</b> K-fold Cross-Validation Example</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="simple-regression-example.html"><a href="simple-regression-example.html"><i class="fa fa-check"></i><b>1.7</b> Simple Regression Example</a></li>
<li class="chapter" data-level="1.8" data-path="underfitting-and-overfitting.html"><a href="underfitting-and-overfitting.html"><i class="fa fa-check"></i><b>1.8</b> Underfitting and Overfitting</a></li>
<li class="chapter" data-level="1.9" data-path="bias-and-variance.html"><a href="bias-and-variance.html"><i class="fa fa-check"></i><b>1.9</b> Bias and Variance</a></li>
<li class="chapter" data-level="1.10" data-path="SummaryIntro.html"><a href="SummaryIntro.html"><i class="fa fa-check"></i><b>1.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>2</b> Predicting Behavior with Classification Models</a><ul>
<li class="chapter" data-level="2.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html"><i class="fa fa-check"></i><b>2.1</b> <em>k</em>-nearest Neighbors</a><ul>
<li class="chapter" data-level="2.1.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#indoor-location-with-wi-fi-signals"><i class="fa fa-check"></i><b>2.1.1</b> Indoor Location with Wi-Fi Signals</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="performance-metrics.html"><a href="performance-metrics.html"><i class="fa fa-check"></i><b>2.2</b> Performance Metrics</a></li>
<li class="chapter" data-level="2.3" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>2.3</b> Decision Trees</a><ul>
<li class="chapter" data-level="2.3.1" data-path="decision-trees.html"><a href="decision-trees.html#activityRecognition"><i class="fa fa-check"></i><b>2.3.1</b> Activity Recognition with Smartphones</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="dynamic-time-warping.html"><a href="dynamic-time-warping.html"><i class="fa fa-check"></i><b>2.4</b> Dynamic Time Warping</a><ul>
<li class="chapter" data-level="2.4.1" data-path="dynamic-time-warping.html"><a href="dynamic-time-warping.html#sechandgestures"><i class="fa fa-check"></i><b>2.4.1</b> Hand Gesture Recognition</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="summaryClassification.html"><a href="summaryClassification.html"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>3</b> Predicting Behavior with Ensemble Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>3.1</b> Bagging</a><ul>
<li class="chapter" data-level="3.1.1" data-path="bagging.html"><a href="bagging.html#activity-recognition-with-bagging"><i class="fa fa-check"></i><b>3.1.1</b> Activity recognition with Bagging</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>3.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.3" data-path="stacked-generalization.html"><a href="stacked-generalization.html"><i class="fa fa-check"></i><b>3.3</b> Stacked Generalization</a></li>
<li class="chapter" data-level="3.4" data-path="multiviewhometasks.html"><a href="multiviewhometasks.html"><i class="fa fa-check"></i><b>3.4</b> Multi-view Stacking for Home Tasks Recognition</a></li>
<li class="chapter" data-level="3.5" data-path="SummaryEnsemble.html"><a href="SummaryEnsemble.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="edavis.html"><a href="edavis.html"><i class="fa fa-check"></i><b>4</b> Exploring and Visualizing Behavioral Data</a><ul>
<li class="chapter" data-level="4.1" data-path="talking-with-field-experts.html"><a href="talking-with-field-experts.html"><i class="fa fa-check"></i><b>4.1</b> Talking with Field Experts</a></li>
<li class="chapter" data-level="4.2" data-path="summary-statistics.html"><a href="summary-statistics.html"><i class="fa fa-check"></i><b>4.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="4.3" data-path="class-distributions.html"><a href="class-distributions.html"><i class="fa fa-check"></i><b>4.3</b> Class Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="user-class-sparsity-matrix.html"><a href="user-class-sparsity-matrix.html"><i class="fa fa-check"></i><b>4.4</b> User-Class Sparsity Matrix</a></li>
<li class="chapter" data-level="4.5" data-path="boxplots.html"><a href="boxplots.html"><i class="fa fa-check"></i><b>4.5</b> Boxplots</a></li>
<li class="chapter" data-level="4.6" data-path="correlation-plots.html"><a href="correlation-plots.html"><i class="fa fa-check"></i><b>4.6</b> Correlation Plots</a><ul>
<li class="chapter" data-level="4.6.1" data-path="correlation-plots.html"><a href="correlation-plots.html#interactive-correlation-plots"><i class="fa fa-check"></i><b>4.6.1</b> Interactive Correlation Plots</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="timeseries.html"><a href="timeseries.html"><i class="fa fa-check"></i><b>4.7</b> Timeseries</a><ul>
<li class="chapter" data-level="4.7.1" data-path="timeseries.html"><a href="timeseries.html#interactive-timeseries"><i class="fa fa-check"></i><b>4.7.1</b> Interactive Timeseries</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html"><i class="fa fa-check"></i><b>4.8</b> Multidimensional Scaling (MDS)</a></li>
<li class="chapter" data-level="4.9" data-path="heatmaps.html"><a href="heatmaps.html"><i class="fa fa-check"></i><b>4.9</b> Heatmaps</a></li>
<li class="chapter" data-level="4.10" data-path="automated-eda.html"><a href="automated-eda.html"><i class="fa fa-check"></i><b>4.10</b> Automated EDA</a></li>
<li class="chapter" data-level="4.11" data-path="SummaryExploratory.html"><a href="SummaryExploratory.html"><i class="fa fa-check"></i><b>4.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>5</b> Preprocessing Behavioral Data</a><ul>
<li class="chapter" data-level="5.1" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>5.1</b> Missing Values</a><ul>
<li class="chapter" data-level="5.1.1" data-path="missing-values.html"><a href="missing-values.html#imputation"><i class="fa fa-check"></i><b>5.1.1</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>5.2</b> Smoothing</a></li>
<li class="chapter" data-level="5.3" data-path="normalization.html"><a href="normalization.html"><i class="fa fa-check"></i><b>5.3</b> Normalization</a></li>
<li class="chapter" data-level="5.4" data-path="imbalanced-classes.html"><a href="imbalanced-classes.html"><i class="fa fa-check"></i><b>5.4</b> Imbalanced Classes</a><ul>
<li class="chapter" data-level="5.4.1" data-path="imbalanced-classes.html"><a href="imbalanced-classes.html#random-oversampling"><i class="fa fa-check"></i><b>5.4.1</b> Random Oversampling</a></li>
<li class="chapter" data-level="5.4.2" data-path="imbalanced-classes.html"><a href="imbalanced-classes.html#smote"><i class="fa fa-check"></i><b>5.4.2</b> SMOTE</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="infoinjection.html"><a href="infoinjection.html"><i class="fa fa-check"></i><b>5.5</b> Information Injection</a></li>
<li class="chapter" data-level="5.6" data-path="one-hot-encoding.html"><a href="one-hot-encoding.html"><i class="fa fa-check"></i><b>5.6</b> One-hot Encoding</a></li>
<li class="chapter" data-level="5.7" data-path="SummaryPreprocessing.html"><a href="SummaryPreprocessing.html"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>6</b> Discovering Behaviors with Unsupervised Learning</a><ul>
<li class="chapter" data-level="6.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>6.1</b> K-means clustering</a><ul>
<li class="chapter" data-level="6.1.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#studentresponses"><i class="fa fa-check"></i><b>6.1.1</b> Grouping Student Responses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="the-silhouette-index.html"><a href="the-silhouette-index.html"><i class="fa fa-check"></i><b>6.2</b> The Silhouette Index</a></li>
<li class="chapter" data-level="6.3" data-path="associationrules.html"><a href="associationrules.html"><i class="fa fa-check"></i><b>6.3</b> Mining Association Rules</a><ul>
<li class="chapter" data-level="6.3.1" data-path="associationrules.html"><a href="associationrules.html#finding-rules-for-criminal-behavior"><i class="fa fa-check"></i><b>6.3.1</b> Finding Rules for Criminal Behavior</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="SummaryUnsupervised.html"><a href="SummaryUnsupervised.html"><i class="fa fa-check"></i><b>6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="representations.html"><a href="representations.html"><i class="fa fa-check"></i><b>7</b> Encoding Behavioral Data</a><ul>
<li class="chapter" data-level="7.1" data-path="feature-vectors.html"><a href="feature-vectors.html"><i class="fa fa-check"></i><b>7.1</b> Feature Vectors</a></li>
<li class="chapter" data-level="7.2" data-path="sectimeseries.html"><a href="sectimeseries.html"><i class="fa fa-check"></i><b>7.2</b> Timeseries</a></li>
<li class="chapter" data-level="7.3" data-path="transactions.html"><a href="transactions.html"><i class="fa fa-check"></i><b>7.3</b> Transactions</a></li>
<li class="chapter" data-level="7.4" data-path="images.html"><a href="images.html"><i class="fa fa-check"></i><b>7.4</b> Images</a></li>
<li class="chapter" data-level="7.5" data-path="recurrence-plots.html"><a href="recurrence-plots.html"><i class="fa fa-check"></i><b>7.5</b> Recurrence Plots</a><ul>
<li class="chapter" data-level="7.5.1" data-path="recurrence-plots.html"><a href="recurrence-plots.html#computing-recurence-plots"><i class="fa fa-check"></i><b>7.5.1</b> Computing Recurence Plots</a></li>
<li class="chapter" data-level="7.5.2" data-path="recurrence-plots.html"><a href="recurrence-plots.html#recurrence-plots-of-hand-gestures"><i class="fa fa-check"></i><b>7.5.2</b> Recurrence Plots of Hand Gestures</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bag-of-words.html"><a href="bag-of-words.html"><i class="fa fa-check"></i><b>7.6</b> Bag-of-Words</a><ul>
<li class="chapter" data-level="7.6.1" data-path="bag-of-words.html"><a href="bag-of-words.html#bow-for-complex-activities."><i class="fa fa-check"></i><b>7.6.1</b> BoW for Complex Activities.</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="graphs.html"><a href="graphs.html"><i class="fa fa-check"></i><b>7.7</b> Graphs</a><ul>
<li class="chapter" data-level="7.7.1" data-path="graphs.html"><a href="graphs.html#complex-activities-as-graphs"><i class="fa fa-check"></i><b>7.7.1</b> Complex Activities as Graphs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="SummaryRepresentations.html"><a href="SummaryRepresentations.html"><i class="fa fa-check"></i><b>7.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="deeplearning.html"><a href="deeplearning.html"><i class="fa fa-check"></i><b>8</b> Predicting Behavior with Deep Learning</a><ul>
<li class="chapter" data-level="8.1" data-path="ann.html"><a href="ann.html"><i class="fa fa-check"></i><b>8.1</b> Introduction to Artificial Neural Networks</a><ul>
<li class="chapter" data-level="8.1.1" data-path="ann.html"><a href="ann.html#sigmoid-and-relu-units"><i class="fa fa-check"></i><b>8.1.1</b> Sigmoid and ReLU Units</a></li>
<li class="chapter" data-level="8.1.2" data-path="ann.html"><a href="ann.html#assembling-units-into-layers"><i class="fa fa-check"></i><b>8.1.2</b> Assembling Units into Layers</a></li>
<li class="chapter" data-level="8.1.3" data-path="ann.html"><a href="ann.html#deep-neural-networks"><i class="fa fa-check"></i><b>8.1.3</b> Deep Neural Networks</a></li>
<li class="chapter" data-level="8.1.4" data-path="ann.html"><a href="ann.html#learning-the-parameters"><i class="fa fa-check"></i><b>8.1.4</b> Learning the Parameters</a></li>
<li class="chapter" data-level="8.1.5" data-path="ann.html"><a href="ann.html#parameter-learning-example-in-r"><i class="fa fa-check"></i><b>8.1.5</b> Parameter Learning Example in R</a></li>
<li class="chapter" data-level="8.1.6" data-path="ann.html"><a href="ann.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>8.1.6</b> Stochastic Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="keras-and-tensorflow-with-r.html"><a href="keras-and-tensorflow-with-r.html"><i class="fa fa-check"></i><b>8.2</b> Keras and TensorFlow with R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="keras-and-tensorflow-with-r.html"><a href="keras-and-tensorflow-with-r.html#keras-example"><i class="fa fa-check"></i><b>8.2.1</b> Keras Example</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="classification-with-neural-networks.html"><a href="classification-with-neural-networks.html"><i class="fa fa-check"></i><b>8.3</b> Classification with Neural Networks</a><ul>
<li class="chapter" data-level="8.3.1" data-path="classification-with-neural-networks.html"><a href="classification-with-neural-networks.html#classification-of-electromyography-signals"><i class="fa fa-check"></i><b>8.3.1</b> Classification of Electromyography Signals</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i><b>8.4</b> Overfitting</a><ul>
<li class="chapter" data-level="8.4.1" data-path="overfitting.html"><a href="overfitting.html#early-stopping"><i class="fa fa-check"></i><b>8.4.1</b> Early Stopping</a></li>
<li class="chapter" data-level="8.4.2" data-path="overfitting.html"><a href="overfitting.html#dropout"><i class="fa fa-check"></i><b>8.4.2</b> Dropout</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="fine-tuning-a-neural-network.html"><a href="fine-tuning-a-neural-network.html"><i class="fa fa-check"></i><b>8.5</b> Fine-Tuning a Neural Network</a></li>
<li class="chapter" data-level="8.6" data-path="cnns.html"><a href="cnns.html"><i class="fa fa-check"></i><b>8.6</b> Convolutional Neural Networks</a><ul>
<li class="chapter" data-level="8.6.1" data-path="cnns.html"><a href="cnns.html#convolutions"><i class="fa fa-check"></i><b>8.6.1</b> Convolutions</a></li>
<li class="chapter" data-level="8.6.2" data-path="cnns.html"><a href="cnns.html#pooling-operations"><i class="fa fa-check"></i><b>8.6.2</b> Pooling Operations</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="cnns-with-keras.html"><a href="cnns-with-keras.html"><i class="fa fa-check"></i><b>8.7</b> CNNs with Keras</a><ul>
<li class="chapter" data-level="8.7.1" data-path="cnns-with-keras.html"><a href="cnns-with-keras.html#example-1"><i class="fa fa-check"></i><b>8.7.1</b> Example 1</a></li>
<li class="chapter" data-level="8.7.2" data-path="cnns-with-keras.html"><a href="cnns-with-keras.html#example-2"><i class="fa fa-check"></i><b>8.7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="cnnSmile.html"><a href="cnnSmile.html"><i class="fa fa-check"></i><b>8.8</b> Smiles Detection with a CNN</a></li>
<li class="chapter" data-level="8.9" data-path="SummaryDeepLearning.html"><a href="SummaryDeepLearning.html"><i class="fa fa-check"></i><b>8.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiuser.html"><a href="multiuser.html"><i class="fa fa-check"></i><b>9</b> Multi-User Validation</a><ul>
<li class="chapter" data-level="9.1" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>9.1</b> Mixed Models</a><ul>
<li class="chapter" data-level="9.1.1" data-path="mixed-models.html"><a href="mixed-models.html#skeleton-action-recognition-with-mixed-models"><i class="fa fa-check"></i><b>9.1.1</b> Skeleton Action Recognition with Mixed Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="user-independent-models.html"><a href="user-independent-models.html"><i class="fa fa-check"></i><b>9.2</b> User-Independent Models</a></li>
<li class="chapter" data-level="9.3" data-path="user-dependent-models.html"><a href="user-dependent-models.html"><i class="fa fa-check"></i><b>9.3</b> User-Dependent Models</a></li>
<li class="chapter" data-level="9.4" data-path="user-adaptive-models.html"><a href="user-adaptive-models.html"><i class="fa fa-check"></i><b>9.4</b> User-Adaptive Models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="user-adaptive-models.html"><a href="user-adaptive-models.html#transfer-learning"><i class="fa fa-check"></i><b>9.4.1</b> Transfer Learning</a></li>
<li class="chapter" data-level="9.4.2" data-path="user-adaptive-models.html"><a href="user-adaptive-models.html#a-user-adaptive-model-for-activity-recognition"><i class="fa fa-check"></i><b>9.4.2</b> A User-Adaptive Model for Activity Recognition</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="SummaryMultiUser.html"><a href="SummaryMultiUser.html"><i class="fa fa-check"></i><b>9.5</b> Summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixInstall.html"><a href="appendixInstall.html"><i class="fa fa-check"></i><b>A</b> Setup Your Environment</a><ul>
<li class="chapter" data-level="A.1" data-path="installing-the-datasets.html"><a href="installing-the-datasets.html"><i class="fa fa-check"></i><b>A.1</b> Installing the Datasets</a></li>
<li class="chapter" data-level="A.2" data-path="installing-the-examples-source-code.html"><a href="installing-the-examples-source-code.html"><i class="fa fa-check"></i><b>A.2</b> Installing the Examples Source Code</a></li>
<li class="chapter" data-level="A.3" data-path="installing-keras-and-tensorflow-.html"><a href="installing-keras-and-tensorflow-.html"><i class="fa fa-check"></i><b>A.3</b> Installing Keras and TensorFlow.</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixDatasets.html"><a href="appendixDatasets.html"><i class="fa fa-check"></i><b>B</b> Datasets</a><ul>
<li class="chapter" data-level="B.1" data-path="complex-activities.html"><a href="complex-activities.html"><i class="fa fa-check"></i><b>B.1</b> COMPLEX ACTIVITIES</a></li>
<li class="chapter" data-level="B.2" data-path="depresjon.html"><a href="depresjon.html"><i class="fa fa-check"></i><b>B.2</b> DEPRESJON</a></li>
<li class="chapter" data-level="B.3" data-path="electromyography.html"><a href="electromyography.html"><i class="fa fa-check"></i><b>B.3</b> ELECTROMYOGRAPHY</a></li>
<li class="chapter" data-level="B.4" data-path="hand-gestures.html"><a href="hand-gestures.html"><i class="fa fa-check"></i><b>B.4</b> HAND GESTURES</a></li>
<li class="chapter" data-level="B.5" data-path="home-tasks.html"><a href="home-tasks.html"><i class="fa fa-check"></i><b>B.5</b> HOME TASKS</a></li>
<li class="chapter" data-level="B.6" data-path="homicide-reports.html"><a href="homicide-reports.html"><i class="fa fa-check"></i><b>B.6</b> HOMICIDE REPORTS</a></li>
<li class="chapter" data-level="B.7" data-path="indoor-location.html"><a href="indoor-location.html"><i class="fa fa-check"></i><b>B.7</b> INDOOR LOCATION</a></li>
<li class="chapter" data-level="B.8" data-path="sheep-goats.html"><a href="sheep-goats.html"><i class="fa fa-check"></i><b>B.8</b> SHEEP GOATS</a></li>
<li class="chapter" data-level="B.9" data-path="skeleton-actions.html"><a href="skeleton-actions.html"><i class="fa fa-check"></i><b>B.9</b> SKELETON ACTIONS</a></li>
<li class="chapter" data-level="B.10" data-path="smartphone-activities.html"><a href="smartphone-activities.html"><i class="fa fa-check"></i><b>B.10</b> SMARTPHONE ACTIVITIES</a></li>
<li class="chapter" data-level="B.11" data-path="smiles.html"><a href="smiles.html"><i class="fa fa-check"></i><b>B.11</b> SMILES</a></li>
<li class="chapter" data-level="B.12" data-path="students-mental-health.html"><a href="students-mental-health.html"><i class="fa fa-check"></i><b>B.12</b> STUDENTS’ MENTAL HEALTH</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="citing-this-book.html"><a href="citing-this-book.html"><i class="fa fa-check"></i>Citing this Book</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Behavior Analysis with Machine Learning and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cnns" class="section level2">
<h2><span class="header-section-number">8.6</span> Convolutional Neural Networks</h2>
<p>Convolutional neural networks or CNNs for short, have become extremely popular due to their capacity to solve computer vision problems. Most of the time they are used for image classification tasks but can also be used for regression and for time series data. If we wanted to perform image classification with a traditional neural network, first we would need to either build a feature vector by:</p>
<ol style="list-style-type: decimal">
<li>extracting features from the image or,</li>
<li>flattening the image pixels into a 1D array.</li>
</ol>
<p>The first solution requires a lot of image processing expertise and domain knowledge. Extracting features from images is not a trivial task and requires a lot of preprocessing to reduce noise, artifacts, segment the objects of interest, remove background, etc. Additionally, considerable effort is spent on feature engineering. The drawback of the second solution is that spatial information is lost, that is, the relationship between neighboring pixels. CNNs solve the two previous problems by automatically extracting features while preserving spatial information. As opposed to traditional networks, CNNs can take as input <span class="math inline">\(n\)</span>-dimensional images and process them efficiently. The main building blocks of a CNN are:</p>
<ol style="list-style-type: decimal">
<li><strong>Convolution layers</strong></li>
<li><strong>Pooling operations</strong></li>
<li><strong>Traditional fully connected layers</strong></li>
</ol>
<p>Figure <a href="cnns.html#fig:cnnArchitecture">8.26</a> shows a simple CNN and its basic components. First, the image goes through a convolution layer with <span class="math inline">\(4\)</span> kernels (details about the convolution operation are described below). This layer is in charge of extracting features by applying the kernels on top of the image. The result of this operation is a convolved image, also known as <strong>feature maps</strong>. The number of feature maps is equal to the number of kernels, in this case, <span class="math inline">\(4\)</span>. Then, a <strong>pooling operation</strong> is applied on top of the feature maps. This operation reduces the size of the feature maps by downsampling them (details on this below). The output of the pooling operation is a set of feature maps with reduced size. Here, the outputs are <span class="math inline">\(4\)</span> reduced feature maps since the pooling operation is applied to each feature map independently of the others. Then, the feature maps are flattened into a one-dimensional array. Conceptually, this array represents all the features extracted from the previous steps. These features are then used as inputs to a neural network with its respective input, hidden, and output layers. An ’*’ and underlined text means that parameter learning occurs in that layer. For example, in the convolution layer, the parameters of the kernels need to be learned. On the other hand, the pooling operation does not require parameter learning since it is a fixed operation. Finally, the parameters of the neural network are learned too, including the hidden layers and the output layer.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnArchitecture"></span>
<img src="images/cnn_architecture.png" alt="Simple CNN architecture. An '*' indicates where parameter learning occurs." width="100%" />
<p class="caption">
Figure 8.26: Simple CNN architecture. An ’*’ indicates where parameter learning occurs.
</p>
</div>
<p>One can build more complex CNNs by stacking more convolution layers and pooling operations. By doing so, the level of abstraction increases. For example, the first convolution extracts simple features like horizontal, vertical, diagonal lines, etc. The next convolution could extract more complex features like squares, triangles, and so on. The parameter learning of all layers (including the convolution layers) occurs during the same forward and backpropagation step just as with a normal neural network. Both, the features and the classification task are learned at the same time! During learning, batches of images are forward propagated and the parameters are adjusted accordingly to minimize the error (for example, the average cross-entropy for classification). The same methods for training normal neural networks are used for CNNs, for example, stochastic gradient descent.</p>

<div class="rmdinfo">
Each kernel in a convolution layer can have an associated bias which is also a parameter to be learned. By default, Keras uses a bias for each kernel. Furthermore, an activation function can be applied to the outputs of the convolution layer. This is applied element-wise. ReLU is the most common one.
</div>

<p>At inference time, the convolution layers and pooling operations act as feature extractors by generating feature maps that are ultimately flattened and passed to a normal neural network. It is also common to use the first layers as feature extractors and then replace the neural network with another model (Random Forest, SVM, etc.). In the following sections, details about the convolution and pooling operations are presented.</p>
<div id="convolutions" class="section level3">
<h3><span class="header-section-number">8.6.1</span> Convolutions</h3>
<p>Convolutions are used to automatically extract feature maps from images. A convolution operation consists of a <strong>kernel</strong> also known as a <strong>filter</strong> which is a matrix with real values. Kernels are usually much smaller than the original image. For example, for a grayscale image of height and width of <span class="math inline">\(100\)</span>x<span class="math inline">\(100\)</span> a typical kernel size would be <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span>. The size of the kernel is a hyperparameter. The convolution operation consists of applying the kernel over the image staring at the upper left corner and moving forward row by row until reaching the bottom right corner. The <strong>stride</strong> controls how many elements the kernel is moved at a time and this is also a hyperparameter. A typical value for the stride is <span class="math inline">\(1\)</span>.</p>
<p>The convolution operation computes the sum of the element-wise product between the kernel and the image region it is covering. The output of this operation is used to generate the convolved image (feature map). Figure <a href="cnns.html#fig:cnnConv">8.27</a> shows the first two iterations and the final iteration of the convolution operation on an image. In this case, the kernel is a <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> matrix with <span class="math inline">\(1\)</span>s in its first row and <span class="math inline">\(0\)</span>s elsewhere. The original image has a size of <span class="math inline">\(5\)</span>x<span class="math inline">\(5\)</span>x<span class="math inline">\(1\)</span> (height, width, depth) and it seems to have the number <span class="math inline">\(7\)</span> in it.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnConv"></span>
<img src="images/cnn_conv_ites.png" alt="Convolution operation with a kernel of size 3x3 and stride=1. Iterations 1, 2 and 9." width="100%" />
<p class="caption">
Figure 8.27: Convolution operation with a kernel of size 3x3 and stride=1. Iterations 1, 2 and 9.
</p>
</div>
<p>In the first iteration, the kernel is aligned with the upper left corner of the original image. An element-wise multiplication is performed and the results are summed. The operation is shown at the top of the figure. In the first iteration, the result was <span class="math inline">\(3\)</span> and it is set at the corresponding position of the final convolved image (feature map). In the next iteration, the kernel is moved one position to the right and again, the final result is <span class="math inline">\(3\)</span> which is set in the next position of the convolved image. The process continues until the kernel reaches the bottom right corner. At the last iteration (9), the result is <span class="math inline">\(1\)</span>.</p>
<p>Now, the convolved image (feature map) represents the features extracted by this particular kernel. Also, note that the feature map is a <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> matrix which is smaller than the original image. It is also possible to force the feature map to have the same size as the original image by padding it with zeros.</p>
<p>Before learning starts, the kernel values are initialized at random. In this example, the kernel has <span class="math inline">\(1\)</span>s in the first row and it has <span class="math inline">\(3\)</span>x<span class="math inline">\(3=9\)</span> parameters. This is whats makes CNNs so efficient since the same kernel is applied to the entire image. This is known as ‘parameter sharing’. Our kernel has <span class="math inline">\(1\)</span>s at the top and zeros elsewhere so it seems that this kernel learned to detect horizontal lines. If we look at the final convolved image we see that the horizontal lines were emphasized by this kernel. This would be a good candidate kernel to differentiate between <span class="math inline">\(7\)</span>s and <span class="math inline">\(0\)</span>s, for example. Since <span class="math inline">\(0\)</span>s does not have long horizontal lines. But maybe it will have difficulties discriminating between <span class="math inline">\(7\)</span>s and <span class="math inline">\(5\)</span>s since both have horizontal lines at the top.</p>
<p>In this example, only <span class="math inline">\(1\)</span> kernel was used but in practice, you may want to have more kernels, each in charge of identifying the best features for the given problem. For example, another kernel could learn to identify diagonal lines which would be useful to differentiate between <span class="math inline">\(7\)</span>s and <span class="math inline">\(5\)</span>s. The number of kernels per convolution layer is a hyperparameter. In the previous example, we could have defined to have <span class="math inline">\(4\)</span> kernels instead of one. In that case, the output of that layer would have been <span class="math inline">\(4\)</span> feature maps of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> each (Figure <a href="cnns.html#fig:cnn4kernels">8.28</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:cnn4kernels"></span>
<img src="images/cnn_4kernels.png" alt="A convolution with 4 kernels. The output is 4 feature maps." width="90%" />
<p class="caption">
Figure 8.28: A convolution with 4 kernels. The output is 4 feature maps.
</p>
</div>
<p>What would be the output of a convolution layer with <span class="math inline">\(4\)</span> kernels of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span> if it is applied to an RGB color image of size <span class="math inline">\(5\)</span>x<span class="math inline">\(5\)</span>x<span class="math inline">\(3\)</span>)? In that case, the output will be the same (<span class="math inline">\(4\)</span> feature maps of size <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span>) as if the image were in grayscale (<span class="math inline">\(5\)</span>x<span class="math inline">\(5\)</span>x<span class="math inline">\(1\)</span>). Remember that the number of output feature maps is equal to the number of kernels regardless of the depth of the image. However, in this case, each kernel will have a depth of <span class="math inline">\(3\)</span>. Each depth is applied independently to the corresponding R, G, and B image channels. Thus, each kernel has <span class="math inline">\(3\)</span>x<span class="math inline">\(3\)</span>x<span class="math inline">\(3=27\)</span> parameters that need to be learned. After applying each kernel to each image channel (in this example, <span class="math inline">\(3\)</span> channels), <strong>the results of each channel are added</strong> and this is why we end up with one feature map per kernel. The following course website has a nice interactive animation of how convolutions are applied to an image with <span class="math inline">\(3\)</span> channels: <a href="https://cs231n.github.io/convolutional-networks/" class="uri">https://cs231n.github.io/convolutional-networks/</a>. In the next section (<em>CNNs with Keras</em>), a couple of examples that demonstrate how to calculate the number of parameters and the outputs’ shape will be presented as well.</p>
</div>
<div id="pooling-operations" class="section level3">
<h3><span class="header-section-number">8.6.2</span> Pooling Operations</h3>
<p>Pooling operations are typically applied after convolution layers. Their purpose is to reduce the size of the data and to emphasize important regions. These operations perform a fixed computation on the image and do no have learnable parameters. Similar to kernels, we need to define a window size. Then, this window is moved throughout the image and a computation is performed on the pixels covered by the window. The difference with kernels is that this window is just a guide but do not have parameters to be learned. The most common pooling operation is <strong>max pooling</strong> which consists of selecting the highest value.
Figure <a href="cnns.html#fig:cnnMaxPooling">8.29</a> shows an example of a max pooling operation on a <span class="math inline">\(4\)</span>x<span class="math inline">\(4\)</span> image. The window size is <span class="math inline">\(2\)</span>x<span class="math inline">\(2\)</span> and the stride is <span class="math inline">\(2\)</span>. The latter means that the window moves <span class="math inline">\(2\)</span> places at a time.</p>
<div class="figure" style="text-align: center"><span id="fig:cnnMaxPooling"></span>
<img src="images/cnn_maxpooling.png" alt="Max pooling with a window of size 2x2 and stride = 2." width="100%" />
<p class="caption">
Figure 8.29: Max pooling with a window of size 2x2 and stride = 2.
</p>
</div>
<p>The result of this operation is an image of size <span class="math inline">\(2\)</span>x<span class="math inline">\(2\)</span> which is half of the original one. Aside from max pooling, average pooling can be applied instead. In that case, it computes the mean value across all values covered by the window.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fine-tuning-a-neural-network.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cnns-with-keras.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
