<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.1 k-nearest Neighbors | Behavior Analysis with Machine Learning and R</title>
  <meta name="description" content="2.1 k-nearest Neighbors | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="2.1 k-nearest Neighbors | Behavior Analysis with Machine Learning and R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.png" />
  <meta property="og:description" content="2.1 k-nearest Neighbors | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.1 k-nearest Neighbors | Behavior Analysis with Machine Learning and R" />
  
  <meta name="twitter:description" content="2.1 k-nearest Neighbors | Behavior Analysis with Machine Learning and R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="twitter:image" content="images/cover.png" />

<meta name="author" content="Enrique Garcia Ceja" />


<meta name="date" content="2020-09-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification.html"/>
<link rel="next" href="performance-metrics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/d3-4.9.0/d3.min.js"></script>
<script src="libs/d3-tip-0.7.1/index-min.js"></script>
<link href="libs/d3panels-1.4.9/d3panels.min.css" rel="stylesheet" />
<script src="libs/d3panels-1.4.9/d3panels.min.js"></script>
<script src="libs/qtlcharts_iplotCorr-0.11.6/iplotCorr.js"></script>
<script src="libs/qtlcharts_iplotCorr-0.11.6/iplotCorr_noscat.js"></script>
<script src="libs/iplotCorr-binding-0.11.6/iplotCorr.js"></script>
<link href="libs/dygraphs-1.1.1/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs-1.1.1/dygraph-combined.js"></script>
<script src="libs/dygraphs-1.1.1/shapes.js"></script>
<script src="libs/moment-2.8.4/moment.js"></script>
<script src="libs/moment-timezone-0.2.5/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter-1.0.0/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding-1.1.1.6/dygraphs.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178679335-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178679335-1', { 'anonymize_ip': true });
</script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="#">Behavior Analysis with Machine Learning and R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#supplemental-material"><i class="fa fa-check"></i>Supplemental Material</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="1.2" data-path="taxonomy.html"><a href="taxonomy.html"><i class="fa fa-check"></i><b>1.2</b> Types of Machine Learning</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> Terminology</a><ul>
<li class="chapter" data-level="1.3.1" data-path="terminology.html"><a href="terminology.html#tables"><i class="fa fa-check"></i><b>1.3.1</b> Tables</a></li>
<li class="chapter" data-level="1.3.2" data-path="terminology.html"><a href="terminology.html#variable-types"><i class="fa fa-check"></i><b>1.3.2</b> Variable Types</a></li>
<li class="chapter" data-level="1.3.3" data-path="terminology.html"><a href="terminology.html#predictive-models"><i class="fa fa-check"></i><b>1.3.3</b> Predictive Models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="pipeline.html"><a href="pipeline.html"><i class="fa fa-check"></i><b>1.4</b> Data Analysis Pipeline</a></li>
<li class="chapter" data-level="1.5" data-path="trainingeval.html"><a href="trainingeval.html"><i class="fa fa-check"></i><b>1.5</b> Evaluating Predictive Models</a></li>
<li class="chapter" data-level="1.6" data-path="simple-classification-example.html"><a href="simple-classification-example.html"><i class="fa fa-check"></i><b>1.6</b> Simple Classification Example</a><ul>
<li class="chapter" data-level="1.6.1" data-path="simple-classification-example.html"><a href="simple-classification-example.html#k-fold-cross-validation-example"><i class="fa fa-check"></i><b>1.6.1</b> K-fold Cross-Validation Example</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="simple-regression-example.html"><a href="simple-regression-example.html"><i class="fa fa-check"></i><b>1.7</b> Simple Regression Example</a></li>
<li class="chapter" data-level="1.8" data-path="underfitting-and-overfitting.html"><a href="underfitting-and-overfitting.html"><i class="fa fa-check"></i><b>1.8</b> Underfitting and Overfitting</a></li>
<li class="chapter" data-level="1.9" data-path="bias-and-variance.html"><a href="bias-and-variance.html"><i class="fa fa-check"></i><b>1.9</b> Bias and Variance</a></li>
<li class="chapter" data-level="1.10" data-path="SummaryIntro.html"><a href="SummaryIntro.html"><i class="fa fa-check"></i><b>1.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>2</b> Predicting Behavior with Classification Models</a><ul>
<li class="chapter" data-level="2.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html"><i class="fa fa-check"></i><b>2.1</b> <em>k</em>-nearest Neighbors</a><ul>
<li class="chapter" data-level="2.1.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#indoor-location-with-wi-fi-signals"><i class="fa fa-check"></i><b>2.1.1</b> Indoor Location with Wi-Fi Signals</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="performance-metrics.html"><a href="performance-metrics.html"><i class="fa fa-check"></i><b>2.2</b> Performance Metrics</a></li>
<li class="chapter" data-level="2.3" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>2.3</b> Decision Trees</a><ul>
<li class="chapter" data-level="2.3.1" data-path="decision-trees.html"><a href="decision-trees.html#activityRecognition"><i class="fa fa-check"></i><b>2.3.1</b> Activity Recognition with Smartphones</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="dynamic-time-warping.html"><a href="dynamic-time-warping.html"><i class="fa fa-check"></i><b>2.4</b> Dynamic Time Warping</a><ul>
<li class="chapter" data-level="2.4.1" data-path="dynamic-time-warping.html"><a href="dynamic-time-warping.html#sechandgestures"><i class="fa fa-check"></i><b>2.4.1</b> Hand Gesture Recognition</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="summaryClassification.html"><a href="summaryClassification.html"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>3</b> Predicting Behavior with Ensemble Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="bagging.html"><a href="bagging.html"><i class="fa fa-check"></i><b>3.1</b> Bagging</a><ul>
<li class="chapter" data-level="3.1.1" data-path="bagging.html"><a href="bagging.html#activity-recognition-with-bagging"><i class="fa fa-check"></i><b>3.1.1</b> Activity recognition with Bagging</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>3.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.3" data-path="stacked-generalization.html"><a href="stacked-generalization.html"><i class="fa fa-check"></i><b>3.3</b> Stacked Generalization</a></li>
<li class="chapter" data-level="3.4" data-path="multiviewhometasks.html"><a href="multiviewhometasks.html"><i class="fa fa-check"></i><b>3.4</b> Multi-view Stacking for Home Tasks Recognition</a></li>
<li class="chapter" data-level="3.5" data-path="SummaryEnsemble.html"><a href="SummaryEnsemble.html"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="edavis.html"><a href="edavis.html"><i class="fa fa-check"></i><b>4</b> Exploring and Visualizing Behavioral Data</a><ul>
<li class="chapter" data-level="4.1" data-path="talking-with-field-experts.html"><a href="talking-with-field-experts.html"><i class="fa fa-check"></i><b>4.1</b> Talking with Field Experts</a></li>
<li class="chapter" data-level="4.2" data-path="summary-statistics.html"><a href="summary-statistics.html"><i class="fa fa-check"></i><b>4.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="4.3" data-path="class-distributions.html"><a href="class-distributions.html"><i class="fa fa-check"></i><b>4.3</b> Class Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="user-class-sparsity-matrix.html"><a href="user-class-sparsity-matrix.html"><i class="fa fa-check"></i><b>4.4</b> User-Class Sparsity Matrix</a></li>
<li class="chapter" data-level="4.5" data-path="boxplots.html"><a href="boxplots.html"><i class="fa fa-check"></i><b>4.5</b> Boxplots</a></li>
<li class="chapter" data-level="4.6" data-path="correlation-plots.html"><a href="correlation-plots.html"><i class="fa fa-check"></i><b>4.6</b> Correlation Plots</a><ul>
<li class="chapter" data-level="4.6.1" data-path="correlation-plots.html"><a href="correlation-plots.html#interactive-correlation-plots"><i class="fa fa-check"></i><b>4.6.1</b> Interactive Correlation Plots</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="timeseries.html"><a href="timeseries.html"><i class="fa fa-check"></i><b>4.7</b> Timeseries</a><ul>
<li class="chapter" data-level="4.7.1" data-path="timeseries.html"><a href="timeseries.html#interactive-timeseries"><i class="fa fa-check"></i><b>4.7.1</b> Interactive Timeseries</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="multidimensional-scaling-mds.html"><a href="multidimensional-scaling-mds.html"><i class="fa fa-check"></i><b>4.8</b> Multidimensional Scaling (MDS)</a></li>
<li class="chapter" data-level="4.9" data-path="heatmaps.html"><a href="heatmaps.html"><i class="fa fa-check"></i><b>4.9</b> Heatmaps</a></li>
<li class="chapter" data-level="4.10" data-path="automated-eda.html"><a href="automated-eda.html"><i class="fa fa-check"></i><b>4.10</b> Automated EDA</a></li>
<li class="chapter" data-level="4.11" data-path="SummaryExploratory.html"><a href="SummaryExploratory.html"><i class="fa fa-check"></i><b>4.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>5</b> Preprocessing Behavioral Data</a><ul>
<li class="chapter" data-level="5.1" data-path="missing-values.html"><a href="missing-values.html"><i class="fa fa-check"></i><b>5.1</b> Missing Values</a><ul>
<li class="chapter" data-level="5.1.1" data-path="missing-values.html"><a href="missing-values.html#imputation"><i class="fa fa-check"></i><b>5.1.1</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="smoothing.html"><a href="smoothing.html"><i class="fa fa-check"></i><b>5.2</b> Smoothing</a></li>
<li class="chapter" data-level="5.3" data-path="normalization.html"><a href="normalization.html"><i class="fa fa-check"></i><b>5.3</b> Normalization</a></li>
<li class="chapter" data-level="5.4" data-path="imbalanced-classes.html"><a href="imbalanced-classes.html"><i class="fa fa-check"></i><b>5.4</b> Imbalanced Classes</a><ul>
<li class="chapter" data-level="5.4.1" data-path="imbalanced-classes.html"><a href="imbalanced-classes.html#random-oversampling"><i class="fa fa-check"></i><b>5.4.1</b> Random Oversampling</a></li>
<li class="chapter" data-level="5.4.2" data-path="imbalanced-classes.html"><a href="imbalanced-classes.html#smote"><i class="fa fa-check"></i><b>5.4.2</b> SMOTE</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="infoinjection.html"><a href="infoinjection.html"><i class="fa fa-check"></i><b>5.5</b> Information Injection</a></li>
<li class="chapter" data-level="5.6" data-path="one-hot-encoding.html"><a href="one-hot-encoding.html"><i class="fa fa-check"></i><b>5.6</b> One-hot Encoding</a></li>
<li class="chapter" data-level="5.7" data-path="SummaryPreprocessing.html"><a href="SummaryPreprocessing.html"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>6</b> Discovering Behaviors with Unsupervised Learning</a><ul>
<li class="chapter" data-level="6.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>6.1</b> K-means clustering</a><ul>
<li class="chapter" data-level="6.1.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#studentresponses"><i class="fa fa-check"></i><b>6.1.1</b> Grouping Student Responses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="the-silhouette-index.html"><a href="the-silhouette-index.html"><i class="fa fa-check"></i><b>6.2</b> The Silhouette Index</a></li>
<li class="chapter" data-level="6.3" data-path="associationrules.html"><a href="associationrules.html"><i class="fa fa-check"></i><b>6.3</b> Mining Association Rules</a><ul>
<li class="chapter" data-level="6.3.1" data-path="associationrules.html"><a href="associationrules.html#finding-rules-for-criminal-behavior"><i class="fa fa-check"></i><b>6.3.1</b> Finding Rules for Criminal Behavior</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="SummaryUnsupervised.html"><a href="SummaryUnsupervised.html"><i class="fa fa-check"></i><b>6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="representations.html"><a href="representations.html"><i class="fa fa-check"></i><b>7</b> Encoding Behavioral Data</a><ul>
<li class="chapter" data-level="7.1" data-path="feature-vectors.html"><a href="feature-vectors.html"><i class="fa fa-check"></i><b>7.1</b> Feature Vectors</a></li>
<li class="chapter" data-level="7.2" data-path="sectimeseries.html"><a href="sectimeseries.html"><i class="fa fa-check"></i><b>7.2</b> Timeseries</a></li>
<li class="chapter" data-level="7.3" data-path="transactions.html"><a href="transactions.html"><i class="fa fa-check"></i><b>7.3</b> Transactions</a></li>
<li class="chapter" data-level="7.4" data-path="images.html"><a href="images.html"><i class="fa fa-check"></i><b>7.4</b> Images</a></li>
<li class="chapter" data-level="7.5" data-path="recurrence-plots.html"><a href="recurrence-plots.html"><i class="fa fa-check"></i><b>7.5</b> Recurrence Plots</a><ul>
<li class="chapter" data-level="7.5.1" data-path="recurrence-plots.html"><a href="recurrence-plots.html#computing-recurence-plots"><i class="fa fa-check"></i><b>7.5.1</b> Computing Recurence Plots</a></li>
<li class="chapter" data-level="7.5.2" data-path="recurrence-plots.html"><a href="recurrence-plots.html#recurrence-plots-of-hand-gestures"><i class="fa fa-check"></i><b>7.5.2</b> Recurrence Plots of Hand Gestures</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="bag-of-words.html"><a href="bag-of-words.html"><i class="fa fa-check"></i><b>7.6</b> Bag-of-Words</a><ul>
<li class="chapter" data-level="7.6.1" data-path="bag-of-words.html"><a href="bag-of-words.html#bow-for-complex-activities."><i class="fa fa-check"></i><b>7.6.1</b> BoW for Complex Activities.</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="graphs.html"><a href="graphs.html"><i class="fa fa-check"></i><b>7.7</b> Graphs</a><ul>
<li class="chapter" data-level="7.7.1" data-path="graphs.html"><a href="graphs.html#complex-activities-as-graphs"><i class="fa fa-check"></i><b>7.7.1</b> Complex Activities as Graphs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="SummaryRepresentations.html"><a href="SummaryRepresentations.html"><i class="fa fa-check"></i><b>7.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="deeplearning.html"><a href="deeplearning.html"><i class="fa fa-check"></i><b>8</b> Predicting Behavior with Deep Learning</a><ul>
<li class="chapter" data-level="8.1" data-path="ann.html"><a href="ann.html"><i class="fa fa-check"></i><b>8.1</b> Introduction to Artificial Neural Networks</a><ul>
<li class="chapter" data-level="8.1.1" data-path="ann.html"><a href="ann.html#sigmoid-and-relu-units"><i class="fa fa-check"></i><b>8.1.1</b> Sigmoid and ReLU Units</a></li>
<li class="chapter" data-level="8.1.2" data-path="ann.html"><a href="ann.html#assembling-units-into-layers"><i class="fa fa-check"></i><b>8.1.2</b> Assembling Units into Layers</a></li>
<li class="chapter" data-level="8.1.3" data-path="ann.html"><a href="ann.html#deep-neural-networks"><i class="fa fa-check"></i><b>8.1.3</b> Deep Neural Networks</a></li>
<li class="chapter" data-level="8.1.4" data-path="ann.html"><a href="ann.html#learning-the-parameters"><i class="fa fa-check"></i><b>8.1.4</b> Learning the Parameters</a></li>
<li class="chapter" data-level="8.1.5" data-path="ann.html"><a href="ann.html#parameter-learning-example-in-r"><i class="fa fa-check"></i><b>8.1.5</b> Parameter Learning Example in R</a></li>
<li class="chapter" data-level="8.1.6" data-path="ann.html"><a href="ann.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>8.1.6</b> Stochastic Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="keras-and-tensorflow-with-r.html"><a href="keras-and-tensorflow-with-r.html"><i class="fa fa-check"></i><b>8.2</b> Keras and TensorFlow with R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="keras-and-tensorflow-with-r.html"><a href="keras-and-tensorflow-with-r.html#keras-example"><i class="fa fa-check"></i><b>8.2.1</b> Keras Example</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="classification-with-neural-networks.html"><a href="classification-with-neural-networks.html"><i class="fa fa-check"></i><b>8.3</b> Classification with Neural Networks</a><ul>
<li class="chapter" data-level="8.3.1" data-path="classification-with-neural-networks.html"><a href="classification-with-neural-networks.html#classification-of-electromyography-signals"><i class="fa fa-check"></i><b>8.3.1</b> Classification of Electromyography Signals</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i><b>8.4</b> Overfitting</a><ul>
<li class="chapter" data-level="8.4.1" data-path="overfitting.html"><a href="overfitting.html#early-stopping"><i class="fa fa-check"></i><b>8.4.1</b> Early Stopping</a></li>
<li class="chapter" data-level="8.4.2" data-path="overfitting.html"><a href="overfitting.html#dropout"><i class="fa fa-check"></i><b>8.4.2</b> Dropout</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="fine-tuning-a-neural-network.html"><a href="fine-tuning-a-neural-network.html"><i class="fa fa-check"></i><b>8.5</b> Fine-Tuning a Neural Network</a></li>
<li class="chapter" data-level="8.6" data-path="cnns.html"><a href="cnns.html"><i class="fa fa-check"></i><b>8.6</b> Convolutional Neural Networks</a><ul>
<li class="chapter" data-level="8.6.1" data-path="cnns.html"><a href="cnns.html#convolutions"><i class="fa fa-check"></i><b>8.6.1</b> Convolutions</a></li>
<li class="chapter" data-level="8.6.2" data-path="cnns.html"><a href="cnns.html#pooling-operations"><i class="fa fa-check"></i><b>8.6.2</b> Pooling Operations</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="cnns-with-keras.html"><a href="cnns-with-keras.html"><i class="fa fa-check"></i><b>8.7</b> CNNs with Keras</a><ul>
<li class="chapter" data-level="8.7.1" data-path="cnns-with-keras.html"><a href="cnns-with-keras.html#example-1"><i class="fa fa-check"></i><b>8.7.1</b> Example 1</a></li>
<li class="chapter" data-level="8.7.2" data-path="cnns-with-keras.html"><a href="cnns-with-keras.html#example-2"><i class="fa fa-check"></i><b>8.7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="cnnSmile.html"><a href="cnnSmile.html"><i class="fa fa-check"></i><b>8.8</b> Smiles Detection with a CNN</a></li>
<li class="chapter" data-level="8.9" data-path="SummaryDeepLearning.html"><a href="SummaryDeepLearning.html"><i class="fa fa-check"></i><b>8.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiuser.html"><a href="multiuser.html"><i class="fa fa-check"></i><b>9</b> Multi-User Validation</a><ul>
<li class="chapter" data-level="9.1" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>9.1</b> Mixed Models</a><ul>
<li class="chapter" data-level="9.1.1" data-path="mixed-models.html"><a href="mixed-models.html#skeleton-action-recognition-with-mixed-models"><i class="fa fa-check"></i><b>9.1.1</b> Skeleton Action Recognition with Mixed Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="user-independent-models.html"><a href="user-independent-models.html"><i class="fa fa-check"></i><b>9.2</b> User-Independent Models</a></li>
<li class="chapter" data-level="9.3" data-path="user-dependent-models.html"><a href="user-dependent-models.html"><i class="fa fa-check"></i><b>9.3</b> User-Dependent Models</a></li>
<li class="chapter" data-level="9.4" data-path="user-adaptive-models.html"><a href="user-adaptive-models.html"><i class="fa fa-check"></i><b>9.4</b> User-Adaptive Models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="user-adaptive-models.html"><a href="user-adaptive-models.html#transfer-learning"><i class="fa fa-check"></i><b>9.4.1</b> Transfer Learning</a></li>
<li class="chapter" data-level="9.4.2" data-path="user-adaptive-models.html"><a href="user-adaptive-models.html#a-user-adaptive-model-for-activity-recognition"><i class="fa fa-check"></i><b>9.4.2</b> A User-Adaptive Model for Activity Recognition</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="SummaryMultiUser.html"><a href="SummaryMultiUser.html"><i class="fa fa-check"></i><b>9.5</b> Summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixInstall.html"><a href="appendixInstall.html"><i class="fa fa-check"></i><b>A</b> Setup Your Environment</a><ul>
<li class="chapter" data-level="A.1" data-path="installing-the-datasets.html"><a href="installing-the-datasets.html"><i class="fa fa-check"></i><b>A.1</b> Installing the Datasets</a></li>
<li class="chapter" data-level="A.2" data-path="installing-the-examples-source-code.html"><a href="installing-the-examples-source-code.html"><i class="fa fa-check"></i><b>A.2</b> Installing the Examples Source Code</a></li>
<li class="chapter" data-level="A.3" data-path="installing-keras-and-tensorflow-.html"><a href="installing-keras-and-tensorflow-.html"><i class="fa fa-check"></i><b>A.3</b> Installing Keras and TensorFlow.</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixDatasets.html"><a href="appendixDatasets.html"><i class="fa fa-check"></i><b>B</b> Datasets</a><ul>
<li class="chapter" data-level="B.1" data-path="complex-activities.html"><a href="complex-activities.html"><i class="fa fa-check"></i><b>B.1</b> COMPLEX ACTIVITIES</a></li>
<li class="chapter" data-level="B.2" data-path="depresjon.html"><a href="depresjon.html"><i class="fa fa-check"></i><b>B.2</b> DEPRESJON</a></li>
<li class="chapter" data-level="B.3" data-path="electromyography.html"><a href="electromyography.html"><i class="fa fa-check"></i><b>B.3</b> ELECTROMYOGRAPHY</a></li>
<li class="chapter" data-level="B.4" data-path="hand-gestures.html"><a href="hand-gestures.html"><i class="fa fa-check"></i><b>B.4</b> HAND GESTURES</a></li>
<li class="chapter" data-level="B.5" data-path="home-tasks.html"><a href="home-tasks.html"><i class="fa fa-check"></i><b>B.5</b> HOME TASKS</a></li>
<li class="chapter" data-level="B.6" data-path="homicide-reports.html"><a href="homicide-reports.html"><i class="fa fa-check"></i><b>B.6</b> HOMICIDE REPORTS</a></li>
<li class="chapter" data-level="B.7" data-path="indoor-location.html"><a href="indoor-location.html"><i class="fa fa-check"></i><b>B.7</b> INDOOR LOCATION</a></li>
<li class="chapter" data-level="B.8" data-path="sheep-goats.html"><a href="sheep-goats.html"><i class="fa fa-check"></i><b>B.8</b> SHEEP GOATS</a></li>
<li class="chapter" data-level="B.9" data-path="skeleton-actions.html"><a href="skeleton-actions.html"><i class="fa fa-check"></i><b>B.9</b> SKELETON ACTIONS</a></li>
<li class="chapter" data-level="B.10" data-path="smartphone-activities.html"><a href="smartphone-activities.html"><i class="fa fa-check"></i><b>B.10</b> SMARTPHONE ACTIVITIES</a></li>
<li class="chapter" data-level="B.11" data-path="smiles.html"><a href="smiles.html"><i class="fa fa-check"></i><b>B.11</b> SMILES</a></li>
<li class="chapter" data-level="B.12" data-path="students-mental-health.html"><a href="students-mental-health.html"><i class="fa fa-check"></i><b>B.12</b> STUDENTS’ MENTAL HEALTH</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="citing-this-book.html"><a href="citing-this-book.html"><i class="fa fa-check"></i>Citing this Book</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Behavior Analysis with Machine Learning and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="k-nearest-neighbors" class="section level2">
<h2><span class="header-section-number">2.1</span> <em>k</em>-nearest Neighbors</h2>
<p><span class="math inline">\(k\)</span>-nearest neighbors (<span class="math inline">\(k\)</span>-NN) is one of the simplest classification algorithms. The predicted class for a given <em>query instance</em> is the most common class of its <em>k</em> nearest neighbors. A <em>query instance</em> is just the instance we want to make predictions on. In its most basic form, the algorithm consists of two steps:</p>
<ol style="list-style-type: decimal">
<li>Compute the distance between the <em>query instance</em> and all <em>training instances</em>.</li>
<li>Return the most common class among the <em>k</em> nearest training instances.</li>
</ol>
<p>This is a type of <em>lazy-learning</em> algorithm because all the computations take place at prediction time. There are no parameters to learn at training time! The training phase consists only of storing the training instances so they can be compared to the query instance at prediction time. The hyper-parameter <em>k</em> is usually specified by the user and will depend on each application. We also need to specify a <em>distance function</em> such that similar instances should have smaller distances between them in the feature space and dissimilar instances should have longer distances. For numeric features, the <strong>Euclidean distance</strong> is one of the most commonly used distance metrics. The Euclidean distance between two points can be computed as follows:</p>
<p><span class="math display" id="eq:euclideanDistance">\[\begin{equation}
  d\left(p,q\right) = \sqrt{\sum_{i=1}^n{\left(p_i-q_i\right)^2}}
  \tag{2.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are <span class="math inline">\(n\)</span>-dimensional feature vectors and <span class="math inline">\(i\)</span> is the index to the vectors’ elements. Figure <a href="k-nearest-neighbors.html#fig:simpleKnn">2.1</a> shows the idea graphically. (Figure inspired from the k-nn article<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> in Wikipedia). The query instance is depicted with the ‘?’ symbol. If we choose <span class="math inline">\(k=3\)</span> (represented by the inner dashed circle) the predicted class is <em>‘square’</em> because there are two squares but only one circle. If <span class="math inline">\(k=5\)</span> (outer dotted circle), the predicted class is <em>‘circle’</em>.</p>
<div class="figure" style="text-align: center"><span id="fig:simpleKnn"></span>
<img src="images/knn.png" alt="k-NN example for k=3 (inner dashed circle) and k=5 (dotted outer circle)." width="40%" />
<p class="caption">
Figure 2.1: k-NN example for k=3 (inner dashed circle) and k=5 (dotted outer circle).
</p>
</div>
<p>Typical values for <span class="math inline">\(k\)</span> are small odd numbers like <span class="math inline">\(1,2,3,5\)</span>. The <span class="math inline">\(k\)</span>-nn algorithm can also be used for regression with a small modification: Instead of returning the majority class of the nearest neighbors, return the mean value of their response variable. Despite its simplicity, <span class="math inline">\(k\)</span>-nn has proved to perform really well in many tasks including time series classification <span class="citation">(Xi et al. <a href="#ref-xi2006" role="doc-biblioref">2006</a>)</span>.</p>
<div id="indoor-location-with-wi-fi-signals" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Indoor Location with Wi-Fi Signals</h3>

<div class="rmdfolder">
<code>indoor_classification.R</code> <code>indoor_auxiliary.R</code>
</div>

<p>It is possible that you might already have experienced some troubles with geolocation services when you are inside a building. Part of this is because GPS technologies do not provide good indoors accuracy due to several sources of interference. For some applications, it would be beneficial to have accurate location estimations inside buildings even at room-level. For example, in domotics and localization services in big public places like airports or shopping malls. Having good indoor location estimates can also be used in behavior analysis such as extracting trajectory patterns.</p>
<p>In this section, we will implement <span class="math inline">\(k\)</span>-NN to perform indoor location in a building based on Wi-Fi signals. For instance, we can use a smartphone to scan the nearby Wi-Fi access points and based on this information, determine our location at room-level. This can be formulated as a classification problem: Given a set of Wi-Fi signals as input, predict the location where the device is located.</p>
<p>For this classification problem, we will use the <em>INDOOR LOCATION</em> dataset (see Appendix <a href="appendixDatasets.html#appendixDatasets">B</a> for more info.) which was collected with an Android smartphone. The smartphone application scans the nearby access points and stores their information and label. The label is provided by the user and represents the room where the device is located. Several instances for every location were recorded. To generate each instance, the device scans and records the MAC address and signal strength of the nearby access points. A delay of <span class="math inline">\(500\)</span> ms is set between scans. For each location, approximately <span class="math inline">\(3\)</span> minutes of data were collected while the user walked around the specific room. Figure <a href="k-nearest-neighbors.html#fig:layoutHouse">2.2</a> depicts the layout of the building where the data was collected. The data has four different locations: <em>‘bedroomA’</em>, <em>‘beadroomB’</em>, <em>‘tvroom’</em>, and the <em>‘lobby’</em>. The lobby (not shown in the layout) is at the same level as bedroom A but on the first floor.</p>
<div class="figure" style="text-align: center"><span id="fig:layoutHouse"></span>
<img src="images/layout.png" alt="Layout of the apartments building." width="90%" />
<p class="caption">
Figure 2.2: Layout of the apartments building.
</p>
</div>
<p>Table <a href="k-nearest-neighbors.html#tab:headWifi">2.1</a> shows the first rows of the dataset. The first column is the class. <code>scanid</code> column is a unique identifier for the given Wi-Fi scan (instance). To preserve privacy, MAC addresses were converted into integer values. Every instance is composed of several rows. For example, the first instance with <code>scanid=1</code> has two rows (one row per mac address). Intuitively, same locations should have similar MAC addresses. From the table, we can see that at <em>bedroomA</em> access points with MAC address <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> are usually found by the device.</p>
<table>
<caption><span id="tab:headWifi">Table 2.1: </span>First rows of wifi scans.</caption>
<thead>
<tr class="header">
<th align="left">locationid</th>
<th align="right">scanid</th>
<th align="right">mac</th>
<th align="right">signalstrength</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bedroomA</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">-88.500</td>
</tr>
<tr class="even">
<td align="left">bedroomA</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">-91.000</td>
</tr>
<tr class="odd">
<td align="left">bedroomA</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">-88.000</td>
</tr>
<tr class="even">
<td align="left">bedroomA</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">-90.000</td>
</tr>
<tr class="odd">
<td align="left">bedroomA</td>
<td align="right">3</td>
<td align="right">1</td>
<td align="right">-87.625</td>
</tr>
<tr class="even">
<td align="left">bedroomA</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">-90.000</td>
</tr>
<tr class="odd">
<td align="left">bedroomA</td>
<td align="right">4</td>
<td align="right">2</td>
<td align="right">-90.250</td>
</tr>
<tr class="even">
<td align="left">bedroomA</td>
<td align="right">4</td>
<td align="right">1</td>
<td align="right">-90.000</td>
</tr>
<tr class="odd">
<td align="left">bedroomA</td>
<td align="right">4</td>
<td align="right">3</td>
<td align="right">-91.000</td>
</tr>
</tbody>
</table>
<p>Since each instance is composed of several rows, we will convert our data frame into a list of lists where each inner list represents a single instance with the class (<code>locationId</code>), a unique id, and a data frame with the corresponding access points. The example code can be found in the script <code>indoor_classification.R</code>.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="k-nearest-neighbors.html#cb20-1"></a><span class="co"># Read Wi-Fi data</span></span>
<span id="cb20-2"><a href="k-nearest-neighbors.html#cb20-2"></a>df &lt;-<span class="st"> </span><span class="kw">read.csv</span>(datapath, <span class="dt">stringsAsFactors =</span> F)</span>
<span id="cb20-3"><a href="k-nearest-neighbors.html#cb20-3"></a></span>
<span id="cb20-4"><a href="k-nearest-neighbors.html#cb20-4"></a><span class="co"># Convert data frame into a list of lists.</span></span>
<span id="cb20-5"><a href="k-nearest-neighbors.html#cb20-5"></a><span class="co"># Each inner list represents one instance.</span></span>
<span id="cb20-6"><a href="k-nearest-neighbors.html#cb20-6"></a>dataset &lt;-<span class="st"> </span><span class="kw">wifiScansToList</span>(df)</span>
<span id="cb20-7"><a href="k-nearest-neighbors.html#cb20-7"></a></span>
<span id="cb20-8"><a href="k-nearest-neighbors.html#cb20-8"></a><span class="co"># Print number of instances in the dataset.</span></span>
<span id="cb20-9"><a href="k-nearest-neighbors.html#cb20-9"></a><span class="kw">length</span>(dataset)</span>
<span id="cb20-10"><a href="k-nearest-neighbors.html#cb20-10"></a><span class="co">#&gt; [1] 365</span></span>
<span id="cb20-11"><a href="k-nearest-neighbors.html#cb20-11"></a></span>
<span id="cb20-12"><a href="k-nearest-neighbors.html#cb20-12"></a><span class="co"># Print the first instance.</span></span>
<span id="cb20-13"><a href="k-nearest-neighbors.html#cb20-13"></a>dataset[[<span class="dv">1</span>]]</span>
<span id="cb20-14"><a href="k-nearest-neighbors.html#cb20-14"></a><span class="co">#&gt; $locationId</span></span>
<span id="cb20-15"><a href="k-nearest-neighbors.html#cb20-15"></a><span class="co">#&gt; [1] &quot;bedroomA&quot;</span></span>
<span id="cb20-16"><a href="k-nearest-neighbors.html#cb20-16"></a><span class="co">#&gt; </span></span>
<span id="cb20-17"><a href="k-nearest-neighbors.html#cb20-17"></a><span class="co">#&gt; $scanId</span></span>
<span id="cb20-18"><a href="k-nearest-neighbors.html#cb20-18"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb20-19"><a href="k-nearest-neighbors.html#cb20-19"></a><span class="co">#&gt; </span></span>
<span id="cb20-20"><a href="k-nearest-neighbors.html#cb20-20"></a><span class="co">#&gt; $accessPoints</span></span>
<span id="cb20-21"><a href="k-nearest-neighbors.html#cb20-21"></a><span class="co">#&gt;   mac signalstrength</span></span>
<span id="cb20-22"><a href="k-nearest-neighbors.html#cb20-22"></a><span class="co">#&gt; 1   1          -88.5</span></span>
<span id="cb20-23"><a href="k-nearest-neighbors.html#cb20-23"></a><span class="co">#&gt; 2   2          -91.0</span></span></code></pre></div>
<p>First, we read the dataset from the csv file and store it in the data frame <code>df</code>. To make things easier, the data frame is converted into a list of lists using the auxiliary function <code>wifiScansToList()</code> which is defined in the script <code>indoor_auxiliary.R</code>. Next we print the number of instances in the dataset, that is, the number of lists in the dataset list. The dataset list contains <span class="math inline">\(365\)</span> instances. The <span class="math inline">\(365\)</span> was just a coincidence, the data was not collected every day during one year but in the same day. Next, we extract the first instance with <code>dataset[[1]]</code>. Here, we can see that each instance has three pieces of information. The class (locationId), a unique id (scanId), and a set of access points stored in a data frame. The first instance has two access points with MAC addresses <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span>. There is also information about the signal strength, though, this one will not be used.</p>
<p>Since we would expect that similar locations have similar MAC addresses and locations that are far away from each other have different MAC addresses, we need a distance measure that captures this notion of similarity. In this case, we cannot use the Euclidean distance on MAC addresses. Even though they were encoded as integer values, they do not represent magnitudes but unique identifiers. Each instance is composed of a set of <span class="math inline">\(n\)</span> MAC addresses stored in the <code>accessPoints</code> data frame. To compute the distance between two instances (two sets) we can use the <em>Jaccard distance</em>. This distance is based on element sets:</p>
<p><span class="math display" id="eq:jaccardDistance">\[\begin{equation}
  j\left(A,B\right)=\frac{\left|A\cup B\right|-\left|A\cap B\right|}{\left|A\cup B\right|}
  \tag{2.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are sets of MAC addresses. A <strong>set</strong> is an unordered collection of elements. As an example, let’s say we have two sets, <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span>:</p>
<p><span class="math display">\[\begin{align*}
S_1&amp;=\{a,b,c,d,e\}\\
S_2&amp;=\{e,f,g,a\}
\end{align*}\]</span></p>
<p>The set <span class="math inline">\(S_1\)</span> has <span class="math inline">\(5\)</span> elements (letters) and <span class="math inline">\(S_2\)</span> has <span class="math inline">\(4\)</span> elements. <span class="math inline">\(A \cup B\)</span> means the <strong>union</strong> of the two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> and its result is the set of all elements that are either in <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span>. For instance, the union of <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> is <span class="math inline">\(S_1 \cup S_2 = \{a,b,c,d,e,f,g\}\)</span>. The <span class="math inline">\(A \cap B\)</span> denotes the <strong>intersection</strong> between <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> which is the set of elements that are in both <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. In our example, <span class="math inline">\(S_1 \cap S_2 = \{a,e\}\)</span>. Finally the vertical bars <span class="math inline">\(||\)</span> mean the <strong>cardinality</strong> of the set, that is, the number of elements. The cardinality of <span class="math inline">\(S_1\)</span> is <span class="math inline">\(|S_1|=5\)</span> because it has <span class="math inline">\(5\)</span> elements. The cardinality of the union of the two sets <span class="math inline">\(|S_1 \cup S_2|=7\)</span> because the set that results from the union of <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> has <span class="math inline">\(7\)</span> elements.</p>
<p>In R, we can implement the Jaccard distance as follows:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="k-nearest-neighbors.html#cb21-1"></a>jaccardDistance &lt;-<span class="st"> </span><span class="cf">function</span>(set1, set2){</span>
<span id="cb21-2"><a href="k-nearest-neighbors.html#cb21-2"></a>  lengthUnion &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">union</span>(set1, set2))</span>
<span id="cb21-3"><a href="k-nearest-neighbors.html#cb21-3"></a>  lengthIntersectoin &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">intersect</span>(set1, set2))</span>
<span id="cb21-4"><a href="k-nearest-neighbors.html#cb21-4"></a>  d &lt;-<span class="st"> </span>(lengthUnion <span class="op">-</span><span class="st"> </span>lengthIntersectoin)  <span class="op">/</span><span class="st"> </span>lengthUnion</span>
<span id="cb21-5"><a href="k-nearest-neighbors.html#cb21-5"></a>  <span class="kw">return</span>(d)</span>
<span id="cb21-6"><a href="k-nearest-neighbors.html#cb21-6"></a>}</span></code></pre></div>
<p>The implementation is in the script <code>indoor_auxiliary.R</code>. Now, we can try our function! Let’s compute the distance between two instances of the same class (<em>‘bedroomA’</em>).</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="k-nearest-neighbors.html#cb22-1"></a><span class="co"># Compute jaccard distance between instances with same class:</span></span>
<span id="cb22-2"><a href="k-nearest-neighbors.html#cb22-2"></a><span class="co"># (bedroomA)</span></span>
<span id="cb22-3"><a href="k-nearest-neighbors.html#cb22-3"></a><span class="kw">jaccardDistance</span>(dataset[[<span class="dv">1</span>]]<span class="op">$</span>accessPoints<span class="op">$</span>mac,</span>
<span id="cb22-4"><a href="k-nearest-neighbors.html#cb22-4"></a>                dataset[[<span class="dv">4</span>]]<span class="op">$</span>accessPoints<span class="op">$</span>mac)</span>
<span id="cb22-5"><a href="k-nearest-neighbors.html#cb22-5"></a><span class="co">#&gt; [1] 0.3333333</span></span></code></pre></div>
<p>Now let’s try to compute the distance between instances with different classes.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="k-nearest-neighbors.html#cb23-1"></a><span class="co"># Jaccard distance of instances with different class:</span></span>
<span id="cb23-2"><a href="k-nearest-neighbors.html#cb23-2"></a><span class="co"># (bedroomA and bedroomB)</span></span>
<span id="cb23-3"><a href="k-nearest-neighbors.html#cb23-3"></a><span class="kw">jaccardDistance</span>(dataset[[<span class="dv">1</span>]]<span class="op">$</span>accessPoints<span class="op">$</span>mac,</span>
<span id="cb23-4"><a href="k-nearest-neighbors.html#cb23-4"></a>                dataset[[<span class="dv">210</span>]]<span class="op">$</span>accessPoints<span class="op">$</span>mac)</span>
<span id="cb23-5"><a href="k-nearest-neighbors.html#cb23-5"></a><span class="co">#&gt; [1] 0.6666667</span></span></code></pre></div>
<p>The distance between instances of the same class was <span class="math inline">\(0.33\)</span> whereas the distance between instances of different class was <span class="math inline">\(0.66\)</span>. So, our function is working as expected.</p>
<p>In the extreme case when sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are the same, the distance will be <span class="math inline">\(0\)</span>. When there are no common elements in the sets, the distance will be <span class="math inline">\(1\)</span>. Armed with this distance metric, we can now implement the <span class="math inline">\(k\)</span>-nn function in R. The <code>knn_classifier()</code> implementation is in the script <code>indoor_auxiliary.R</code>. Its first argument is the dataset (the list of instances). The second argument <em>k</em>, is the number of nearest neighbors to use, and the last two arguments are the indices of the train and test instances, respectively. This indices are pointers to the elements in the <code>dataset</code> variable.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="k-nearest-neighbors.html#cb24-1"></a>knn_classifier &lt;-<span class="st"> </span><span class="cf">function</span>(dataset, k, trainSetIndices, testSetIndices){</span>
<span id="cb24-2"><a href="k-nearest-neighbors.html#cb24-2"></a>  </span>
<span id="cb24-3"><a href="k-nearest-neighbors.html#cb24-3"></a>  groundTruth &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb24-4"><a href="k-nearest-neighbors.html#cb24-4"></a>  predictions &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb24-5"><a href="k-nearest-neighbors.html#cb24-5"></a>  </span>
<span id="cb24-6"><a href="k-nearest-neighbors.html#cb24-6"></a>  <span class="cf">for</span>(queryInstance <span class="cf">in</span> testSetIndices){</span>
<span id="cb24-7"><a href="k-nearest-neighbors.html#cb24-7"></a>    distancesToQuery &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb24-8"><a href="k-nearest-neighbors.html#cb24-8"></a>    </span>
<span id="cb24-9"><a href="k-nearest-neighbors.html#cb24-9"></a>    <span class="cf">for</span>(trainInstance <span class="cf">in</span> trainSetIndices){</span>
<span id="cb24-10"><a href="k-nearest-neighbors.html#cb24-10"></a>      jd &lt;-<span class="st"> </span><span class="kw">jaccardDistance</span>(dataset[[queryInstance]]<span class="op">$</span>accessPoints<span class="op">$</span>mac,</span>
<span id="cb24-11"><a href="k-nearest-neighbors.html#cb24-11"></a>                            dataset[[trainInstance]]<span class="op">$</span>accessPoints<span class="op">$</span>mac)</span>
<span id="cb24-12"><a href="k-nearest-neighbors.html#cb24-12"></a>      distancesToQuery &lt;-<span class="st"> </span><span class="kw">c</span>(distancesToQuery, jd)</span>
<span id="cb24-13"><a href="k-nearest-neighbors.html#cb24-13"></a>    }</span>
<span id="cb24-14"><a href="k-nearest-neighbors.html#cb24-14"></a>    </span>
<span id="cb24-15"><a href="k-nearest-neighbors.html#cb24-15"></a>    indices &lt;-<span class="st"> </span><span class="kw">sort</span>(distancesToQuery, <span class="dt">index.return =</span> <span class="ot">TRUE</span>)<span class="op">$</span>ix</span>
<span id="cb24-16"><a href="k-nearest-neighbors.html#cb24-16"></a>    indices &lt;-<span class="st"> </span>indices[<span class="dv">1</span><span class="op">:</span>k]</span>
<span id="cb24-17"><a href="k-nearest-neighbors.html#cb24-17"></a>    <span class="co"># Indices of the k nearest neighbors</span></span>
<span id="cb24-18"><a href="k-nearest-neighbors.html#cb24-18"></a>    nnIndices &lt;-<span class="st"> </span>trainSetIndices[indices]</span>
<span id="cb24-19"><a href="k-nearest-neighbors.html#cb24-19"></a>    <span class="co"># Get the actual instances</span></span>
<span id="cb24-20"><a href="k-nearest-neighbors.html#cb24-20"></a>    nnInstances &lt;-<span class="st"> </span>dataset[nnIndices]</span>
<span id="cb24-21"><a href="k-nearest-neighbors.html#cb24-21"></a>    <span class="co"># Get their respective classes</span></span>
<span id="cb24-22"><a href="k-nearest-neighbors.html#cb24-22"></a>    nnClasses &lt;-<span class="st"> </span><span class="kw">sapply</span>(nnInstances, <span class="cf">function</span>(e){e[[<span class="dv">1</span>]]})</span>
<span id="cb24-23"><a href="k-nearest-neighbors.html#cb24-23"></a>    prediction &lt;-<span class="st"> </span><span class="kw">Mode</span>(nnClasses)</span>
<span id="cb24-24"><a href="k-nearest-neighbors.html#cb24-24"></a>    predictions &lt;-<span class="st"> </span><span class="kw">c</span>(predictions, prediction)</span>
<span id="cb24-25"><a href="k-nearest-neighbors.html#cb24-25"></a>    groundTruth &lt;-<span class="st"> </span><span class="kw">c</span>(groundTruth,</span>
<span id="cb24-26"><a href="k-nearest-neighbors.html#cb24-26"></a>                     dataset[[queryInstance]]<span class="op">$</span>locationId)</span>
<span id="cb24-27"><a href="k-nearest-neighbors.html#cb24-27"></a>  }</span>
<span id="cb24-28"><a href="k-nearest-neighbors.html#cb24-28"></a>  </span>
<span id="cb24-29"><a href="k-nearest-neighbors.html#cb24-29"></a>  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">predictions =</span> predictions,</span>
<span id="cb24-30"><a href="k-nearest-neighbors.html#cb24-30"></a>              <span class="dt">groundTruth =</span> groundTruth))</span>
<span id="cb24-31"><a href="k-nearest-neighbors.html#cb24-31"></a>}</span></code></pre></div>
<p>For each instance <code>queryInstance</code> in the test set, the <code>knn_classifier()</code> computes its jaccard distance to every other instance in the train set and stores those distances in <code>distancesToQuery</code>. Then, those distances are sorted in ascending order and the most common class among the first <span class="math inline">\(k\)</span> elements is returned as the predicted class. The function <code>Mode()</code> was used to return the most common element. Finally, <code>knn_classifier()</code> returns a list with the predictions for every instance in the test set and their respective ground truth class for evaluation.</p>
<p>Now, we can try our classifier. We will use <span class="math inline">\(70\%\)</span> of the dataset as train set and the remaining as the test set.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="k-nearest-neighbors.html#cb25-1"></a><span class="co"># Total number of instances</span></span>
<span id="cb25-2"><a href="k-nearest-neighbors.html#cb25-2"></a>numberInstances &lt;-<span class="st"> </span><span class="kw">length</span>(dataset)</span>
<span id="cb25-3"><a href="k-nearest-neighbors.html#cb25-3"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb25-4"><a href="k-nearest-neighbors.html#cb25-4"></a><span class="kw">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb25-5"><a href="k-nearest-neighbors.html#cb25-5"></a><span class="co"># Split into train and test sets.</span></span>
<span id="cb25-6"><a href="k-nearest-neighbors.html#cb25-6"></a>trainSetIndices &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>numberInstances,</span>
<span id="cb25-7"><a href="k-nearest-neighbors.html#cb25-7"></a>                          <span class="dt">size =</span> <span class="kw">round</span>(numberInstances <span class="op">*</span><span class="st"> </span><span class="fl">0.7</span>),</span>
<span id="cb25-8"><a href="k-nearest-neighbors.html#cb25-8"></a>                          <span class="dt">replace =</span> F)</span>
<span id="cb25-9"><a href="k-nearest-neighbors.html#cb25-9"></a>testSetIndices &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">:</span>numberInstances)[<span class="op">-</span>trainSetIndices]</span></code></pre></div>
<p>The function <code>knn_classifier()</code> will predict the class for each test set instance and will return a list with their predictions and their ground truth classes. With this information, we can compute the accuracy on the test set which is the percentage of correctly classified instances. For this example, I will set <span class="math inline">\(k=3\)</span>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="k-nearest-neighbors.html#cb26-1"></a><span class="co"># Obtain predictions on the test set.</span></span>
<span id="cb26-2"><a href="k-nearest-neighbors.html#cb26-2"></a>result &lt;-<span class="st"> </span><span class="kw">knn_classifier</span>(dataset,</span>
<span id="cb26-3"><a href="k-nearest-neighbors.html#cb26-3"></a>                         <span class="dt">k =</span> <span class="dv">3</span>,</span>
<span id="cb26-4"><a href="k-nearest-neighbors.html#cb26-4"></a>                         trainSetIndices,</span>
<span id="cb26-5"><a href="k-nearest-neighbors.html#cb26-5"></a>                         testSetIndices)</span>
<span id="cb26-6"><a href="k-nearest-neighbors.html#cb26-6"></a><span class="co"># Calculate and print accuracy.</span></span>
<span id="cb26-7"><a href="k-nearest-neighbors.html#cb26-7"></a><span class="kw">sum</span>(result<span class="op">$</span>predictions <span class="op">==</span><span class="st"> </span>result<span class="op">$</span>groundTruth) <span class="op">/</span></span>
<span id="cb26-8"><a href="k-nearest-neighbors.html#cb26-8"></a><span class="st">  </span><span class="kw">length</span>(result<span class="op">$</span>predictions)</span>
<span id="cb26-9"><a href="k-nearest-neighbors.html#cb26-9"></a><span class="co">#&gt; [1] 0.9454545</span></span></code></pre></div>
<p>Not bad! Our simple <span class="math inline">\(k\)</span>-nn algorithm achieved an accuracy of <span class="math inline">\(94.5\%\)</span>. Usually, it is a good idea to visualize the predictions to have a better understanding of the classifier’s behavior. <strong>Confusion matrices</strong> allow us to precisely do that. We can use the <code>confusionMatrix()</code> function from the <code>caret</code> package to generate a confusion matrix. Its first argument is a factor with the predictions and the second one is a factor with the corresponding true values. This function returns an object with several performance metrics (see next section) and the confusion matrix.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="k-nearest-neighbors.html#cb27-1"></a><span class="kw">library</span>(caret)</span>
<span id="cb27-2"><a href="k-nearest-neighbors.html#cb27-2"></a>cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(result<span class="op">$</span>predictions),</span>
<span id="cb27-3"><a href="k-nearest-neighbors.html#cb27-3"></a>                      <span class="kw">factor</span>(result<span class="op">$</span>groundTruth))</span>
<span id="cb27-4"><a href="k-nearest-neighbors.html#cb27-4"></a>cm<span class="op">$</span>table <span class="co"># Access the confusion matrix.</span></span>
<span id="cb27-5"><a href="k-nearest-neighbors.html#cb27-5"></a><span class="co">#&gt; Reference</span></span>
<span id="cb27-6"><a href="k-nearest-neighbors.html#cb27-6"></a><span class="co">#&gt; Prediction bedroomA bedroomB lobby tvroom</span></span>
<span id="cb27-7"><a href="k-nearest-neighbors.html#cb27-7"></a><span class="co">#&gt; bedroomA       26        0     3      1</span></span>
<span id="cb27-8"><a href="k-nearest-neighbors.html#cb27-8"></a><span class="co">#&gt; bedroomB        0       17     0      1</span></span>
<span id="cb27-9"><a href="k-nearest-neighbors.html#cb27-9"></a><span class="co">#&gt; lobby           0        1    28      0</span></span>
<span id="cb27-10"><a href="k-nearest-neighbors.html#cb27-10"></a><span class="co">#&gt; tvroom          0        0     0     33</span></span></code></pre></div>
<p>The columns represent the true classes and rows the predictions. For example, from the total <span class="math inline">\(31\)</span> instances of type <em>‘lobby’</em>, <span class="math inline">\(28\)</span> of them were correctly classified as <em>‘lobby’</em> but <span class="math inline">\(3\)</span> of them were misclassified as <em>‘bedroomA’</em>. Something I find useful is to plot the confusion matrix as proportions instead of counts (Figure <a href="k-nearest-neighbors.html#fig:wifiCM">2.3</a>). From this confusion matrix we can see that for the class <em>‘bedroomB’</em>, <span class="math inline">\(94\%\)</span> of the instances were correctly classified and <span class="math inline">\(6\%\)</span> were mislabeled as <em>‘lobby’</em>. On the other hand, instances of type <em>‘bedroomA’</em> were always classified correctly.</p>
<div class="figure" style="text-align: center"><span id="fig:wifiCM"></span>
<img src="images/indoorCM.png" alt="Confusion matrix for location predictions." width="70%" />
<p class="caption">
Figure 2.3: Confusion matrix for location predictions.
</p>
</div>
<p>A confusion matrix is a good way to analyze classification results per class and spot weaknesses which we can use to improve the model, for example, by extracting additional features.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-xi2006">
<p>Xi, Xiaopeng, Eamonn Keogh, Christian Shelton, Li Wei, and Chotirat Ann Ratanamahatana. 2006. “Fast Time Series Classification Using Numerosity Reduction.” In <em>Proceedings of the 23rd International Conference on Machine Learning</em>, 1033–40.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" class="uri">https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm</a><a href="k-nearest-neighbors.html#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="performance-metrics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
