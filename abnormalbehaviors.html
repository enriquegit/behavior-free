<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Detecting Abnormal Behaviors | Behavior Analysis with Machine Learning Using R</title>
  <meta name="description" content="Chapter 10 Detecting Abnormal Behaviors | Behavior Analysis with Machine Learning Using R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Detecting Abnormal Behaviors | Behavior Analysis with Machine Learning Using R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/images/cover.png" />
  <meta property="og:description" content="Chapter 10 Detecting Abnormal Behaviors | Behavior Analysis with Machine Learning Using R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Detecting Abnormal Behaviors | Behavior Analysis with Machine Learning Using R" />
  
  <meta name="twitter:description" content="Chapter 10 Detecting Abnormal Behaviors | Behavior Analysis with Machine Learning Using R teaches you how to train machine learning models in the R programming language to make sense of behavioral data collected with sensors and stored in electronic records. This book introduces machine learning concepts and algorithms applied to a diverse set of behavior analysis problems by focusing on practical aspects. Some of the topics include how to: Build supervised models to predict indoor locations based on Wi-Fi signals, recognize physical activities from smartphone sensors, use unsupervised learning to discover criminal behavioral patterns, build deep learning models to analyze electromyography signals, CNNs to detect smiles in images and much more." />
  <meta name="twitter:image" content="/images/cover.png" />

<meta name="author" content="Enrique Garcia Ceja" />


<meta name="date" content="2025-06-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiuser.html"/>
<link rel="next" href="appendixInstall.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/d3/d3.min.js"></script>
<link href="libs/d3panels/d3panels.min.css" rel="stylesheet" />
<script src="libs/d3panels/d3panels.min.js"></script>
<script src="libs/qtlcharts_iplotCorr/iplotCorr.js"></script>
<script src="libs/qtlcharts_iplotCorr/iplotCorr_noscat.js"></script>
<script src="libs/iplotCorr-binding/iplotCorr.js"></script>
<link href="libs/dygraphs/dygraph.css" rel="stylesheet" />
<script src="libs/dygraphs/dygraph-combined.js"></script>
<script src="libs/dygraphs/shapes.js"></script>
<script src="libs/moment/moment.js"></script>
<script src="libs/moment-timezone/moment-timezone-with-data.js"></script>
<script src="libs/moment-fquarter/moment-fquarter.min.js"></script>
<script src="libs/dygraphs-binding/dygraphs.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-178679335-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-178679335-1', { 'anonymize_ip': true });
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="#">Behavior Analysis with Machine Learning Using R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-front-cover"><i class="fa fa-check"></i>About the Front Cover</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the Author</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#new-book"><i class="fa fa-check"></i>New Book!</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#supplemental-material"><i class="fa fa-check"></i>Supplemental Material</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#conventions"><i class="fa fa-check"></i>Conventions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to Behavior and Machine Learning</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-behavior"><i class="fa fa-check"></i><b>1.1</b> What Is Behavior?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#taxonomy"><i class="fa fa-check"></i><b>1.3</b> Types of Machine Learning</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#terminology"><i class="fa fa-check"></i><b>1.4</b> Terminology</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#tables"><i class="fa fa-check"></i><b>1.4.1</b> Tables</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#variable-types"><i class="fa fa-check"></i><b>1.4.2</b> Variable Types</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#predictive-models"><i class="fa fa-check"></i><b>1.4.3</b> Predictive Models</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#pipeline"><i class="fa fa-check"></i><b>1.5</b> Data Analysis Pipeline</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#trainingeval"><i class="fa fa-check"></i><b>1.6</b> Evaluating Predictive Models</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#simple-classification-example"><i class="fa fa-check"></i><b>1.7</b> Simple Classification Example</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="intro.html"><a href="intro.html#k-fold-cross-validation-example"><i class="fa fa-check"></i><b>1.7.1</b> <span class="math inline">\(k\)</span>-fold Cross-validation Example</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#simple-regression-example"><i class="fa fa-check"></i><b>1.8</b> Simple Regression Example</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>1.9</b> Underfitting and Overfitting</a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#bias-and-variance"><i class="fa fa-check"></i><b>1.10</b> Bias and Variance</a></li>
<li class="chapter" data-level="1.11" data-path="intro.html"><a href="intro.html#SummaryIntro"><i class="fa fa-check"></i><b>1.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>2</b> Predicting Behavior with Classification Models</a>
<ul>
<li class="chapter" data-level="2.1" data-path="classification.html"><a href="classification.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>2.1</b> <em>k</em>-Nearest Neighbors</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="classification.html"><a href="classification.html#indoor-location-with-wi-fi-signals"><i class="fa fa-check"></i><b>2.1.1</b> Indoor Location with Wi-Fi Signals</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="classification.html"><a href="classification.html#performance-metrics"><i class="fa fa-check"></i><b>2.2</b> Performance Metrics</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="classification.html"><a href="classification.html#confusion-matrix"><i class="fa fa-check"></i><b>2.2.1</b> Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="classification.html"><a href="classification.html#decision-trees"><i class="fa fa-check"></i><b>2.3</b> Decision Trees</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="classification.html"><a href="classification.html#activityRecognition"><i class="fa fa-check"></i><b>2.3.1</b> Activity Recognition with Smartphones</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="classification.html"><a href="classification.html#naive-bayes"><i class="fa fa-check"></i><b>2.4</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="classification.html"><a href="classification.html#activity-recognition-with-naive-bayes"><i class="fa fa-check"></i><b>2.4.1</b> Activity Recognition with Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="classification.html"><a href="classification.html#dynamic-time-warping"><i class="fa fa-check"></i><b>2.5</b> Dynamic Time Warping</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="classification.html"><a href="classification.html#sechandgestures"><i class="fa fa-check"></i><b>2.5.1</b> Hand Gesture Recognition</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="classification.html"><a href="classification.html#dummy-models"><i class="fa fa-check"></i><b>2.6</b> Dummy Models</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="classification.html"><a href="classification.html#most-frequent-class-classifier"><i class="fa fa-check"></i><b>2.6.1</b> Most-frequent-class Classifier</a></li>
<li class="chapter" data-level="2.6.2" data-path="classification.html"><a href="classification.html#uniform-classifier"><i class="fa fa-check"></i><b>2.6.2</b> Uniform Classifier</a></li>
<li class="chapter" data-level="2.6.3" data-path="classification.html"><a href="classification.html#frequency-based-classifier"><i class="fa fa-check"></i><b>2.6.3</b> Frequency-based Classifier</a></li>
<li class="chapter" data-level="2.6.4" data-path="classification.html"><a href="classification.html#other-dummy-classifiers"><i class="fa fa-check"></i><b>2.6.4</b> Other Dummy Classifiers</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="classification.html"><a href="classification.html#summaryClassification"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble.html"><a href="ensemble.html"><i class="fa fa-check"></i><b>3</b> Predicting Behavior with Ensemble Learning</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ensemble.html"><a href="ensemble.html#bagging"><i class="fa fa-check"></i><b>3.1</b> Bagging</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="ensemble.html"><a href="ensemble.html#activity-recognition-with-bagging"><i class="fa fa-check"></i><b>3.1.1</b> Activity Recognition with Bagging</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ensemble.html"><a href="ensemble.html#random-forest"><i class="fa fa-check"></i><b>3.2</b> Random Forest</a></li>
<li class="chapter" data-level="3.3" data-path="ensemble.html"><a href="ensemble.html#stacked-generalization"><i class="fa fa-check"></i><b>3.3</b> Stacked Generalization</a></li>
<li class="chapter" data-level="3.4" data-path="ensemble.html"><a href="ensemble.html#multiviewhometasks"><i class="fa fa-check"></i><b>3.4</b> Multi-view Stacking for Home Tasks Recognition</a></li>
<li class="chapter" data-level="3.5" data-path="ensemble.html"><a href="ensemble.html#SummaryEnsemble"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="edavis.html"><a href="edavis.html"><i class="fa fa-check"></i><b>4</b> Exploring and Visualizing Behavioral Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="edavis.html"><a href="edavis.html#talking-with-field-experts"><i class="fa fa-check"></i><b>4.1</b> Talking with Field Experts</a></li>
<li class="chapter" data-level="4.2" data-path="edavis.html"><a href="edavis.html#summary-statistics"><i class="fa fa-check"></i><b>4.2</b> Summary Statistics</a></li>
<li class="chapter" data-level="4.3" data-path="edavis.html"><a href="edavis.html#class-distributions"><i class="fa fa-check"></i><b>4.3</b> Class Distributions</a></li>
<li class="chapter" data-level="4.4" data-path="edavis.html"><a href="edavis.html#user-class-sparsity-matrix"><i class="fa fa-check"></i><b>4.4</b> User-class Sparsity Matrix</a></li>
<li class="chapter" data-level="4.5" data-path="edavis.html"><a href="edavis.html#boxplots"><i class="fa fa-check"></i><b>4.5</b> Boxplots</a></li>
<li class="chapter" data-level="4.6" data-path="edavis.html"><a href="edavis.html#correlation-plots"><i class="fa fa-check"></i><b>4.6</b> Correlation Plots</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="edavis.html"><a href="edavis.html#interactive-correlation-plots"><i class="fa fa-check"></i><b>4.6.1</b> Interactive Correlation Plots</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="edavis.html"><a href="edavis.html#timeseries"><i class="fa fa-check"></i><b>4.7</b> Timeseries</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="edavis.html"><a href="edavis.html#interactive-timeseries"><i class="fa fa-check"></i><b>4.7.1</b> Interactive Timeseries</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="edavis.html"><a href="edavis.html#multidimensional-scaling-mds"><i class="fa fa-check"></i><b>4.8</b> Multidimensional Scaling (MDS)</a></li>
<li class="chapter" data-level="4.9" data-path="edavis.html"><a href="edavis.html#heatmaps"><i class="fa fa-check"></i><b>4.9</b> Heatmaps</a></li>
<li class="chapter" data-level="4.10" data-path="edavis.html"><a href="edavis.html#automated-eda"><i class="fa fa-check"></i><b>4.10</b> Automated EDA</a></li>
<li class="chapter" data-level="4.11" data-path="edavis.html"><a href="edavis.html#SummaryExploratory"><i class="fa fa-check"></i><b>4.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="preprocessing.html"><a href="preprocessing.html"><i class="fa fa-check"></i><b>5</b> Preprocessing Behavioral Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="preprocessing.html"><a href="preprocessing.html#missing-values"><i class="fa fa-check"></i><b>5.1</b> Missing Values</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="preprocessing.html"><a href="preprocessing.html#imputation"><i class="fa fa-check"></i><b>5.1.1</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="preprocessing.html"><a href="preprocessing.html#smoothing"><i class="fa fa-check"></i><b>5.2</b> Smoothing</a></li>
<li class="chapter" data-level="5.3" data-path="preprocessing.html"><a href="preprocessing.html#normalization"><i class="fa fa-check"></i><b>5.3</b> Normalization</a></li>
<li class="chapter" data-level="5.4" data-path="preprocessing.html"><a href="preprocessing.html#imbalanced-classes"><i class="fa fa-check"></i><b>5.4</b> Imbalanced Classes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="preprocessing.html"><a href="preprocessing.html#random-oversampling"><i class="fa fa-check"></i><b>5.4.1</b> Random Oversampling</a></li>
<li class="chapter" data-level="5.4.2" data-path="preprocessing.html"><a href="preprocessing.html#smote"><i class="fa fa-check"></i><b>5.4.2</b> SMOTE</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="preprocessing.html"><a href="preprocessing.html#infoinjection"><i class="fa fa-check"></i><b>5.5</b> Information Injection</a></li>
<li class="chapter" data-level="5.6" data-path="preprocessing.html"><a href="preprocessing.html#one-hot-encoding"><i class="fa fa-check"></i><b>5.6</b> One-hot Encoding</a></li>
<li class="chapter" data-level="5.7" data-path="preprocessing.html"><a href="preprocessing.html#SummaryPreprocessing"><i class="fa fa-check"></i><b>5.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>6</b> Discovering Behaviors with Unsupervised Learning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="unsupervised.html"><a href="unsupervised.html#k-means-clustering"><i class="fa fa-check"></i><b>6.1</b> <span class="math inline">\(k\)</span>-means Clustering</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="unsupervised.html"><a href="unsupervised.html#studentresponses"><i class="fa fa-check"></i><b>6.1.1</b> Grouping Student Responses</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="unsupervised.html"><a href="unsupervised.html#the-silhouette-index"><i class="fa fa-check"></i><b>6.2</b> The Silhouette Index</a></li>
<li class="chapter" data-level="6.3" data-path="unsupervised.html"><a href="unsupervised.html#associationrules"><i class="fa fa-check"></i><b>6.3</b> Mining Association Rules</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="unsupervised.html"><a href="unsupervised.html#finding-rules-for-criminal-behavior"><i class="fa fa-check"></i><b>6.3.1</b> Finding Rules for Criminal Behavior</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="unsupervised.html"><a href="unsupervised.html#SummaryUnsupervised"><i class="fa fa-check"></i><b>6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="representations.html"><a href="representations.html"><i class="fa fa-check"></i><b>7</b> Encoding Behavioral Data</a>
<ul>
<li class="chapter" data-level="7.1" data-path="representations.html"><a href="representations.html#feature-vectors"><i class="fa fa-check"></i><b>7.1</b> Feature Vectors</a></li>
<li class="chapter" data-level="7.2" data-path="representations.html"><a href="representations.html#sectimeseries"><i class="fa fa-check"></i><b>7.2</b> Timeseries</a></li>
<li class="chapter" data-level="7.3" data-path="representations.html"><a href="representations.html#transactions"><i class="fa fa-check"></i><b>7.3</b> Transactions</a></li>
<li class="chapter" data-level="7.4" data-path="representations.html"><a href="representations.html#images"><i class="fa fa-check"></i><b>7.4</b> Images</a></li>
<li class="chapter" data-level="7.5" data-path="representations.html"><a href="representations.html#recurrence-plots"><i class="fa fa-check"></i><b>7.5</b> Recurrence Plots</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="representations.html"><a href="representations.html#computing-recurrence-plots"><i class="fa fa-check"></i><b>7.5.1</b> Computing Recurrence Plots</a></li>
<li class="chapter" data-level="7.5.2" data-path="representations.html"><a href="representations.html#recurrence-plots-of-hand-gestures"><i class="fa fa-check"></i><b>7.5.2</b> Recurrence Plots of Hand Gestures</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="representations.html"><a href="representations.html#bag-of-words"><i class="fa fa-check"></i><b>7.6</b> Bag-of-Words</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="representations.html"><a href="representations.html#bow-for-complex-activities."><i class="fa fa-check"></i><b>7.6.1</b> BoW for Complex Activities.</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="representations.html"><a href="representations.html#graphs"><i class="fa fa-check"></i><b>7.7</b> Graphs</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="representations.html"><a href="representations.html#complex-activities-as-graphs"><i class="fa fa-check"></i><b>7.7.1</b> Complex Activities as Graphs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="representations.html"><a href="representations.html#SummaryRepresentations"><i class="fa fa-check"></i><b>7.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="deeplearning.html"><a href="deeplearning.html"><i class="fa fa-check"></i><b>8</b> Predicting Behavior with Deep Learning</a>
<ul>
<li class="chapter" data-level="8.1" data-path="deeplearning.html"><a href="deeplearning.html#ann"><i class="fa fa-check"></i><b>8.1</b> Introduction to Artificial Neural Networks</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="deeplearning.html"><a href="deeplearning.html#sigmoid-and-relu-units"><i class="fa fa-check"></i><b>8.1.1</b> Sigmoid and ReLU Units</a></li>
<li class="chapter" data-level="8.1.2" data-path="deeplearning.html"><a href="deeplearning.html#assembling-units-into-layers"><i class="fa fa-check"></i><b>8.1.2</b> Assembling Units into Layers</a></li>
<li class="chapter" data-level="8.1.3" data-path="deeplearning.html"><a href="deeplearning.html#deep-neural-networks"><i class="fa fa-check"></i><b>8.1.3</b> Deep Neural Networks</a></li>
<li class="chapter" data-level="8.1.4" data-path="deeplearning.html"><a href="deeplearning.html#learning-the-parameters"><i class="fa fa-check"></i><b>8.1.4</b> Learning the Parameters</a></li>
<li class="chapter" data-level="8.1.5" data-path="deeplearning.html"><a href="deeplearning.html#parameter-learning-example-in-r"><i class="fa fa-check"></i><b>8.1.5</b> Parameter Learning Example in R</a></li>
<li class="chapter" data-level="8.1.6" data-path="deeplearning.html"><a href="deeplearning.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>8.1.6</b> Stochastic Gradient Descent</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="deeplearning.html"><a href="deeplearning.html#keras-and-tensorflow-with-r"><i class="fa fa-check"></i><b>8.2</b> Keras and TensorFlow with R</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="deeplearning.html"><a href="deeplearning.html#keras-example"><i class="fa fa-check"></i><b>8.2.1</b> Keras Example</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="deeplearning.html"><a href="deeplearning.html#classification-with-neural-networks"><i class="fa fa-check"></i><b>8.3</b> Classification with Neural Networks</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="deeplearning.html"><a href="deeplearning.html#classification-of-electromyography-signals"><i class="fa fa-check"></i><b>8.3.1</b> Classification of Electromyography Signals</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="deeplearning.html"><a href="deeplearning.html#overfitting"><i class="fa fa-check"></i><b>8.4</b> Overfitting</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="deeplearning.html"><a href="deeplearning.html#early-stopping"><i class="fa fa-check"></i><b>8.4.1</b> Early Stopping</a></li>
<li class="chapter" data-level="8.4.2" data-path="deeplearning.html"><a href="deeplearning.html#dropout"><i class="fa fa-check"></i><b>8.4.2</b> Dropout</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="deeplearning.html"><a href="deeplearning.html#fine-tuning-a-neural-network"><i class="fa fa-check"></i><b>8.5</b> Fine-tuning a Neural Network</a></li>
<li class="chapter" data-level="8.6" data-path="deeplearning.html"><a href="deeplearning.html#cnns"><i class="fa fa-check"></i><b>8.6</b> Convolutional Neural Networks</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="deeplearning.html"><a href="deeplearning.html#convolutions"><i class="fa fa-check"></i><b>8.6.1</b> Convolutions</a></li>
<li class="chapter" data-level="8.6.2" data-path="deeplearning.html"><a href="deeplearning.html#pooling-operations"><i class="fa fa-check"></i><b>8.6.2</b> Pooling Operations</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="deeplearning.html"><a href="deeplearning.html#cnns-with-keras"><i class="fa fa-check"></i><b>8.7</b> CNNs with Keras</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="deeplearning.html"><a href="deeplearning.html#example-1"><i class="fa fa-check"></i><b>8.7.1</b> Example 1</a></li>
<li class="chapter" data-level="8.7.2" data-path="deeplearning.html"><a href="deeplearning.html#example-2"><i class="fa fa-check"></i><b>8.7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="deeplearning.html"><a href="deeplearning.html#cnnSmile"><i class="fa fa-check"></i><b>8.8</b> Smiles Detection with a CNN</a></li>
<li class="chapter" data-level="8.9" data-path="deeplearning.html"><a href="deeplearning.html#SummaryDeepLearning"><i class="fa fa-check"></i><b>8.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multiuser.html"><a href="multiuser.html"><i class="fa fa-check"></i><b>9</b> Multi-user Validation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="multiuser.html"><a href="multiuser.html#mixed-models"><i class="fa fa-check"></i><b>9.1</b> Mixed Models</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="multiuser.html"><a href="multiuser.html#skeleton-action-recognition-with-mixed-models"><i class="fa fa-check"></i><b>9.1.1</b> Skeleton Action Recognition with Mixed Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="multiuser.html"><a href="multiuser.html#user-independent-models"><i class="fa fa-check"></i><b>9.2</b> User-independent Models</a></li>
<li class="chapter" data-level="9.3" data-path="multiuser.html"><a href="multiuser.html#user-dependent-models"><i class="fa fa-check"></i><b>9.3</b> User-dependent Models</a></li>
<li class="chapter" data-level="9.4" data-path="multiuser.html"><a href="multiuser.html#user-adaptive-models"><i class="fa fa-check"></i><b>9.4</b> User-adaptive Models</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="multiuser.html"><a href="multiuser.html#transfer-learning"><i class="fa fa-check"></i><b>9.4.1</b> Transfer Learning</a></li>
<li class="chapter" data-level="9.4.2" data-path="multiuser.html"><a href="multiuser.html#a-user-adaptive-model-for-activity-recognition"><i class="fa fa-check"></i><b>9.4.2</b> A User-adaptive Model for Activity Recognition</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="multiuser.html"><a href="multiuser.html#SummaryMultiUser"><i class="fa fa-check"></i><b>9.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html"><i class="fa fa-check"></i><b>10</b> Detecting Abnormal Behaviors</a>
<ul>
<li class="chapter" data-level="10.1" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#isolation-forests"><i class="fa fa-check"></i><b>10.1</b> Isolation Forests</a></li>
<li class="chapter" data-level="10.2" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#detecting-abnormal-fish-behaviors"><i class="fa fa-check"></i><b>10.2</b> Detecting Abnormal Fish Behaviors</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#exploring-and-visualizing-trajectories"><i class="fa fa-check"></i><b>10.2.1</b> Exploring and Visualizing Trajectories</a></li>
<li class="chapter" data-level="10.2.2" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#preprocessing-and-feature-extraction"><i class="fa fa-check"></i><b>10.2.2</b> Preprocessing and Feature Extraction</a></li>
<li class="chapter" data-level="10.2.3" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#training-the-model"><i class="fa fa-check"></i><b>10.2.3</b> Training the Model</a></li>
<li class="chapter" data-level="10.2.4" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#roc-curve-and-auc"><i class="fa fa-check"></i><b>10.2.4</b> ROC Curve and AUC</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#autoencoders"><i class="fa fa-check"></i><b>10.3</b> Autoencoders</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#autoencoders-for-anomaly-detection"><i class="fa fa-check"></i><b>10.3.1</b> Autoencoders for Anomaly Detection</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="abnormalbehaviors.html"><a href="abnormalbehaviors.html#SummaryAnomalyDetection"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendixInstall.html"><a href="appendixInstall.html"><i class="fa fa-check"></i><b>A</b> Setup Your Environment</a>
<ul>
<li class="chapter" data-level="A.1" data-path="appendixInstall.html"><a href="appendixInstall.html#installing-the-datasets"><i class="fa fa-check"></i><b>A.1</b> Installing the Datasets</a></li>
<li class="chapter" data-level="A.2" data-path="appendixInstall.html"><a href="appendixInstall.html#installing-the-examples-source-code"><i class="fa fa-check"></i><b>A.2</b> Installing the Examples Source Code</a></li>
<li class="chapter" data-level="A.3" data-path="appendixInstall.html"><a href="appendixInstall.html#running-shiny-apps"><i class="fa fa-check"></i><b>A.3</b> Running Shiny Apps</a></li>
<li class="chapter" data-level="A.4" data-path="appendixInstall.html"><a href="appendixInstall.html#installing-keras-and-tensorflow"><i class="fa fa-check"></i><b>A.4</b> Installing Keras and TensorFlow</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appendixDatasets.html"><a href="appendixDatasets.html"><i class="fa fa-check"></i><b>B</b> Datasets</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appendixDatasets.html"><a href="appendixDatasets.html#complex-activities"><i class="fa fa-check"></i><b>B.1</b> COMPLEX ACTIVITIES</a></li>
<li class="chapter" data-level="B.2" data-path="appendixDatasets.html"><a href="appendixDatasets.html#depresjon"><i class="fa fa-check"></i><b>B.2</b> DEPRESJON</a></li>
<li class="chapter" data-level="B.3" data-path="appendixDatasets.html"><a href="appendixDatasets.html#electromyography"><i class="fa fa-check"></i><b>B.3</b> ELECTROMYOGRAPHY</a></li>
<li class="chapter" data-level="B.4" data-path="appendixDatasets.html"><a href="appendixDatasets.html#fish-trajectories"><i class="fa fa-check"></i><b>B.4</b> FISH TRAJECTORIES</a></li>
<li class="chapter" data-level="B.5" data-path="appendixDatasets.html"><a href="appendixDatasets.html#hand-gestures"><i class="fa fa-check"></i><b>B.5</b> HAND GESTURES</a></li>
<li class="chapter" data-level="B.6" data-path="appendixDatasets.html"><a href="appendixDatasets.html#home-tasks"><i class="fa fa-check"></i><b>B.6</b> HOME TASKS</a></li>
<li class="chapter" data-level="B.7" data-path="appendixDatasets.html"><a href="appendixDatasets.html#homicide-reports"><i class="fa fa-check"></i><b>B.7</b> HOMICIDE REPORTS</a></li>
<li class="chapter" data-level="B.8" data-path="appendixDatasets.html"><a href="appendixDatasets.html#indoor-location"><i class="fa fa-check"></i><b>B.8</b> INDOOR LOCATION</a></li>
<li class="chapter" data-level="B.9" data-path="appendixDatasets.html"><a href="appendixDatasets.html#sheep-goats"><i class="fa fa-check"></i><b>B.9</b> SHEEP GOATS</a></li>
<li class="chapter" data-level="B.10" data-path="appendixDatasets.html"><a href="appendixDatasets.html#skeleton-actions"><i class="fa fa-check"></i><b>B.10</b> SKELETON ACTIONS</a></li>
<li class="chapter" data-level="B.11" data-path="appendixDatasets.html"><a href="appendixDatasets.html#smartphone-activities"><i class="fa fa-check"></i><b>B.11</b> SMARTPHONE ACTIVITIES</a></li>
<li class="chapter" data-level="B.12" data-path="appendixDatasets.html"><a href="appendixDatasets.html#smiles"><i class="fa fa-check"></i><b>B.12</b> SMILES</a></li>
<li class="chapter" data-level="B.13" data-path="appendixDatasets.html"><a href="appendixDatasets.html#students-mental-health"><i class="fa fa-check"></i><b>B.13</b> STUDENTS’ MENTAL HEALTH</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="citing-this-book.html"><a href="citing-this-book.html"><i class="fa fa-check"></i>Citing this Book</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Behavior Analysis with Machine Learning Using R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="abnormalbehaviors" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Chapter 10</span> Detecting Abnormal Behaviors<a href="abnormalbehaviors.html#abnormalbehaviors" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Abnormal data points are instances that are rare or do not occur very often. They are also called <em>outliers</em>. Some examples include illegal bank transactions, defective products, natural disasters, etc. Detecting abnormal behaviors is an important topic in the fields of health care, ecology, economy, psychology, and so on. For example, abnormal behaviors in wildlife creatures can be an indication of abrupt changes in the environment and rare behavioral patterns in a person may be an indication of health deterioration.</p>
<p>Anomaly detection can be formulated as a binary classification task and solved by training a classifier to distinguish between <em>normal</em> and <em>abnormal</em> instances. The problem with this approach is that anomalous points are rare and there may not be enough to train a classifier. This can also lead to class imbalance problems. Furthermore, the models should be able to detect abnormal points even if they are very different from the training data. To address those issues, several anomaly detection methods have been developed over the years and this chapter introduces two of them: Isolation Forests and autoencoders.</p>
<p>This chapter starts by explaining how Isolation Forests work and then, an example of how to apply them for abnormal trajectory detection is presented. Next, a method (ROC curve) to evaluate the performance of such models is described. Finally, another method called autoencoder that can be used for anomaly detection is explained and applied to the abnormal trajectory detection problem.</p>
<div id="isolation-forests" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Isolation Forests<a href="abnormalbehaviors.html#isolation-forests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As its name implies, an <em>Isolation Forest</em> identifies anomalous points by explicitly ‘isolating’ them. In this context <em>isolation</em> means separating an instance from the others. This approach is different from many other anomaly detection algorithms where they first build a profile of normal instances and mark an instance as an anomaly if it does not conform to the normal profile. Isolation Forests were proposed by <span class="citation">Liu, Ting, and Zhou (<a href="#ref-Liu2008isolation">2008</a>)</span> and the method is based on building many trees (similar to Random Forests, chapter <a href="ensemble.html#ensemble">3</a>). This method has several advantages including its efficiency in terms of time and memory usage. Another advantage is that at training time it does not need to have examples of the abnormal cases but if available, they can be incorporated as well. Since this method is based on trees, another nice thing about it is that there is no need to scale the features.</p>
<p>This method is based on the observation that anomalies are ‘few and different’ which makes them easier to isolate. It is based on building an ensemble of trees where each tree is called an Isolation Tree. Each Isolation Tree partitions the features until every instance is isolated (it’s at a leaf node). Since anomalies are easier to isolate they will be closer to the root of the tree. An instance is marked as an anomaly if its average path length to the root across all Isolation Trees is short.</p>
<p>A tree is generated recursively by randomly selecting a feature and then selecting a random partition between the maximum and minimum value of that feature. Each partition corresponds to a split in a tree. The procedure terminates when all instances are isolated. The number of partitions that were required to isolate a point corresponds to the path length of that point to the root of the tree.</p>
<p>Figure <a href="abnormalbehaviors.html#fig:partitionExamle">10.1</a> shows a set of points with only one feature (x axis). One of the anomalous points is highlighted as a red triangle. One of the normal points is marked as a blue solid circle.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:partitionExamle"></span>
<img src="images/anomaly_example.png" alt="Example partitioning of a normal and an anomalous point." width="100%" />
<p class="caption">
FIGURE 10.1: Example partitioning of a normal and an anomalous point.
</p>
</div>
<p>To isolate the anomalous instance, we can randomly and recursively choose partition positions (vertical lines in Figure <a href="abnormalbehaviors.html#fig:partitionExamle">10.1</a>) until the instance is encapsulated in its own partition. In this example, it took <span class="math inline">\(4\)</span> partitions (red lines) to isolate the anomalous instance, thus, the path length of this instance to the root of the tree is <span class="math inline">\(4\)</span>. The partitions were located at <span class="math inline">\(0.51, 1.6, 1.7,\)</span> and <span class="math inline">\(1.8\)</span>. The code to reproduce this example is in the script <code>example_isolate_point.R</code>. If we look at the highlighted normal instance we can see that it took <span class="math inline">\(8\)</span> partitions to isolate it.</p>
<p>Instead of generating a single tree, we can generate an ensemble of <span class="math inline">\(n\)</span> trees and average their path lengths. Figure <a href="abnormalbehaviors.html#fig:anomalyIts">10.2</a> shows the average path length for the same previous normal and anomalous instances as the number of trees in the ensemble is increased.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:anomalyIts"></span>
<img src="images/anomaly_its.png" alt="Average path lenghts for increasing number of trees." width="100%" />
<p class="caption">
FIGURE 10.2: Average path lenghts for increasing number of trees.
</p>
</div>
<p>After <span class="math inline">\(200\)</span> trees, the average path length of the normal instance starts to converge to <span class="math inline">\(8.7\)</span> and the path length of the anomalous one converges to <span class="math inline">\(3.1\)</span>. This shows that anomalies have shorter path lengths on average.</p>
<p>In practice, an Isolation Tree is recursively grown until a predefined maximum height is reached (more on this later), or when all instances are isolated, or all instances in a partition have the same values. Once all Isolation Trees in the ensemble (Isolation Forest) are generated, the instances can be sorted according to their average path length to the root. Then, instances with the shorter path lengths can be marked as anomalies.</p>
<p>Instead of directly using the average path lengths for deciding whether or not an instance is an anomaly, the authors of the method proposed an anomaly score that is between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. The reason for this, is that this score is easier to interpret since it’s normalized. The closer the anomaly score is to <span class="math inline">\(1\)</span> the more likely the instance is an anomaly. Instances with anomaly scores <span class="math inline">\(&lt;&lt; 0.5\)</span> can be marked as normal. The anomaly score for an instance <span class="math inline">\(x\)</span> is computed with the formula:</p>
<p><span class="math display" id="eq:anomalyScore">\[\begin{equation}
  s(x) = 2^{-\frac{E(h(x))}{c(n)}}
  \tag{10.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(h(x)\)</span> is the path length of <span class="math inline">\(x\)</span> to the root of a given tree and <span class="math inline">\(E(h(x))\)</span> is the average of the path lengths of <span class="math inline">\(x\)</span> across all trees in the ensemble. <span class="math inline">\(n\)</span> is the number of instances in the train set. <span class="math inline">\(c(n)\)</span> is the average path length of an unsuccessful search in a binary search tree:</p>
<p><span class="math display" id="eq:avgpathlength">\[\begin{equation}
  c(n) = 2H(n-1) - (2(n-1)/n)
  \tag{10.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(H(x)\)</span> denotes the harmonic number and is estimated by <span class="math inline">\(ln(x) + 0.5772156649\)</span> (Euler-Mascheroni constant).</p>
<p>A practical ‘trick’ that Isolation Forests use is <em>sub-sampling without replacement</em>. That is, instead of using the entire training set, an independent random sample of size <span class="math inline">\(p\)</span> is used to build each tree. The sub-sampling reduces the <em>swamping</em> and <em>masking</em> effects. <em>Swamping</em> occurs when normal instances are too close to anomalies and thus, marked as anomalies. <em>Masking</em> refers to the presence of too many anomalies close together. This increases the number of partitions needed to isolate each anomaly point.</p>
<p>Figure <a href="abnormalbehaviors.html#fig:samplingInstances">10.3</a> (left) shows a set of <span class="math inline">\(4000\)</span> normal and <span class="math inline">\(100\)</span> anomalous instances clustered in the same region. The right plot shows how it looks like after sampling <span class="math inline">\(256\)</span> instances from the total. Here, we can see that the anomalous points are more clearly separated from the normal ones.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:samplingInstances"></span>
<img src="images/sampling_instances.png" alt="Dataset before and after sampling." width="100%" />
<p class="caption">
FIGURE 10.3: Dataset before and after sampling.
</p>
</div>
<p>Previously, I mentioned that trees are grown until a predefined maximum height is reached. The authors of the method suggest to set this maximum height to <span class="math inline">\(l=ceiling(log_2(p))\)</span> which approximates the average tree height. Remember that <span class="math inline">\(p\)</span> is the sampling size. Since anomalous instances are closer to the root, we can expect normal instances to be in the lower sections of the tree, thus, there is no need to grow the entire tree and we can limit its height.</p>
<p>The only two parameters of the algorithm are the number of trees and the sampling size <span class="math inline">\(p\)</span>. The authors recommend a default sampling size of <span class="math inline">\(256\)</span> and <span class="math inline">\(100\)</span> trees.</p>
<p>At training time, the ensemble of trees is generated using the train data. It is not necessary that the train data contain examples of anomalous instances. This is advantageous because in many cases the anomalous instances are scarce so we can reserve them for testing. At test time, instances in the test set are passed through all trees and an anomaly score is computed for each. Instances with an anomaly score greater than some threshold are marked as anomalies. The optimal threshold can be estimated using an Area Under the Curve analysis which will be covered in the following sections.</p>
<p>The <code>solitude</code> R package <span class="citation">(<a href="#ref-solitude">Srikanth 2020</a>)</span> provides convenient functions to train Isolation Forests and make predictions. In the following section we will use it to detect abnormal fish behaviors.</p>
</div>
<div id="detecting-abnormal-fish-behaviors" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Detecting Abnormal Fish Behaviors<a href="abnormalbehaviors.html#detecting-abnormal-fish-behaviors" class="anchor-section" aria-label="Anchor link to header"></a></h2>

<div class="rmdfolder">
<code>visualize_fish.R</code> <code>extract_features.R</code> <code>isolation_forest_fish.R</code>
</div>
<p>In marine biology, the analysis of fish behavior is essential since it can be used to detect environmental changes produced by pollution, climate change, etc. Fish behaviors can be characterized by their trajectories, that is, how they move within the environment. A <strong>trajectory</strong> is the path that an object follows through space and time.</p>
<p>Capturing fish trajectories is a challenging task specially, in unconstrained underwater conditions. Thankfully, the Fish4Knowledge<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a> project has developed fish analysis tools and methods to ease the task. They have processed enormous amounts of video streaming data and have extracted fish information including trajectories. They have made the fish trajectories dataset publicly available<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a> <span class="citation">(<a href="#ref-Beyan2013">Beyan and Fisher 2013</a>)</span>.</p>
<p>The <em>FISH TRAJECTORIES</em> dataset contains <span class="math inline">\(3102\)</span> trajectories belonging to the <em>Dascyllus reticulatus</em> fish (see Figure <a href="abnormalbehaviors.html#fig:dascyllus">10.4</a>) observed in the Taiwanese coral reef. Each trajectory is labeled as <em>‘normal’</em> or <em>‘abnormal’</em>. The trajectories were extracted from underwater video and stored as coordinates over time.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dascyllus"></span>
<img src="images/dascyllus_reticulatus.jpg" alt="Example of Dascyllus reticulatus fish. (Author: Rickard Zerpe. Source: wikimedia.org (CC BY 2.0) [https://creativecommons.org/licenses/by/2.0/legalcode])." width="45%" />
<p class="caption">
FIGURE 10.4: Example of Dascyllus reticulatus fish. (Author: Rickard Zerpe. Source: wikimedia.org (CC BY 2.0) [<a href="https://creativecommons.org/licenses/by/2.0/legalcode" class="uri">https://creativecommons.org/licenses/by/2.0/legalcode</a>]).
</p>
</div>
<p>Our main task will be to detect the <strong>abnormal</strong> trajectories using an Isolation Forest but before that, we are going to explore, visualize, and pre-process the dataset.</p>
<div id="exploring-and-visualizing-trajectories" class="section level3 hasAnchor" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Exploring and Visualizing Trajectories<a href="abnormalbehaviors.html#exploring-and-visualizing-trajectories" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The data is stored in a <code>.mat</code> file, so we are going to use the package <code>R.matlab</code> <span class="citation">(<a href="#ref-rmatlab">Bengtsson 2018</a>)</span> to import the data into an array. The following code can be found in the script <code>visualize_fish.R</code>.</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="abnormalbehaviors.html#cb218-1" tabindex="-1"></a><span class="fu">library</span>(R.matlab)</span>
<span id="cb218-2"><a href="abnormalbehaviors.html#cb218-2" tabindex="-1"></a></span>
<span id="cb218-3"><a href="abnormalbehaviors.html#cb218-3" tabindex="-1"></a><span class="co"># Read data.</span></span>
<span id="cb218-4"><a href="abnormalbehaviors.html#cb218-4" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">readMat</span>(<span class="st">&quot;../fishDetections_total3102.mat&quot;</span>)<span class="er">)</span><span class="sc">$</span>fish.detections</span>
<span id="cb218-5"><a href="abnormalbehaviors.html#cb218-5" tabindex="-1"></a></span>
<span id="cb218-6"><a href="abnormalbehaviors.html#cb218-6" tabindex="-1"></a><span class="co"># Print data frame dimensions.</span></span>
<span id="cb218-7"><a href="abnormalbehaviors.html#cb218-7" tabindex="-1"></a><span class="fu">dim</span>(df)</span>
<span id="cb218-8"><a href="abnormalbehaviors.html#cb218-8" tabindex="-1"></a><span class="co">#&gt; [1]    7    1 3102</span></span></code></pre></div>
<p>We use the <code>dim()</code> function to print the dimensions of the array. From the output, we can see that there are <span class="math inline">\(3102\)</span> individual trajectories and each trajectory has <span class="math inline">\(7\)</span> attributes. Let’s explore what are the contents of a single trajectory. The following code snippet extracts the first trajectory and prints its structure.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="abnormalbehaviors.html#cb219-1" tabindex="-1"></a><span class="co"># Read one of the trajectories.</span></span>
<span id="cb219-2"><a href="abnormalbehaviors.html#cb219-2" tabindex="-1"></a>trj <span class="ot">&lt;-</span> df[,,<span class="dv">1</span>]</span>
<span id="cb219-3"><a href="abnormalbehaviors.html#cb219-3" tabindex="-1"></a></span>
<span id="cb219-4"><a href="abnormalbehaviors.html#cb219-4" tabindex="-1"></a><span class="co"># Inspect its structure.</span></span>
<span id="cb219-5"><a href="abnormalbehaviors.html#cb219-5" tabindex="-1"></a><span class="fu">str</span>(trj)</span>
<span id="cb219-6"><a href="abnormalbehaviors.html#cb219-6" tabindex="-1"></a><span class="co">#&gt; List of 7</span></span>
<span id="cb219-7"><a href="abnormalbehaviors.html#cb219-7" tabindex="-1"></a><span class="co">#&gt; $ frame.number    : num [1:37, 1] 826 827 828 829 833 834 835 836 ...</span></span>
<span id="cb219-8"><a href="abnormalbehaviors.html#cb219-8" tabindex="-1"></a><span class="co">#&gt; $ bounding.box.x  : num [1:37, 1] 167 165 162 159 125 124 126 126 ...</span></span>
<span id="cb219-9"><a href="abnormalbehaviors.html#cb219-9" tabindex="-1"></a><span class="co">#&gt; $ bounding.box.y  : num [1:37, 1] 67 65 65 66 58 61 65 71 71 62 ...</span></span>
<span id="cb219-10"><a href="abnormalbehaviors.html#cb219-10" tabindex="-1"></a><span class="co">#&gt; $ bounding.box.w  : num [1:37, 1] 40 37 39 34 39 39 38 38 37 31 ...</span></span>
<span id="cb219-11"><a href="abnormalbehaviors.html#cb219-11" tabindex="-1"></a><span class="co">#&gt; $ bounding.box.h  : num [1:37, 1] 38 40 40 38 35 34 34 33 34 35 ...</span></span>
<span id="cb219-12"><a href="abnormalbehaviors.html#cb219-12" tabindex="-1"></a><span class="co">#&gt; $ class           : num [1, 1] 1</span></span>
<span id="cb219-13"><a href="abnormalbehaviors.html#cb219-13" tabindex="-1"></a><span class="co">#&gt; $ classDescription: chr [1, 1] &quot;normal&quot;</span></span></code></pre></div>
<p>A trajectory is composed of <span class="math inline">\(7\)</span> pieces of information:</p>
<ol style="list-style-type: decimal">
<li>frame.number: Frame number in original video.</li>
<li>bounding.box.x: Bounding box leftmost edge.</li>
<li>bounding.box.y: Bounding box topmost edge.</li>
<li>bounding.box.w: Bounding box width.</li>
<li>bounding.box.h: Bounding box height.</li>
<li>class: 1=normal, 2=rare.</li>
<li>classDescription: ‘normal’ or abnormal’.</li>
</ol>
<p>The bounding box represents the square region where the fish was detected in the video footage. Figure <a href="abnormalbehaviors.html#fig:fishBox">10.5</a> shows an example of a fish and its bounding box (not from the original dataset but for illustration purpose only). Also note that the dataset does not contain the images but only the bounding boxes’ coordinates.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:fishBox"></span>
<img src="images/bounding_box.png" alt="Fish bounding box (in red). (Author: Nick Hobgood. Source: wikimedia.org (CC BY-SA 3.0) [https://creativecommons.org/licenses/by-sa/3.0/legalcode])." width="40%" />
<p class="caption">
FIGURE 10.5: Fish bounding box (in red). (Author: Nick Hobgood. Source: wikimedia.org (CC BY-SA 3.0) [<a href="https://creativecommons.org/licenses/by-sa/3.0/legalcode" class="uri">https://creativecommons.org/licenses/by-sa/3.0/legalcode</a>]).
</p>
</div>
<p>Each trajectory has a different number of video frames. We can get the frame count by inspecting the length of one of the coordinates.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="abnormalbehaviors.html#cb220-1" tabindex="-1"></a><span class="co"># Count how many frames this trajectory has.</span></span>
<span id="cb220-2"><a href="abnormalbehaviors.html#cb220-2" tabindex="-1"></a><span class="fu">length</span>(trj<span class="sc">$</span>bounding.box.x)</span>
<span id="cb220-3"><a href="abnormalbehaviors.html#cb220-3" tabindex="-1"></a><span class="co">#&gt; [1] 37</span></span></code></pre></div>
<p>The first trajectory has <span class="math inline">\(37\)</span> frames but on average, they have <span class="math inline">\(10\)</span> frames. For our analyses, we only include trajectories with a minimum of <span class="math inline">\(10\)</span> frames since it may be difficult to extract patterns from shorter paths. Furthermore, we are not going to use the bounding boxes themselves but the center point of the box.</p>
<p>At this point, it would be a good idea to plot how the data looks like. To do so, I will use the <code>anipaths</code> package <span class="citation">(<a href="#ref-anipaths">Scharf 2020</a>)</span> which has a function to animate trajectories! I will not cover the details here on how to use the package but the complete code is in the same script <code>visualize_fish.R</code>. The output result is in the form of an ‘index.html’ file that contains the interactive animation. For simplicity, I only selected <span class="math inline">\(50\)</span> and <span class="math inline">\(10\)</span> normal and abnormal trajectories (respectively) to be plotted. Figure <a href="abnormalbehaviors.html#fig:animTrajectories">10.6</a> shows the resulting plot. The plot also includes some controls to play, pause, change the speed of the animation, etc.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:animTrajectories"></span>
<img src="images/anim_trajectories.png" alt="Example of animated trajectories generated with the anipaths package." width="50%" />
<p class="caption">
FIGURE 10.6: Example of animated trajectories generated with the anipaths package.
</p>
</div>
<p>The <em>‘normal’</em> and <em>‘abnormal’</em> labels were determined by visual inspection by experts. The abnormal cases include events such as predator avoidance and aggressive movements (due to another fish or because of being frightened).</p>
</div>
<div id="preprocessing-and-feature-extraction" class="section level3 hasAnchor" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Preprocessing and Feature Extraction<a href="abnormalbehaviors.html#preprocessing-and-feature-extraction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have explored and visualized the data, we can begin with the preprocessing and feature extraction. As previously mentioned, the database contains bounding boxes and we want to use the center of the boxes to define the trajectories. The following code snippet (from <code>extract_features.R</code>) shows how the center of a box can be computed.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="abnormalbehaviors.html#cb221-1" tabindex="-1"></a><span class="co"># Compute center of bounding box.</span></span>
<span id="cb221-2"><a href="abnormalbehaviors.html#cb221-2" tabindex="-1"></a>x.coord <span class="ot">&lt;-</span> trj<span class="sc">$</span>bounding.box.x <span class="sc">+</span> (trj<span class="sc">$</span>bounding.box.w <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb221-3"><a href="abnormalbehaviors.html#cb221-3" tabindex="-1"></a>y.coord <span class="ot">&lt;-</span> trj<span class="sc">$</span>bounding.box.y <span class="sc">+</span> (trj<span class="sc">$</span>bounding.box.h <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb221-4"><a href="abnormalbehaviors.html#cb221-4" tabindex="-1"></a>  </span>
<span id="cb221-5"><a href="abnormalbehaviors.html#cb221-5" tabindex="-1"></a><span class="co"># Make times start at 0.</span></span>
<span id="cb221-6"><a href="abnormalbehaviors.html#cb221-6" tabindex="-1"></a>times <span class="ot">&lt;-</span> trj<span class="sc">$</span>frame.number <span class="sc">-</span> trj<span class="sc">$</span>frame.number[<span class="dv">1</span>]</span>
<span id="cb221-7"><a href="abnormalbehaviors.html#cb221-7" tabindex="-1"></a>tmp <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x.coord, y.coord, <span class="at">time=</span>times)</span></code></pre></div>
<p>The <em>x</em> and <em>y</em> coordinates of the center points from a given trajectory <code>trj</code> for all time frames will be stored in <code>x.coord</code> and <code>y.coord</code>. The next line ‘shifts’ the frame numbers so they all start in <span class="math inline">\(0\)</span> (to simplify preprocessing). Finally we store the coordinates and frame times in a temporal data frame for further preprocessing.</p>
<p>At this point we will use the <code>trajr</code> package <span class="citation">(<a href="#ref-trajr">McLean and Volponi 2018</a>)</span> which includes functions to plot and perform operations on trajectories. The <code>TrajFromCoords()</code> function can be used to create a trajectory object from a data frame. Note that the data frame needs to have a predefined order. That is why we first stored the x coordinates, then the y coordinates, and finally the time in the <code>tmp</code> data frame.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="abnormalbehaviors.html#cb222-1" tabindex="-1"></a>tmp.trj <span class="ot">&lt;-</span> <span class="fu">TrajFromCoords</span>(tmp, <span class="at">fps =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>The temporal data frame is passed as the first argument and the frames per second is set to <span class="math inline">\(1\)</span>. Now we plot the <code>tmp.trj</code> object.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="abnormalbehaviors.html#cb223-1" tabindex="-1"></a><span class="fu">plot</span>(tmp.trj, <span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;y&quot;</span>)</span>
<span id="cb223-2"><a href="abnormalbehaviors.html#cb223-2" tabindex="-1"></a><span class="fu">points</span>(tmp.trj, <span class="at">draw.start.pt =</span> T, <span class="at">pch =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb223-3"><a href="abnormalbehaviors.html#cb223-3" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;Starting point&quot;</span>), <span class="at">pch =</span> <span class="fu">c</span>(<span class="dv">16</span>), <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;black&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:trajPlot"></span>
<img src="images/traj_plot.png" alt="Plot of first trajectory." width="100%" />
<p class="caption">
FIGURE 10.7: Plot of first trajectory.
</p>
</div>
<p>From Figure <a href="abnormalbehaviors.html#fig:trajPlot">10.7</a> we can see that there are big time gaps between some points. This is because some time frames are missing. If we print the first rows of the trajectory and look at the time, we see that for example, time steps <span class="math inline">\(4,5,\)</span> and <span class="math inline">\(6\)</span> are missing.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="abnormalbehaviors.html#cb224-1" tabindex="-1"></a><span class="fu">head</span>(tmp.trj)</span>
<span id="cb224-2"><a href="abnormalbehaviors.html#cb224-2" tabindex="-1"></a><span class="co">#&gt;        x    y time displacementTime       polar displacement</span></span>
<span id="cb224-3"><a href="abnormalbehaviors.html#cb224-3" tabindex="-1"></a><span class="co">#&gt; 1  187.0 86.0    0                0 187.0+86.0i     0.0+0.0i</span></span>
<span id="cb224-4"><a href="abnormalbehaviors.html#cb224-4" tabindex="-1"></a><span class="co">#&gt; 2  183.5 85.0    1                1 183.5+85.0i    -3.5-1.0i</span></span>
<span id="cb224-5"><a href="abnormalbehaviors.html#cb224-5" tabindex="-1"></a><span class="co">#&gt; 3  181.5 85.0    2                2 181.5+85.0i    -2.0+0.0i</span></span>
<span id="cb224-6"><a href="abnormalbehaviors.html#cb224-6" tabindex="-1"></a><span class="co">#&gt; 4  176.0 85.0    3                3 176.0+85.0i    -5.5+0.0i</span></span>
<span id="cb224-7"><a href="abnormalbehaviors.html#cb224-7" tabindex="-1"></a><span class="co">#&gt; 5  144.5 75.5    7                7 144.5+75.5i   -31.5-9.5i</span></span></code></pre></div>
<p>Before continuing, it would be a good idea to try to fill those gaps. The function <code>TrajResampleTime()</code> does exactly that by applying linear interpolation along the trajectory.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="abnormalbehaviors.html#cb225-1" tabindex="-1"></a>resampled <span class="ot">&lt;-</span> <span class="fu">TrajResampleTime</span>(tmp.trj, <span class="dv">1</span>)</span></code></pre></div>
<p>If we plot the resampled trajectory (Figure <a href="abnormalbehaviors.html#fig:trajResampledPlot">10.8</a>) we will see how the missing points were filled.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:trajResampledPlot"></span>
<img src="images/traj_resampled_plot.png" alt="The original trajectory (circles) and after filling the gaps with linear interpolation (crosses)." width="100%" />
<p class="caption">
FIGURE 10.8: The original trajectory (circles) and after filling the gaps with linear interpolation (crosses).
</p>
</div>
<p>Now we are almost ready to start detecting anomalies. Remember that Isolation Trees work with features by making partitions. Thus, we need to convert the trajectories into a feature vector representation. To do that, we will extract some features from the trajectories based on <em>speed</em> and <em>acceleration</em>. The <code>TrajDerivatives()</code> function computes the speed and linear acceleration between pairs of trajectory points.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="abnormalbehaviors.html#cb226-1" tabindex="-1"></a>derivs <span class="ot">&lt;-</span> <span class="fu">TrajDerivatives</span>(resampled)</span>
<span id="cb226-2"><a href="abnormalbehaviors.html#cb226-2" tabindex="-1"></a></span>
<span id="cb226-3"><a href="abnormalbehaviors.html#cb226-3" tabindex="-1"></a><span class="co"># Print first speeds.</span></span>
<span id="cb226-4"><a href="abnormalbehaviors.html#cb226-4" tabindex="-1"></a><span class="fu">head</span>(derivs<span class="sc">$</span>speed)</span>
<span id="cb226-5"><a href="abnormalbehaviors.html#cb226-5" tabindex="-1"></a><span class="co">#&gt; [1] 3.640055 2.000000 5.500000 8.225342 8.225342 8.225342</span></span>
<span id="cb226-6"><a href="abnormalbehaviors.html#cb226-6" tabindex="-1"></a></span>
<span id="cb226-7"><a href="abnormalbehaviors.html#cb226-7" tabindex="-1"></a><span class="co"># Print first linear accelerations.</span></span>
<span id="cb226-8"><a href="abnormalbehaviors.html#cb226-8" tabindex="-1"></a><span class="fu">head</span>(derivs<span class="sc">$</span>acceleration)</span>
<span id="cb226-9"><a href="abnormalbehaviors.html#cb226-9" tabindex="-1"></a><span class="co">#&gt; [1] -1.640055  3.500000  2.725342  0.000000  0.000000  0.000000</span></span></code></pre></div>
<p>The number of resulting speeds and accelerations are <span class="math inline">\(n-1\)</span> and <span class="math inline">\(n-2\)</span>, respectively where <span class="math inline">\(n\)</span> is the number of time steps in the trajectory. When training an Isolation Forest, all feature vectors need to be of the same length however, the trajectories in the database have different number of time steps. In order to have fixed-length feature vectors we will compute the <em>mean</em>, <em>standard deviation</em>, <em>min</em>, and <em>max</em> from both, the speeds and accelerations. Thus, we will end up having <span class="math inline">\(8\)</span> features per trajectory. Finally we assemble the features into a data frame along with the trajectory id and the label (<em>‘normal’</em> or <em>‘abnormal’</em>).</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="abnormalbehaviors.html#cb227-1" tabindex="-1"></a>  f.meanSpeed <span class="ot">&lt;-</span> <span class="fu">mean</span>(derivs<span class="sc">$</span>speed)</span>
<span id="cb227-2"><a href="abnormalbehaviors.html#cb227-2" tabindex="-1"></a>  f.sdSpeed <span class="ot">&lt;-</span> <span class="fu">sd</span>(derivs<span class="sc">$</span>speed)</span>
<span id="cb227-3"><a href="abnormalbehaviors.html#cb227-3" tabindex="-1"></a>  f.minSpeed <span class="ot">&lt;-</span> <span class="fu">min</span>(derivs<span class="sc">$</span>speed)</span>
<span id="cb227-4"><a href="abnormalbehaviors.html#cb227-4" tabindex="-1"></a>  f.maxSpeed <span class="ot">&lt;-</span> <span class="fu">max</span>(derivs<span class="sc">$</span>speed)</span>
<span id="cb227-5"><a href="abnormalbehaviors.html#cb227-5" tabindex="-1"></a>  </span>
<span id="cb227-6"><a href="abnormalbehaviors.html#cb227-6" tabindex="-1"></a>  f.meanAcc <span class="ot">&lt;-</span> <span class="fu">mean</span>(derivs<span class="sc">$</span>acceleration)</span>
<span id="cb227-7"><a href="abnormalbehaviors.html#cb227-7" tabindex="-1"></a>  f.sdAcc <span class="ot">&lt;-</span> <span class="fu">sd</span>(derivs<span class="sc">$</span>acceleration)</span>
<span id="cb227-8"><a href="abnormalbehaviors.html#cb227-8" tabindex="-1"></a>  f.minAcc <span class="ot">&lt;-</span> <span class="fu">min</span>(derivs<span class="sc">$</span>acceleration)</span>
<span id="cb227-9"><a href="abnormalbehaviors.html#cb227-9" tabindex="-1"></a>  f.maxAcc <span class="ot">&lt;-</span> <span class="fu">max</span>(derivs<span class="sc">$</span>acceleration)</span>
<span id="cb227-10"><a href="abnormalbehaviors.html#cb227-10" tabindex="-1"></a>  </span>
<span id="cb227-11"><a href="abnormalbehaviors.html#cb227-11" tabindex="-1"></a>  features <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">id=</span><span class="fu">paste0</span>(<span class="st">&quot;id&quot;</span>,i), <span class="at">label=</span>trj<span class="sc">$</span>classDescription[<span class="dv">1</span>],</span>
<span id="cb227-12"><a href="abnormalbehaviors.html#cb227-12" tabindex="-1"></a>                         f.meanSpeed, f.sdSpeed, f.minSpeed, f.maxSpeed,</span>
<span id="cb227-13"><a href="abnormalbehaviors.html#cb227-13" tabindex="-1"></a>                         f.meanAcc, f.sdAcc, f.minAcc, f.maxAcc)</span></code></pre></div>
<p>We do the feature extraction for each trajectory and save the results as a .csv file <em>fishFeatures.csv</em> which is already included in the dataset. Let’s read and print the first rows of the dataset.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="abnormalbehaviors.html#cb228-1" tabindex="-1"></a><span class="co"># Read dataset.</span></span>
<span id="cb228-2"><a href="abnormalbehaviors.html#cb228-2" tabindex="-1"></a>dataset <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;fishFeatures.csv&quot;</span>, <span class="at">stringsAsFactors =</span> T)</span>
<span id="cb228-3"><a href="abnormalbehaviors.html#cb228-3" tabindex="-1"></a></span>
<span id="cb228-4"><a href="abnormalbehaviors.html#cb228-4" tabindex="-1"></a><span class="co"># Print first rows of the dataset.</span></span>
<span id="cb228-5"><a href="abnormalbehaviors.html#cb228-5" tabindex="-1"></a><span class="fu">head</span>(dataset)</span>
<span id="cb228-6"><a href="abnormalbehaviors.html#cb228-6" tabindex="-1"></a><span class="co">#&gt;    id  label f.meanSpeed f.sdSpeed f.minSpeed f.maxSpeed   f.meanAcc</span></span>
<span id="cb228-7"><a href="abnormalbehaviors.html#cb228-7" tabindex="-1"></a><span class="co">#&gt; 1 id1 normal    2.623236  2.228456  0.5000000   8.225342 -0.05366002</span></span>
<span id="cb228-8"><a href="abnormalbehaviors.html#cb228-8" tabindex="-1"></a><span class="co">#&gt; 2 id2 normal    5.984859  3.820270  1.4142136  15.101738 -0.03870468</span></span>
<span id="cb228-9"><a href="abnormalbehaviors.html#cb228-9" tabindex="-1"></a><span class="co">#&gt; 3 id3 normal   16.608716 14.502042  0.7071068  46.424670 -1.00019597</span></span>
<span id="cb228-10"><a href="abnormalbehaviors.html#cb228-10" tabindex="-1"></a><span class="co">#&gt; 4 id5 normal    4.808608  4.137387  0.5000000  17.204651 -0.28181520</span></span>
<span id="cb228-11"><a href="abnormalbehaviors.html#cb228-11" tabindex="-1"></a><span class="co">#&gt; 5 id6 normal   17.785747  9.926729  3.3541020  44.240818 -0.53753380</span></span>
<span id="cb228-12"><a href="abnormalbehaviors.html#cb228-12" tabindex="-1"></a><span class="co">#&gt; 6 id7 normal    9.848422  6.026229  0.0000000  33.324165 -0.10555561</span></span>
<span id="cb228-13"><a href="abnormalbehaviors.html#cb228-13" tabindex="-1"></a><span class="co">#&gt; f.sdAcc   f.minAcc  f.maxAcc</span></span>
<span id="cb228-14"><a href="abnormalbehaviors.html#cb228-14" tabindex="-1"></a><span class="co">#&gt; 1  1.839475  -5.532760  3.500000</span></span>
<span id="cb228-15"><a href="abnormalbehaviors.html#cb228-15" tabindex="-1"></a><span class="co">#&gt; 2  2.660073  -7.273932  7.058594</span></span>
<span id="cb228-16"><a href="abnormalbehaviors.html#cb228-16" tabindex="-1"></a><span class="co">#&gt; 3 12.890386 -24.320298 30.714624</span></span>
<span id="cb228-17"><a href="abnormalbehaviors.html#cb228-17" tabindex="-1"></a><span class="co">#&gt; 4  5.228209 -12.204651 15.623512</span></span>
<span id="cb228-18"><a href="abnormalbehaviors.html#cb228-18" tabindex="-1"></a><span class="co">#&gt; 5 11.272472 -22.178067 21.768613</span></span>
<span id="cb228-19"><a href="abnormalbehaviors.html#cb228-19" tabindex="-1"></a><span class="co">#&gt; 6  6.692688 -31.262613 11.683561</span></span></code></pre></div>
<p>Each row represents one trajectory. We can use the <code>table()</code> function to get the counts for <em>‘normal’</em> and <em>‘abnormal’</em> cases.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="abnormalbehaviors.html#cb229-1" tabindex="-1"></a><span class="fu">table</span>(dataset<span class="sc">$</span>label)</span>
<span id="cb229-2"><a href="abnormalbehaviors.html#cb229-2" tabindex="-1"></a><span class="co">#&gt; abnormal   normal </span></span>
<span id="cb229-3"><a href="abnormalbehaviors.html#cb229-3" tabindex="-1"></a><span class="co">#&gt;       54     1093</span></span></code></pre></div>
<p>After discarding trajectories with less than <span class="math inline">\(10\)</span> points we ended up with <span class="math inline">\(1093\)</span> <em>‘normal’</em> instances and <span class="math inline">\(54\)</span> <em>‘abnormal’</em> instances.</p>
</div>
<div id="training-the-model" class="section level3 hasAnchor" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> Training the Model<a href="abnormalbehaviors.html#training-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To get a preliminary idea of how difficult it is to separate the two classes we can use a MDS plot (see chapter <a href="edavis.html#edavis">4</a>) to project the <span class="math inline">\(8\)</span> features into a <span class="math inline">\(2\)</span>-dimensional plane.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mdsFishes"></span>
<img src="images/mdsFishes.png" alt="MDS of the fish trajectories." width="80%" />
<p class="caption">
FIGURE 10.9: MDS of the fish trajectories.
</p>
</div>
<p>In Figure <a href="abnormalbehaviors.html#fig:mdsFishes">10.9</a> we see that several <em>abnormal</em> points are in the right hand side but many others are in the same space as the <em>normal</em> points so it’s time to train an Isolation Forest and see to what extent it can detect the abnormal cases!</p>
<p>One of the nice things about Isolation Forest is that it does not need examples of the abnormal cases during training. If we want, we can also include the abnormal cases but since we don’t have many we will reserve them for the test set. The script <code>isolation_forest_fish.R</code> contains the code to train the model. We will split the data into a train set (<span class="math inline">\(80\%\)</span>) consisting only of normal instances and a test set with both, normal and abnormal instances. The train set is stored in the data frame <code>train.normal</code> and the test set in <code>test.all</code>. Since the method is based on trees, we don’t need to normalize the data.</p>
<p>First, we need to define the parameters of the Isolation Forest. We can do so by passing the values at creation time.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="abnormalbehaviors.html#cb230-1" tabindex="-1"></a>m.iforest <span class="ot">&lt;-</span> isolationForest<span class="sc">$</span><span class="fu">new</span>(<span class="at">sample_size =</span> <span class="dv">256</span>,</span>
<span id="cb230-2"><a href="abnormalbehaviors.html#cb230-2" tabindex="-1"></a>                                 <span class="at">num_trees =</span> <span class="dv">100</span>,</span>
<span id="cb230-3"><a href="abnormalbehaviors.html#cb230-3" tabindex="-1"></a>                                 <span class="at">nproc =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>As suggested in the original paper <span class="citation">(<a href="#ref-Liu2008isolation">Liu, Ting, and Zhou 2008</a>)</span>, the sampling size is set to <span class="math inline">\(256\)</span> and the number of trees to <span class="math inline">\(100\)</span>. The <code>nproc</code> parameter specifies the number of CPU cores to use. I set it to <span class="math inline">\(1\)</span> to ensure we get reproducible results.</p>
<p>Now we can train the model with the train set. The first two columns are removed since they correspond to the trajectories ids and class label.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="abnormalbehaviors.html#cb231-1" tabindex="-1"></a><span class="co"># Fit the model.</span></span>
<span id="cb231-2"><a href="abnormalbehaviors.html#cb231-2" tabindex="-1"></a>m.iforest<span class="sc">$</span><span class="fu">fit</span>(train.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span></code></pre></div>
<p>Once the model is trained, we can start making predictions. Let’s start by making predictions on the <strong>train set</strong> (later we’ll do it on the test set). We know that the train set only consists of normal instances.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="abnormalbehaviors.html#cb232-1" tabindex="-1"></a><span class="co"># Predict anomaly scores on train set.</span></span>
<span id="cb232-2"><a href="abnormalbehaviors.html#cb232-2" tabindex="-1"></a>train.scores <span class="ot">&lt;-</span> m.iforest<span class="sc">$</span><span class="fu">predict</span>(train.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span></code></pre></div>
<p>The returned value of the <code>predict()</code> function is a data frame containing the average tree depth and the anomaly score for each instance.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="abnormalbehaviors.html#cb233-1" tabindex="-1"></a><span class="co"># Print first rows of predictions.</span></span>
<span id="cb233-2"><a href="abnormalbehaviors.html#cb233-2" tabindex="-1"></a><span class="fu">head</span>(train.scores)</span>
<span id="cb233-3"><a href="abnormalbehaviors.html#cb233-3" tabindex="-1"></a></span>
<span id="cb233-4"><a href="abnormalbehaviors.html#cb233-4" tabindex="-1"></a><span class="co">#&gt;    id average_depth anomaly_score</span></span>
<span id="cb233-5"><a href="abnormalbehaviors.html#cb233-5" tabindex="-1"></a><span class="co">#&gt; 1:  1          7.97     0.5831917</span></span>
<span id="cb233-6"><a href="abnormalbehaviors.html#cb233-6" tabindex="-1"></a><span class="co">#&gt; 2:  2          8.00     0.5820092</span></span>
<span id="cb233-7"><a href="abnormalbehaviors.html#cb233-7" tabindex="-1"></a><span class="co">#&gt; 3:  3          7.98     0.5827973</span></span>
<span id="cb233-8"><a href="abnormalbehaviors.html#cb233-8" tabindex="-1"></a><span class="co">#&gt; 4:  4          7.80     0.5899383</span></span>
<span id="cb233-9"><a href="abnormalbehaviors.html#cb233-9" tabindex="-1"></a><span class="co">#&gt; 5:  5          7.77     0.5911370</span></span>
<span id="cb233-10"><a href="abnormalbehaviors.html#cb233-10" tabindex="-1"></a><span class="co">#&gt; 6:  6          7.90     0.5859603</span></span></code></pre></div>
<p>We know that the train set only has normal instances thus, we need to find the highest anomaly score so that we can set a threshold to detect the abnormal cases. The following code will print the highest anomaly scores.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="abnormalbehaviors.html#cb234-1" tabindex="-1"></a><span class="co"># Sort and display instances with the highest anomaly scores.</span></span>
<span id="cb234-2"><a href="abnormalbehaviors.html#cb234-2" tabindex="-1"></a><span class="fu">head</span>(train.scores[<span class="fu">order</span>(anomaly_score, <span class="at">decreasing =</span> <span class="cn">TRUE</span>)])</span>
<span id="cb234-3"><a href="abnormalbehaviors.html#cb234-3" tabindex="-1"></a></span>
<span id="cb234-4"><a href="abnormalbehaviors.html#cb234-4" tabindex="-1"></a><span class="co">#&gt;     id average_depth anomaly_score</span></span>
<span id="cb234-5"><a href="abnormalbehaviors.html#cb234-5" tabindex="-1"></a><span class="co">#&gt; 1:  75          4.05     0.7603188</span></span>
<span id="cb234-6"><a href="abnormalbehaviors.html#cb234-6" tabindex="-1"></a><span class="co">#&gt; 2: 618          4.45     0.7400179</span></span>
<span id="cb234-7"><a href="abnormalbehaviors.html#cb234-7" tabindex="-1"></a><span class="co">#&gt; 3: 147          4.67     0.7290844</span></span>
<span id="cb234-8"><a href="abnormalbehaviors.html#cb234-8" tabindex="-1"></a><span class="co">#&gt; 4: 661          4.75     0.7251487</span></span>
<span id="cb234-9"><a href="abnormalbehaviors.html#cb234-9" tabindex="-1"></a><span class="co">#&gt; 5: 756          4.80     0.7226998</span></span>
<span id="cb234-10"><a href="abnormalbehaviors.html#cb234-10" tabindex="-1"></a><span class="co">#&gt; 6:  54          5.54     0.6874070</span></span></code></pre></div>
<p>The highest anomaly score for a normal instance is <span class="math inline">\(0.7603\)</span> so we would assume that abnormal points will have higher anomaly scores. Armed with this information, we set the threshold to <span class="math inline">\(0.7603\)</span> and instances having a higher anomaly score will be considered to be abnormal.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="abnormalbehaviors.html#cb235-1" tabindex="-1"></a>threshold <span class="ot">&lt;-</span> <span class="fl">0.7603</span></span></code></pre></div>
<p>Now, we predict the anomaly scores on the <strong>test set</strong> and if the score is <span class="math inline">\(&gt; threshold\)</span> then we classify that point as abnormal. The <code>predicted.labels</code> array will contain <span class="math inline">\(0s\)</span> and <span class="math inline">\(1s\)</span>. A <span class="math inline">\(1\)</span> means that the instance is abnormal.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="abnormalbehaviors.html#cb236-1" tabindex="-1"></a><span class="co"># Predict anomaly scores on test set.</span></span>
<span id="cb236-2"><a href="abnormalbehaviors.html#cb236-2" tabindex="-1"></a>test.scores <span class="ot">&lt;-</span> m.iforest<span class="sc">$</span><span class="fu">predict</span>(test.all[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)])</span>
<span id="cb236-3"><a href="abnormalbehaviors.html#cb236-3" tabindex="-1"></a></span>
<span id="cb236-4"><a href="abnormalbehaviors.html#cb236-4" tabindex="-1"></a><span class="co"># Predict labels based on threshold.</span></span>
<span id="cb236-5"><a href="abnormalbehaviors.html#cb236-5" tabindex="-1"></a>predicted.labels <span class="ot">&lt;-</span> <span class="fu">as.integer</span>((test.scores<span class="sc">$</span>anomaly_score <span class="sc">&gt;</span> threshold))</span></code></pre></div>
<p>Now that we have the predicted labels we can compute some performance metrics.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="abnormalbehaviors.html#cb237-1" tabindex="-1"></a><span class="co"># All abnormal cases are at the end so we can</span></span>
<span id="cb237-2"><a href="abnormalbehaviors.html#cb237-2" tabindex="-1"></a><span class="co"># compute the ground truth as follows.</span></span>
<span id="cb237-3"><a href="abnormalbehaviors.html#cb237-3" tabindex="-1"></a>gt.all <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>,<span class="fu">nrow</span>(test.normal)), <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">nrow</span>(test.abnormal)))</span>
<span id="cb237-4"><a href="abnormalbehaviors.html#cb237-4" tabindex="-1"></a>levels <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;0&quot;</span>,<span class="st">&quot;1&quot;</span>)</span>
<span id="cb237-5"><a href="abnormalbehaviors.html#cb237-5" tabindex="-1"></a></span>
<span id="cb237-6"><a href="abnormalbehaviors.html#cb237-6" tabindex="-1"></a><span class="co"># Compute performance metrics.</span></span>
<span id="cb237-7"><a href="abnormalbehaviors.html#cb237-7" tabindex="-1"></a>cm <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(<span class="fu">factor</span>(predicted.labels, <span class="at">levels =</span> levels),</span>
<span id="cb237-8"><a href="abnormalbehaviors.html#cb237-8" tabindex="-1"></a>                      <span class="fu">factor</span>(gt.all, <span class="at">levels =</span> levels),</span>
<span id="cb237-9"><a href="abnormalbehaviors.html#cb237-9" tabindex="-1"></a>                      <span class="at">positive =</span> <span class="st">&quot;1&quot;</span>)</span>
<span id="cb237-10"><a href="abnormalbehaviors.html#cb237-10" tabindex="-1"></a></span>
<span id="cb237-11"><a href="abnormalbehaviors.html#cb237-11" tabindex="-1"></a><span class="co"># Print confusion matrix.</span></span>
<span id="cb237-12"><a href="abnormalbehaviors.html#cb237-12" tabindex="-1"></a>cm<span class="sc">$</span>table</span>
<span id="cb237-13"><a href="abnormalbehaviors.html#cb237-13" tabindex="-1"></a></span>
<span id="cb237-14"><a href="abnormalbehaviors.html#cb237-14" tabindex="-1"></a><span class="co">#&gt;           Reference</span></span>
<span id="cb237-15"><a href="abnormalbehaviors.html#cb237-15" tabindex="-1"></a><span class="co">#&gt; Prediction   0   1</span></span>
<span id="cb237-16"><a href="abnormalbehaviors.html#cb237-16" tabindex="-1"></a><span class="co">#&gt;          0 218  37</span></span>
<span id="cb237-17"><a href="abnormalbehaviors.html#cb237-17" tabindex="-1"></a><span class="co">#&gt;          1   0  17</span></span>
<span id="cb237-18"><a href="abnormalbehaviors.html#cb237-18" tabindex="-1"></a></span>
<span id="cb237-19"><a href="abnormalbehaviors.html#cb237-19" tabindex="-1"></a><span class="co"># Print sensitivity</span></span>
<span id="cb237-20"><a href="abnormalbehaviors.html#cb237-20" tabindex="-1"></a>cm<span class="sc">$</span>byClass[<span class="st">&quot;Sensitivity&quot;</span>]</span>
<span id="cb237-21"><a href="abnormalbehaviors.html#cb237-21" tabindex="-1"></a></span>
<span id="cb237-22"><a href="abnormalbehaviors.html#cb237-22" tabindex="-1"></a><span class="co">#&gt; Sensitivity </span></span>
<span id="cb237-23"><a href="abnormalbehaviors.html#cb237-23" tabindex="-1"></a><span class="co">#&gt;   0.3148148 </span></span></code></pre></div>
<p>From the confusion matrix we see that <span class="math inline">\(17\)</span> out of <span class="math inline">\(54\)</span> abnormal instances were detected. On the other hand, all the normal instances (<span class="math inline">\(218\)</span>) were correctly identified as such. The sensitivity (also known as recall) of the abnormal class was <span class="math inline">\(17/54=0.314\)</span> which seems very low. We are failing to detect several of the abnormal cases.</p>
<p>One thing we can do is to decrease the threshold at the expense of increasing the false positives, that is, classifying normal instances as abnormal. If we set <code>threshold &lt;- 0.6</code> we get the following confusion matrix.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="abnormalbehaviors.html#cb238-1" tabindex="-1"></a><span class="co">#&gt;           Reference</span></span>
<span id="cb238-2"><a href="abnormalbehaviors.html#cb238-2" tabindex="-1"></a><span class="co">#&gt; Prediction   0   1</span></span>
<span id="cb238-3"><a href="abnormalbehaviors.html#cb238-3" tabindex="-1"></a><span class="co">#&gt;          0 206   8</span></span>
<span id="cb238-4"><a href="abnormalbehaviors.html#cb238-4" tabindex="-1"></a><span class="co">#&gt;          1  12  46</span></span></code></pre></div>
<p>This time we were able to identify <span class="math inline">\(46\)</span> of the abnormal cases! This gives a sensitivity of <span class="math inline">\(46/54=0.85\)</span> which is much better than before. However, nothing is for free. If we look at the normal class, this time we had <span class="math inline">\(12\)</span> misclassified points (false positives).</p>

<div class="rmdgoodpractice">
A good way of finding the best threshold is to set apart a validation set from which the optimal threshold can be estimated. However, this is not always feasible due to the limited amount of abnormal points.
</div>
<p>In this example we manually tried different thresholds and evaluated their impact on the final results. In the following section I will show you a method that allows you to estimate the performance of a model when considering many possible thresholds at once!</p>
</div>
<div id="roc-curve-and-auc" class="section level3 hasAnchor" number="10.2.4">
<h3><span class="header-section-number">10.2.4</span> ROC Curve and AUC<a href="abnormalbehaviors.html#roc-curve-and-auc" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>receiver operating characteristic curve</strong>, also known as <strong>ROC curve</strong> is a plot that depicts how the sensitivity and the false positive rate (FPR) behave as the detection threshold varies. The sensitivity/recall can be calculated by dividing the true positives by the total number of positives <span class="math inline">\(TP/P\)</span> (see chapter <a href="classification.html#classification">2</a>). The <span class="math inline">\(FPR=FP/N\)</span> where FP are the false positives and N are the total number of negative examples (the normal trajectories). The FPR is also known as the probability of false alarm. Ideally, we want a model that has a high sensitivity and a low FPR.</p>
<p>In R we can use the <code>PRROC</code> package <span class="citation">(<a href="#ref-prroc">Grau, Grosse, and Keilwagen 2015</a>)</span> to plot ROC curves. The ROC curve of the Isolation Forest results for the abnormal fish trajectory detection can be plotted using the following code:</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="abnormalbehaviors.html#cb239-1" tabindex="-1"></a><span class="fu">library</span>(PRROC)</span>
<span id="cb239-2"><a href="abnormalbehaviors.html#cb239-2" tabindex="-1"></a>roc_obj <span class="ot">&lt;-</span> <span class="fu">roc.curve</span>(<span class="at">scores.class0 =</span> test.scores<span class="sc">$</span>anomaly_score,</span>
<span id="cb239-3"><a href="abnormalbehaviors.html#cb239-3" tabindex="-1"></a>                     <span class="at">weights.class0 =</span> gt.all,</span>
<span id="cb239-4"><a href="abnormalbehaviors.html#cb239-4" tabindex="-1"></a>                     <span class="at">curve =</span> <span class="cn">TRUE</span>,</span>
<span id="cb239-5"><a href="abnormalbehaviors.html#cb239-5" tabindex="-1"></a>                     <span class="at">rand.compute =</span> <span class="cn">TRUE</span>)</span>
<span id="cb239-6"><a href="abnormalbehaviors.html#cb239-6" tabindex="-1"></a></span>
<span id="cb239-7"><a href="abnormalbehaviors.html#cb239-7" tabindex="-1"></a><span class="co"># Set rand.plot = TRUE to also plot the random model&#39;s curve.</span></span>
<span id="cb239-8"><a href="abnormalbehaviors.html#cb239-8" tabindex="-1"></a><span class="fu">plot</span>(roc_obj, <span class="at">rand.plot =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>The argument <code>scores.class0</code> specifies the returned scores by the Isolation Forest and <code>weights.class0</code> are the true labels, <span class="math inline">\(1\)</span> for the positive class (abnormal), and <span class="math inline">\(0\)</span> for the negative class (normal). We set <code>curve=TRUE</code> so the method returns a table with thresholds and their respective sensitivity and FPR. The <code>rand.compute=TRUE</code> instructs the function to also compute the curve of a random model, that is, one that predicts scores at random. Figure <a href="abnormalbehaviors.html#fig:rocCurve">10.10</a> shows the ROC plot.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rocCurve"></span>
<img src="images/roc_curve.png" alt="ROC curve and AUC. The dashed line represents a random model." width="90%" />
<p class="caption">
FIGURE 10.10: ROC curve and AUC. The dashed line represents a random model.
</p>
</div>
<p>Here we can see how the sensitivity and FPR increase as the threshold decreases. In the best case we want a sensitivity of <span class="math inline">\(1\)</span> and a FPR of <span class="math inline">\(0\)</span>. This ideal point is located at top left corner but this model does not reach that level of performance but a bit lower. The dashed line in the diagonal is the curve for a random model. We can also access the thresholds table:</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="abnormalbehaviors.html#cb240-1" tabindex="-1"></a><span class="co"># Print first values of the curve table.</span></span>
<span id="cb240-2"><a href="abnormalbehaviors.html#cb240-2" tabindex="-1"></a>roc_obj<span class="sc">$</span>curve</span>
<span id="cb240-3"><a href="abnormalbehaviors.html#cb240-3" tabindex="-1"></a></span>
<span id="cb240-4"><a href="abnormalbehaviors.html#cb240-4" tabindex="-1"></a><span class="co">#&gt;      [,1]       [,2]      [,3]</span></span>
<span id="cb240-5"><a href="abnormalbehaviors.html#cb240-5" tabindex="-1"></a><span class="co">#&gt; [1,]    0 0.00000000 0.8015213</span></span>
<span id="cb240-6"><a href="abnormalbehaviors.html#cb240-6" tabindex="-1"></a><span class="co">#&gt; [2,]    0 0.01851852 0.7977342</span></span>
<span id="cb240-7"><a href="abnormalbehaviors.html#cb240-7" tabindex="-1"></a><span class="co">#&gt; [3,]    0 0.03703704 0.7939650</span></span>
<span id="cb240-8"><a href="abnormalbehaviors.html#cb240-8" tabindex="-1"></a><span class="co">#&gt; [4,]    0 0.05555556 0.7875449</span></span>
<span id="cb240-9"><a href="abnormalbehaviors.html#cb240-9" tabindex="-1"></a><span class="co">#&gt; [5,]    0 0.09259259 0.7864799</span></span>
<span id="cb240-10"><a href="abnormalbehaviors.html#cb240-10" tabindex="-1"></a><span class="co">#&gt;  .....</span></span></code></pre></div>
<p>The first column is the FPR, the second column is the sensitivity, and the last column is the threshold. Choosing the best threshold is not straightforward and will depend on the compromise we want to have between sensitivity and FPR.</p>
<p>Note that the plot also prints an <span class="math inline">\(AUC=0.963\)</span>. This is known as the <strong>Area Under the Curve (AUC)</strong> and as the name implies, it is the area under the ROC curve. A perfect model will have an AUC of <span class="math inline">\(1.0\)</span>. Our model achieved an AUC of <span class="math inline">\(0.963\)</span> which is pretty good. A random model will have an AUC around <span class="math inline">\(0.5\)</span>. A value below <span class="math inline">\(0.5\)</span> means that the model is performing worse than random. The AUC is a performance metric that measures the quality of a model regardless of the selected threshold and is typically presented in addition to accuracy, recall, precision, etc.</p>

<div class="rmdgoodpractice">
If someone tells you something negative about yourself (e.g., that you don’t play football well), assume that they have an AUC below <span class="math inline">\(0.5\)</span> (worse than random). At least, that’s what I do to cope with those situations. (If you invert the predictions of a binary classifier that does worse than random you will get a classifier that is better than random).
</div>
</div>
</div>
<div id="autoencoders" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Autoencoders<a href="abnormalbehaviors.html#autoencoders" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In its simplest form, an autoencoder is a neural network whose output layer has the same shape as the input layer. If you are not familiar with artificial neural networks, you can take a look at chapter <a href="deeplearning.html#deeplearning">8</a>. An autoencoder will try to learn how to generate an output that is as similar as possible to the provided input. Figure <a href="abnormalbehaviors.html#fig:simpleAutoencoder">10.11</a> shows an example of a simple autoencoder with <span class="math inline">\(4\)</span> units in the input and output layers. The hidden layer has <span class="math inline">\(2\)</span> units.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:simpleAutoencoder"></span>
<img src="images/autoencoder.png" alt="Example of a simple autoencoder." width="40%" />
<p class="caption">
FIGURE 10.11: Example of a simple autoencoder.
</p>
</div>
<p>Recall that when training a classification or regression model, we need to provide training examples of the form <span class="math inline">\((x,y)\)</span> where <span class="math inline">\(x\)</span> represents the input features and <span class="math inline">\(y\)</span> is the desired output (a label or a number). When training an autoencoder, the input and the output is the same, that is, <span class="math inline">\((x,x)\)</span>.</p>
<p>Now you may be wondering what is the point of training a model that generates the same output as its input. If you take a closer look at Figure <a href="abnormalbehaviors.html#fig:simpleAutoencoder">10.11</a> you can see that the hidden layer has fewer units (only <span class="math inline">\(2\)</span>) than the input and output layers. When the data is passed from the input layer to the hidden layer it is ‘reduced’ (compressed). Then, the compressed data is reconstructed as it is passed to the subsequent layers until it reaches the output. Thus, the neural network will learn to compress and reconstruct the data at the same time. Once the network is trained, we can get rid of the layers after the middle hidden layer and use the ‘left-hand-side’ of the network to compress our data. This left-hand-side is called the <strong>encoder</strong>. Then, we can use the right-hand-side to decompress the data. This part is called the <strong>decoder</strong>. In this example, the encoder and decoder consist of only <span class="math inline">\(1\)</span> layer but they can have more (as we will see in the next section). In practice, you will not use autoencoders to compress files in your computer because there are more efficient methods to do that. Furthermore, the compression is <em>lossy</em>, that is, there is no guarantee that the reconstructed file will be exactly the same as the original. However, autoencoders have many applications including:</p>
<ul>
<li>Dimensionality reduction for visualization.</li>
<li>Data denoising.</li>
<li>Data generation (variational autoencoders).</li>
<li>Anomaly detection (this is what we are interested in!).</li>
</ul>
<p>Recall that when training a neural network we need to define a loss function. The loss function captures how well the network is learning. It measures how different the predictions are from the true expected outputs. In the context of autoencoders, this difference is known as the <strong>reconstruction error</strong> and can be measured using the mean squared error (similar to regression).</p>

<div class="rmdinfo">
In this section I introduced the most simple type of autoencoder but there are many variants such as denoising autoencoders, variational autoencoders (VAEs), and so on. The following Wikipedia page provides a good overview of the different types of autoencoders: <a href="https://en.wikipedia.org/wiki/Autoencoder" class="uri">https://en.wikipedia.org/wiki/Autoencoder</a>
</div>
<div id="autoencoders-for-anomaly-detection" class="section level3 hasAnchor" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Autoencoders for Anomaly Detection<a href="abnormalbehaviors.html#autoencoders-for-anomaly-detection" class="anchor-section" aria-label="Anchor link to header"></a></h3>

<div class="rmdfolder">
<code>keras_autoencoder_fish.R</code>
</div>
<p>Autoencoders can be used as anomaly detectors. This idea will be demonstrated with an example to detect abnormal fish trajectories. The way this is done is by training an autoencoder to compress and reconstruct the <strong>normal</strong> instances. Once the autoencoder has learned to encode normal instances, we can expect the reconstruction error to be small. When presented with out-of-the-normal instances, the autoencoder will have a hard time trying to reconstruct them and consequently, the reconstruction error will be high. Similar to Isolation Forests where the tree path length provides a measure of the rarity of an instance, the reconstruction error in autoencoders can be used as an anomaly score.</p>
<p>To tell whether an instance is abnormal or not, we pass it through the autoencoder and compute its reconstruction error <span class="math inline">\(\epsilon\)</span>. If <span class="math inline">\(\epsilon &gt; threshold\)</span> the input data can be regarded as abnormal.</p>
<p>Similar to what we did with the Isolation Forest, we will use the <em>fishFeatures.csv</em> file that contains the fish trajectories encoded as feature vectors. Each trajectory is composed of <span class="math inline">\(8\)</span> numeric features based on acceleration and speed. We will use <span class="math inline">\(80\%\)</span> of the normal instances to train the autoencoder. All abnormal instances will be used for the test set.</p>
<p>After splitting the data (the code is in <code>keras_autoencoder_fish.R</code>), we will normalize (standardize) it. The <code>normalize.standard()</code> function will normalize the data such that it has a mean of <span class="math inline">\(0\)</span> and a standard deviation of <span class="math inline">\(1\)</span> using the following formula:</p>
<p><span class="math display" id="eq:standardize">\[\begin{equation}
  z_i = \frac{x_i - \mu}{\sigma}
  \tag{10.3}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the mean and <span class="math inline">\(\sigma\)</span> is the standard deviation of <span class="math inline">\(x\)</span>. This is slightly different from the <span class="math inline">\(0\)</span>-<span class="math inline">\(1\)</span> normalization we have used before. The reason is that when scaling to <span class="math inline">\(0\)</span>-<span class="math inline">\(1\)</span> the min and max values from the train set need to be learned. If there are data points in the test set that have values outside the min and max they will be truncated. But since we expect anomalies to have rare values, it is likely that they will be outside the train set ranges and will be truncated. After being truncated, abnormal instances could now look more similar to the normal ones thus, it will be more difficult to spot them. By standardizing the data we make sure that the extreme values of the abnormal points are preserved. In this case, the parameters to be learned from the train set are <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<p>Once the data is normalized we can define the autoencoder in keras as follows:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="abnormalbehaviors.html#cb241-1" tabindex="-1"></a>autoencoder <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>()</span>
<span id="cb241-2"><a href="abnormalbehaviors.html#cb241-2" tabindex="-1"></a></span>
<span id="cb241-3"><a href="abnormalbehaviors.html#cb241-3" tabindex="-1"></a>autoencoder <span class="sc">%&gt;%</span></span>
<span id="cb241-4"><a href="abnormalbehaviors.html#cb241-4" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>,</span>
<span id="cb241-5"><a href="abnormalbehaviors.html#cb241-5" tabindex="-1"></a>              <span class="at">input_shape =</span> <span class="fu">ncol</span>(train.normal)<span class="sc">-</span><span class="dv">2</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb241-6"><a href="abnormalbehaviors.html#cb241-6" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">16</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb241-7"><a href="abnormalbehaviors.html#cb241-7" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">8</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb241-8"><a href="abnormalbehaviors.html#cb241-8" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">16</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb241-9"><a href="abnormalbehaviors.html#cb241-9" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">32</span>, <span class="at">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb241-10"><a href="abnormalbehaviors.html#cb241-10" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="fu">ncol</span>(train.normal)<span class="sc">-</span><span class="dv">2</span>, <span class="at">activation =</span> <span class="st">&#39;linear&#39;</span>)</span></code></pre></div>
<p>This is a normal neural network with an input layer having the same number of units as number of features (<span class="math inline">\(8\)</span>). This network has <span class="math inline">\(5\)</span> hidden layers of size <span class="math inline">\(32,16,8,16\)</span>, and <span class="math inline">\(32\)</span>, respectively. The output layer has <span class="math inline">\(8\)</span> units (the same as the input layer). All activation functions are RELU’s except the last one which is linear because the network should be able to produce any number as output. Now we can compile and fit the model.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="abnormalbehaviors.html#cb242-1" tabindex="-1"></a>autoencoder <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb242-2"><a href="abnormalbehaviors.html#cb242-2" tabindex="-1"></a>  <span class="at">loss =</span> <span class="st">&#39;mse&#39;</span>,</span>
<span id="cb242-3"><a href="abnormalbehaviors.html#cb242-3" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="fu">optimizer_sgd</span>(<span class="at">lr =</span> <span class="fl">0.01</span>),</span>
<span id="cb242-4"><a href="abnormalbehaviors.html#cb242-4" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">&#39;mse&#39;</span>)</span>
<span id="cb242-5"><a href="abnormalbehaviors.html#cb242-5" tabindex="-1"></a>)</span>
<span id="cb242-6"><a href="abnormalbehaviors.html#cb242-6" tabindex="-1"></a></span>
<span id="cb242-7"><a href="abnormalbehaviors.html#cb242-7" tabindex="-1"></a>history <span class="ot">&lt;-</span> autoencoder <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb242-8"><a href="abnormalbehaviors.html#cb242-8" tabindex="-1"></a>  <span class="fu">as.matrix</span>(train.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]),</span>
<span id="cb242-9"><a href="abnormalbehaviors.html#cb242-9" tabindex="-1"></a>  <span class="fu">as.matrix</span>(train.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]),</span>
<span id="cb242-10"><a href="abnormalbehaviors.html#cb242-10" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">100</span>,</span>
<span id="cb242-11"><a href="abnormalbehaviors.html#cb242-11" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">32</span>,</span>
<span id="cb242-12"><a href="abnormalbehaviors.html#cb242-12" tabindex="-1"></a>  <span class="at">validation_split =</span> <span class="fl">0.10</span>,</span>
<span id="cb242-13"><a href="abnormalbehaviors.html#cb242-13" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="dv">2</span>,</span>
<span id="cb242-14"><a href="abnormalbehaviors.html#cb242-14" tabindex="-1"></a>  <span class="at">view_metrics =</span> <span class="cn">TRUE</span></span>
<span id="cb242-15"><a href="abnormalbehaviors.html#cb242-15" tabindex="-1"></a>)</span></code></pre></div>
<p>We set <em>mean squared error</em> (MSE) as the loss function. We use the normal instances in the train set (<code>train.normal</code>) as the input and expected output. The validation split is set to <span class="math inline">\(10\%\)</span> so we can plot the reconstruction error (loss) on unseen instances. Finally, the model is trained for <span class="math inline">\(100\)</span> epochs. From Figure <a href="abnormalbehaviors.html#fig:lossAutoencoder">10.12</a> we can see that as the training progresses, the loss and the MSE decrease.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lossAutoencoder"></span>
<img src="images/loss_autoencoder.png" alt="Loss and MSE." width="90%" />
<p class="caption">
FIGURE 10.12: Loss and MSE.
</p>
</div>
<p>We can now compute the MSE on the normal and abnormal <strong>test sets</strong>. The <code>test.normal</code> data frame only contains normal test instances and <code>test.abnormal</code> only contains abnormal test instances.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="abnormalbehaviors.html#cb243-1" tabindex="-1"></a><span class="co"># Compute MSE on normal test set.</span></span>
<span id="cb243-2"><a href="abnormalbehaviors.html#cb243-2" tabindex="-1"></a>autoencoder <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(<span class="fu">as.matrix</span>(test.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]),</span>
<span id="cb243-3"><a href="abnormalbehaviors.html#cb243-3" tabindex="-1"></a>                         <span class="fu">as.matrix</span>(test.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]))</span>
<span id="cb243-4"><a href="abnormalbehaviors.html#cb243-4" tabindex="-1"></a><span class="co">#&gt;        loss mean_squared_error </span></span>
<span id="cb243-5"><a href="abnormalbehaviors.html#cb243-5" tabindex="-1"></a><span class="co">#&gt;  0.06147528         0.06147528 </span></span>
<span id="cb243-6"><a href="abnormalbehaviors.html#cb243-6" tabindex="-1"></a></span>
<span id="cb243-7"><a href="abnormalbehaviors.html#cb243-7" tabindex="-1"></a><span class="co"># Compute MSE on abnormal test set.</span></span>
<span id="cb243-8"><a href="abnormalbehaviors.html#cb243-8" tabindex="-1"></a>autoencoder <span class="sc">%&gt;%</span> <span class="fu">evaluate</span>(<span class="fu">as.matrix</span>(test.abnormal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]),</span>
<span id="cb243-9"><a href="abnormalbehaviors.html#cb243-9" tabindex="-1"></a>                         <span class="fu">as.matrix</span>(test.abnormal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]))</span>
<span id="cb243-10"><a href="abnormalbehaviors.html#cb243-10" tabindex="-1"></a><span class="co">#&gt;       loss mean_squared_error </span></span>
<span id="cb243-11"><a href="abnormalbehaviors.html#cb243-11" tabindex="-1"></a><span class="co">#&gt;   2.660597           2.660597</span></span></code></pre></div>
<p>Clearly, the MSE of the normal test set is much lower than the abnormal test set. This means that the autoencoder had a difficult time trying to reconstruct the abnormal points because it never saw similar ones before.</p>
<p>To find a good threshold we can start by analyzing the reconstruction errors on the <strong>train set</strong>. First, we need to get the predictions.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="abnormalbehaviors.html#cb244-1" tabindex="-1"></a><span class="co"># Predict values on the normal train set.</span></span>
<span id="cb244-2"><a href="abnormalbehaviors.html#cb244-2" tabindex="-1"></a>preds.train.normal <span class="ot">&lt;-</span> autoencoder <span class="sc">%&gt;%</span></span>
<span id="cb244-3"><a href="abnormalbehaviors.html#cb244-3" tabindex="-1"></a>  <span class="fu">predict_on_batch</span>(<span class="fu">as.matrix</span>(train.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]))</span></code></pre></div>
<p>The variable <code>preds.train.normal</code> contains the predicted values for each feature and each instance. We can use those predictions to compute the reconstruction error by comparing them with the ground truth values. As reconstruction error we will use the squared errors. The function <code>squared.errors()</code> computes the reconstruction error for each instance.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="abnormalbehaviors.html#cb245-1" tabindex="-1"></a><span class="co"># Compute individual squared errors in train set.</span></span>
<span id="cb245-2"><a href="abnormalbehaviors.html#cb245-2" tabindex="-1"></a>errors.train.normal <span class="ot">&lt;-</span> <span class="fu">squared.errors</span>(preds.train.normal,</span>
<span id="cb245-3"><a href="abnormalbehaviors.html#cb245-3" tabindex="-1"></a>                                   <span class="fu">as.matrix</span>(train.normal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]))</span>
<span id="cb245-4"><a href="abnormalbehaviors.html#cb245-4" tabindex="-1"></a></span>
<span id="cb245-5"><a href="abnormalbehaviors.html#cb245-5" tabindex="-1"></a><span class="fu">mean</span>(errors.train.normal)</span>
<span id="cb245-6"><a href="abnormalbehaviors.html#cb245-6" tabindex="-1"></a><span class="co">#&gt; [1] 0.8113273</span></span>
<span id="cb245-7"><a href="abnormalbehaviors.html#cb245-7" tabindex="-1"></a></span>
<span id="cb245-8"><a href="abnormalbehaviors.html#cb245-8" tabindex="-1"></a><span class="fu">quantile</span>(errors.train.normal)</span>
<span id="cb245-9"><a href="abnormalbehaviors.html#cb245-9" tabindex="-1"></a><span class="co">#&gt;         0%        25%        50%        75%       100% </span></span>
<span id="cb245-10"><a href="abnormalbehaviors.html#cb245-10" tabindex="-1"></a><span class="co">#&gt;  0.0158690  0.2926631  0.4978471  0.8874694 15.0958992 </span></span></code></pre></div>
<p>The mean reconstruction error of the normal instances in the train set is <span class="math inline">\(0.811\)</span>. If we look at the quantiles, we can see that most of the instances have an error of <span class="math inline">\(&lt;= 0.887\)</span>. With this information we can set <code>threshold &lt;- 1.0</code>. If the reconstruction error is <span class="math inline">\(&gt; threshold\)</span> then we will consider that point as an anomaly.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="abnormalbehaviors.html#cb246-1" tabindex="-1"></a><span class="co"># Make predictions on the abnormal test set.</span></span>
<span id="cb246-2"><a href="abnormalbehaviors.html#cb246-2" tabindex="-1"></a>preds.test.abnormal <span class="ot">&lt;-</span> autoencoder <span class="sc">%&gt;%</span></span>
<span id="cb246-3"><a href="abnormalbehaviors.html#cb246-3" tabindex="-1"></a>  <span class="fu">predict_on_batch</span>(<span class="fu">as.matrix</span>(test.abnormal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]))</span>
<span id="cb246-4"><a href="abnormalbehaviors.html#cb246-4" tabindex="-1"></a></span>
<span id="cb246-5"><a href="abnormalbehaviors.html#cb246-5" tabindex="-1"></a><span class="co"># Compute reconstruction errors.</span></span>
<span id="cb246-6"><a href="abnormalbehaviors.html#cb246-6" tabindex="-1"></a>errors.test.abnormal <span class="ot">&lt;-</span> <span class="fu">squared.errors</span>(preds.test.abnormal,</span>
<span id="cb246-7"><a href="abnormalbehaviors.html#cb246-7" tabindex="-1"></a>                                       <span class="fu">as.matrix</span>(test.abnormal[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]))</span>
<span id="cb246-8"><a href="abnormalbehaviors.html#cb246-8" tabindex="-1"></a></span>
<span id="cb246-9"><a href="abnormalbehaviors.html#cb246-9" tabindex="-1"></a><span class="co"># Predict labels based on threshold 1:abnormal, 0:normal.</span></span>
<span id="cb246-10"><a href="abnormalbehaviors.html#cb246-10" tabindex="-1"></a>pred.labels.abnormal <span class="ot">&lt;-</span> <span class="fu">as.integer</span>((errors.test.abnormal <span class="sc">&gt;</span> threshold))</span>
<span id="cb246-11"><a href="abnormalbehaviors.html#cb246-11" tabindex="-1"></a></span>
<span id="cb246-12"><a href="abnormalbehaviors.html#cb246-12" tabindex="-1"></a><span class="co"># Count how many abnormal instances were detected.</span></span>
<span id="cb246-13"><a href="abnormalbehaviors.html#cb246-13" tabindex="-1"></a><span class="fu">sum</span>(pred.labels.abnormal)</span>
<span id="cb246-14"><a href="abnormalbehaviors.html#cb246-14" tabindex="-1"></a><span class="co">#&gt; [1] 46</span></span></code></pre></div>
<p>By using that threshold the autoencoder was able to detect <span class="math inline">\(46\)</span> out of the <span class="math inline">\(54\)</span> anomaly points. From the following confusion matrix we can also see that there were <span class="math inline">\(16\)</span> false positives.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="abnormalbehaviors.html#cb247-1" tabindex="-1"></a></span>
<span id="cb247-2"><a href="abnormalbehaviors.html#cb247-2" tabindex="-1"></a><span class="co">#&gt;           Reference</span></span>
<span id="cb247-3"><a href="abnormalbehaviors.html#cb247-3" tabindex="-1"></a><span class="co">#&gt; Prediction   0   1</span></span>
<span id="cb247-4"><a href="abnormalbehaviors.html#cb247-4" tabindex="-1"></a><span class="co">#&gt;          0 202   8</span></span>
<span id="cb247-5"><a href="abnormalbehaviors.html#cb247-5" tabindex="-1"></a><span class="co">#&gt;          1  16  46</span></span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rocAutoencoder"></span>
<img src="images/roc_curve_autoencoder.png" alt="ROC curve and AUC. The dashed line represents a random model." width="90%" />
<p class="caption">
FIGURE 10.13: ROC curve and AUC. The dashed line represents a random model.
</p>
</div>
<p>From the ROC curve in Figure <a href="abnormalbehaviors.html#fig:rocAutoencoder">10.13</a> we can see that the AUC was <span class="math inline">\(0.93\)</span> which is lower than the <span class="math inline">\(0.96\)</span> achieved by the Isolation Forest but with some fine tuning and training for more epochs, the autoencoder should be able to achieve similar results.</p>
</div>
</div>
<div id="SummaryAnomalyDetection" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Summary<a href="abnormalbehaviors.html#SummaryAnomalyDetection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter presented two anomaly detection models, namely Isolation Forests and autoencoders. Examples of how those models can be used for anomaly trajectory detection were also presented. This chapter also introduced ROC curves and AUC which can be used to assess the performance of a model.</p>
<ul>
<li><strong>Isolation Forests</strong> work by generating random partitions of the features until all instances are isolated.</li>
<li>Abnormal points are more likely to be isolated during the first partitions.</li>
<li>The average tree path length of abnormal points is smaller than that of normal points.</li>
<li>An <strong>anomaly score</strong> that ranges between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> is calculated based on the path length and the closer to <span class="math inline">\(1\)</span> the more likely the point is an anomaly.</li>
<li>A <strong>ROC curve</strong> is used to visualize the sensitivity and false positive rate of a model for different thresholds.</li>
<li>The area under the curve <strong>AUC</strong> can be used to summarize the performance of a model.</li>
<li>A simple <strong>autoencoder</strong> is an artificial neural network whose output layer has the same shape as the input layer.</li>
<li>Autoencoders are used to encode the data into a lower dimension from which then, it can be reconstructed.</li>
<li>The <strong>reconstruction error</strong> (loss) is a measure of how distant a prediction is from the ground truth and can be used as an anomaly score.</li>
</ul>
<p><img src="images/comic_anomaly.png" width="100%" style="display: block; margin: auto;" />
</p>

</div>
</div>



<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-rmatlab" class="csl-entry">
Bengtsson, Henrik. 2018. <em>R.matlab: Read and Write MAT Files and Call MATLAB from Within r</em>. <a href="https://CRAN.R-project.org/package=R.matlab">https://CRAN.R-project.org/package=R.matlab</a>.
</div>
<div id="ref-Beyan2013" class="csl-entry">
Beyan, Cigdem, and Robert B Fisher. 2013. <span>“Detecting Abnormal Fish Trajectories Using Clustered and Labeled Data.”</span> In <em>2013 <span>IEEE</span> International Conference on Image Processing</em>, 1476–80. <span>IEEE</span>.
</div>
<div id="ref-prroc" class="csl-entry">
Grau, Jan, Ivo Grosse, and Jens Keilwagen. 2015. <span>“PRROC: Computing and Visualizing Precision-Recall and Receiver Operating Characteristic Curves in r.”</span> <em>Bioinformatics</em> 31 (15): 2595–97.
</div>
<div id="ref-Liu2008isolation" class="csl-entry">
Liu, F. T., K. M. Ting, and Z. Zhou. 2008. <span>“Isolation Forest.”</span> In <em>2008 Eighth <span>IEEE</span> International Conference on Data Mining</em>, 413–22.
</div>
<div id="ref-trajr" class="csl-entry">
McLean, Donald James, and Marta A. Skowron Volponi. 2018. <span>“Trajr: An r Package for Characterisation of Animal Trajectories.”</span> <em>Ethology</em> 124 (6). <a href="https://doi.org/10.1111/eth.12739">https://doi.org/10.1111/eth.12739</a>.
</div>
<div id="ref-anipaths" class="csl-entry">
Scharf, Henry. 2020. <em>Anipaths: Animation of Observed Trajectories Using Spline-Based Interpolation</em>. <a href="https://CRAN.R-project.org/package=anipaths">https://CRAN.R-project.org/package=anipaths</a>.
</div>
<div id="ref-solitude" class="csl-entry">
Srikanth, Komala Sheshachala. 2020. <em>Solitude: An Implementation of Isolation Forest</em>. <a href="https://CRAN.R-project.org/package=solitude">https://CRAN.R-project.org/package=solitude</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="28">
<li id="fn28"><p><a href="http://groups.inf.ed.ac.uk/f4k/" class="uri">http://groups.inf.ed.ac.uk/f4k/</a><a href="abnormalbehaviors.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p><a href="http://groups.inf.ed.ac.uk/f4k/GROUNDTRUTH/BEHAVIOR/" class="uri">http://groups.inf.ed.ac.uk/f4k/GROUNDTRUTH/BEHAVIOR/</a><a href="abnormalbehaviors.html#fnref29" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiuser.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendixInstall.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
